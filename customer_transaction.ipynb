{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af07aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f72688f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1914388a",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c4e1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float32', 'float64']  # Removed float16\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                # Skip float16 to avoid overflow issues with pandas display\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1711958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_class_distribution(y):\n",
    "    class0 = (y == 0).sum()\n",
    "    class1 = (y == 1).sum()\n",
    "\n",
    "    data = {\n",
    "        'Class': ['Class 0', 'Class 1'],\n",
    "        'Count': [class0, class1]\n",
    "    }\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(x='Class', y='Count', data=data)\n",
    "    plt.title('Class Distribution (Train Set)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc4cded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    # Ensure results folder exists\n",
    "    folder = \"results\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Build full path\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    # Save model\n",
    "    with open(filepath, 'wb') as file:\n",
    "        pkl.dump(model, file)\n",
    "\n",
    "    print(f\"Model saved to: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e86eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    # Build full path\n",
    "    filepath = os.path.join(\"results\", filename)\n",
    "\n",
    "    # Load model\n",
    "    with open(filepath, 'rb') as file:\n",
    "        model = pkl.load(file)\n",
    "\n",
    "    print(f\"Model loaded from: {filepath}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f80d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e2c1661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_classification_report(y_true, y_pred):\n",
    "    # Generate report as dict\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    \n",
    "    # Convert to DataFrame & transpose\n",
    "    df = pd.DataFrame(report).transpose().round(4)\n",
    "\n",
    "    # Reorder rows: class labels first, then accuracy + averages\n",
    "    row_order = [str(label) for label in sorted(df.index[:-3])] + [\"accuracy\", \"macro avg\", \"weighted avg\"]\n",
    "    df = df.loc[row_order]\n",
    "\n",
    "    # Fix accuracy row: put accuracy value in f1-score column\n",
    "    if \"accuracy\" in df.index:\n",
    "        df.loc[\"accuracy\", \"precision\"] = None\n",
    "        df.loc[\"accuracy\", \"recall\"] = None\n",
    "        df.loc[\"accuracy\", \"f1-score\"] = report[\"accuracy\"]\n",
    "    \n",
    "    # Color encoding for good / medium / bad values\n",
    "    def color_scale(s):\n",
    "        colors = []\n",
    "        for v in s:\n",
    "            if pd.isna(v):\n",
    "                colors.append(\"\")  \n",
    "            elif v >= 0.80:\n",
    "                colors.append(\"background-color: rgba(0, 200, 0, 0.35)\")   # green\n",
    "            elif v >= 0.50:\n",
    "                colors.append(\"background-color: rgba(255, 165, 0, 0.35)\") # yellow/orange\n",
    "            else:\n",
    "                colors.append(\"background-color: rgba(255, 0, 0, 0.35)\")   # red\n",
    "        return colors\n",
    "\n",
    "    numeric_cols = [\"precision\", \"recall\", \"f1-score\"]\n",
    "    styled = df.style.apply(color_scale, subset=numeric_cols)\n",
    "\n",
    "    # Make column headers bold\n",
    "    styled = styled.set_properties(**{\"font-weight\": \"bold\"}, subset=pd.IndexSlice[:, numeric_cols])\n",
    "\n",
    "    return styled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c69c95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(\n",
    "    model,\n",
    "    model_name,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    sampled=False\n",
    "):\n",
    "    # ---- Train model ----\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ---- Predictions ----\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # ---- Classification Report ----\n",
    "    report = show_classification_report(y_test, y_pred)\n",
    "\n",
    "    # ---- Build filename ----\n",
    "    suffix = \"_sampled\" if sampled else \"\"\n",
    "    filename = f\"{model_name}{suffix}.pkl\"\n",
    "\n",
    "    # ---- Save model ----\n",
    "    save_model(model, filename)\n",
    "\n",
    "    return model, y_pred, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587fc5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_for_imbalance(model, y_train):\n",
    "    \"\"\"\n",
    "    Automatically configures a model with the best imbalance-handling parameters.\n",
    "\n",
    "    Works with:\n",
    "    - LogisticRegression\n",
    "    - RandomForestClassifier\n",
    "    - GradientBoostingClassifier\n",
    "    - AdaBoostClassifier\n",
    "    - SVC / LinearSVC\n",
    "    - KNN\n",
    "    - GaussianNB\n",
    "    - MLPClassifier\n",
    "    - XGBClassifier\n",
    "    - LGBMClassifier\n",
    "    - CatBoostClassifier\n",
    "    \"\"\"\n",
    "\n",
    "    # compute class weights / imbalance ratio\n",
    "    counter = Counter(y_train)\n",
    "    maj = counter[0]\n",
    "    minr = counter[1]\n",
    "\n",
    "    imbalance_ratio = maj / minr  # used for scale_pos_weight etc.\n",
    "\n",
    "    params = {}\n",
    "\n",
    "    # ----- XGBoost -----\n",
    "    if model.__class__.__name__ == \"XGBClassifier\":\n",
    "        params[\"scale_pos_weight\"] = imbalance_ratio\n",
    "\n",
    "    # ----- LightGBM -----\n",
    "    elif model.__class__.__name__ == \"LGBMClassifier\":\n",
    "        params[\"is_unbalance\"] = True\n",
    "        params[\"scale_pos_weight\"] = imbalance_ratio\n",
    "\n",
    "    # ----- CatBoost -----\n",
    "    elif model.__class__.__name__ == \"CatBoostClassifier\":\n",
    "        params[\"class_weights\"] = [1, imbalance_ratio]\n",
    "\n",
    "    # ----- Logistic Regression -----\n",
    "    elif model.__class__.__name__ == \"LogisticRegression\":\n",
    "        params[\"class_weight\"] = \"balanced\"\n",
    "\n",
    "    # ----- Random Forest -----\n",
    "    elif model.__class__.__name__ == \"RandomForestClassifier\":\n",
    "        params[\"class_weight\"] = \"balanced\"\n",
    "\n",
    "    # ----- Gradient Boosting -----\n",
    "    elif model.__class__.__name__ == \"GradientBoostingClassifier\":\n",
    "        params[\"subsample\"] = 1.0  # stabilize on imbalance\n",
    "\n",
    "    # ----- AdaBoost -----\n",
    "    elif model.__class__.__name__ == \"AdaBoostClassifier\":\n",
    "        params[\"algorithm\"] = \"SAMME.R\"\n",
    "\n",
    "    # ----- SVC / LinearSVC -----\n",
    "    elif model.__class__.__name__ in [\"SVC\", \"LinearSVC\"]:\n",
    "        params[\"class_weight\"] = \"balanced\"\n",
    "\n",
    "    # Set parameters dynamically\n",
    "    for key, value in params.items():\n",
    "        try:\n",
    "            setattr(model, key, value)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386e98c",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "- Import the data from Kaggle [Santander Customer Transaction Prediction Dataset](https://www.kaggle.com/datasets/lakshmi25npathi/santander-customer-transaction-prediction-dataset/data)\n",
    "- Visualize the data: \n",
    "    - Check the size and type of data.\n",
    "- Convert data to practical formats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a43d2c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: /Users/olutolaoloruntobipaul/.cache/kagglehub/datasets/lakshmi25npathi/santander-customer-transaction-prediction-dataset/versions/1\n",
      "\n",
      "Files in the dataset:\n",
      "  - test.csv\n",
      "  - train.csv\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset first to see what files are available\n",
    "dataset_path = kagglehub.dataset_download(\"lakshmi25npathi/santander-customer-transaction-prediction-dataset\")\n",
    "\n",
    "print(f\"Dataset downloaded to: {dataset_path}\")\n",
    "print(\"\\nFiles in the dataset:\")\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        print(f\"  - {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eac3d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(dataset_path, \"train.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e53f29",
   "metadata": {},
   "source": [
    "#### Dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ae8aece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e358589b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99b5ff5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1243a2",
   "metadata": {},
   "source": [
    "### Exploration Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a796dd9",
   "metadata": {},
   "source": [
    "- Downsampling a copy of the dataset\n",
    "- Check data type\n",
    "- Data cleaning\n",
    "    - Fill in missing values (empty or NaN) or drop their rows\n",
    "    - Fix or Remove outliers\n",
    "- Feature selection\n",
    "    - Drop non relevant columns\n",
    "- Feature engineering\n",
    "    - Possibly discretize continuous features\n",
    "    - Decompose features (e.g., categorical, date/time)\n",
    "    - Add promising feature transformations (e.g., log(x), x^2)\n",
    "    - Aggregate features into promising new features\n",
    "- Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df375c",
   "metadata": {},
   "source": [
    "Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c70c8001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID_code, target, var_0, var_1, var_2, var_3, var_4, var_5, var_6, var_7, var_8, var_9, var_10, var_11, var_12, var_13, var_14, var_15, var_16, var_17, var_18, var_19, var_20, var_21, var_22, var_23, var_24, var_25, var_26, var_27, var_28, var_29, var_30, var_31, var_32, var_33, var_34, var_35, var_36, var_37, var_38, var_39, var_40, var_41, var_42, var_43, var_44, var_45, var_46, var_47, var_48, var_49, var_50, var_51, var_52, var_53, var_54, var_55, var_56, var_57, var_58, var_59, var_60, var_61, var_62, var_63, var_64, var_65, var_66, var_67, var_68, var_69, var_70, var_71, var_72, var_73, var_74, var_75, var_76, var_77, var_78, var_79, var_80, var_81, var_82, var_83, var_84, var_85, var_86, var_87, var_88, var_89, var_90, var_91, var_92, var_93, var_94, var_95, var_96, var_97, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 202 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check empty values in each column\n",
    "empty = df.isna().sum()\n",
    "print(empty[empty>0])\n",
    "# Show rows with any null values\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fa91c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    179902\n",
       "1     20098\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fe01072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target    var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266   \n",
       "1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338   \n",
       "2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155   \n",
       "3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250   \n",
       "4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514   \n",
       "\n",
       "    var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0 -4.9200  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   \n",
       "1  3.1468  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   \n",
       "2 -4.9193  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417  -6.5213   \n",
       "3 -5.8609  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706  -2.9275   \n",
       "4  6.2654  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   3.9267   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0   8.5635  12.7803  -1.0914  \n",
       "1   8.7889  18.3560   1.9518  \n",
       "2   8.2675  14.7222   0.3965  \n",
       "3  10.2922  17.9697  -8.9996  \n",
       "4   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the ID_code column\n",
    "df = df.drop(columns=['ID_code'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7853c945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total outliers detected across all columns: 26536\n",
      "Total unique rows with outliers: 24896\n",
      "\n",
      "Outlier rows shape: (24896, 201)\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers\n",
    "total_outliers = 0\n",
    "\n",
    "# Detect outliers using the IQR method\n",
    "\n",
    "outlier_indices = set()\n",
    "\n",
    "for col in df.columns.drop('target'):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outlier_mask = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "    outlier_idx = df[outlier_mask].index.tolist()\n",
    "    \n",
    "    #print(f\"Column: {col}, Outliers detected: {len(outlier_idx)}\")\n",
    "    \n",
    "    # Add indices to the set (automatically removes duplicates)\n",
    "    outlier_indices.update(outlier_idx)\n",
    "    total_outliers += len(outlier_idx)\n",
    "print(f\"Total outliers detected across all columns: {total_outliers}\")\n",
    "print(f\"Total unique rows with outliers: {len(outlier_indices)}\")\n",
    "\n",
    "# (Optional) View the unique outlier rows\n",
    "outlier_rows = df.loc[list(outlier_indices)]\n",
    "print(f\"\\nOutlier rows shape: {outlier_rows.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "29827127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check non numeric columns to transform data into a more efficient type for the training\n",
    "non_numeric_cols = df.select_dtypes(exclude=['number']).columns\n",
    "non_numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b43aff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175104, 201)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove outlier rows from the original dataframe\n",
    "df_cleaned = df.drop(index=outlier_indices)\n",
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8351630",
   "metadata": {},
   "source": [
    "Split test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64bd4056",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cleaned.drop(columns=['target'])\n",
    "y = df_cleaned['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "60135367",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1a3f3",
   "metadata": {},
   "source": [
    "Visualize target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2cea460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_class_distribution(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc15488",
   "metadata": {},
   "source": [
    "We see an imbalance dataset. Solution:\n",
    "- Doing downsampling on a copy of the training dataset to evaluate the performance\n",
    "- Doing class weighted on the models\n",
    "\n",
    "We don't do upsample because we want to minimize training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "165ebea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Downsampling\n",
    "X_train_copy = X_train.copy()\n",
    "y_train_copy = y_train.copy()\n",
    "rus = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_resampled_down, y_resampled_down = rus.fit_resample(X_train_copy, y_train_copy)\n",
    "visualize_class_distribution(y_resampled_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d0c75056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1, 1: 10.24}\n"
     ]
    }
   ],
   "source": [
    "# Class weigthing\n",
    "class_weights = {0: 1, 1: round((len(y_train) / sum(y_train)),2)}  # Adjust weights based on class distribution\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b25425",
   "metadata": {},
   "source": [
    "Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "03e7667a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050677</td>\n",
       "      <td>0.047490</td>\n",
       "      <td>0.057339</td>\n",
       "      <td>0.011219</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.030933</td>\n",
       "      <td>0.067612</td>\n",
       "      <td>-0.002929</td>\n",
       "      <td>0.019535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054470</td>\n",
       "      <td>0.047234</td>\n",
       "      <td>-0.041799</td>\n",
       "      <td>-0.018757</td>\n",
       "      <td>-0.022275</td>\n",
       "      <td>0.028054</td>\n",
       "      <td>0.024125</td>\n",
       "      <td>-0.036136</td>\n",
       "      <td>-0.051309</td>\n",
       "      <td>0.024045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_0</th>\n",
       "      <td>0.050677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.006565</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>-0.005919</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>-0.001463</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>-0.004247</td>\n",
       "      <td>0.002421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_1</th>\n",
       "      <td>0.047490</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>-0.000727</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006455</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>-0.001848</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>-0.002533</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>-0.005277</td>\n",
       "      <td>0.002958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_2</th>\n",
       "      <td>0.057339</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>-0.001774</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>-0.002770</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_3</th>\n",
       "      <td>0.011219</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>-0.000779</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>-0.002122</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>-0.000593</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>-0.001852</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>-0.003154</td>\n",
       "      <td>-0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_195</th>\n",
       "      <td>0.028054</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>-0.001078</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>-0.003227</td>\n",
       "      <td>-0.003516</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.002546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_196</th>\n",
       "      <td>0.024125</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>-0.001852</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.006531</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001792</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>-0.003472</td>\n",
       "      <td>-0.006053</td>\n",
       "      <td>-0.003678</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001325</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_197</th>\n",
       "      <td>-0.036136</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>-0.000746</td>\n",
       "      <td>-0.001695</td>\n",
       "      <td>-0.004202</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005261</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>-0.001156</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.001325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.005727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_198</th>\n",
       "      <td>-0.051309</td>\n",
       "      <td>-0.004247</td>\n",
       "      <td>-0.005277</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>-0.003154</td>\n",
       "      <td>-0.000949</td>\n",
       "      <td>-0.000902</td>\n",
       "      <td>-0.001469</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000754</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_199</th>\n",
       "      <td>0.024045</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>-0.001976</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000696</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>-0.001420</td>\n",
       "      <td>-0.004930</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>-0.005660</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           target     var_0     var_1     var_2     var_3     var_4     var_5  \\\n",
       "target   1.000000  0.050677  0.047490  0.057339  0.011219  0.012102  0.030933   \n",
       "var_0    0.050677  1.000000  0.000447  0.005772  0.003607  0.001497  0.003588   \n",
       "var_1    0.047490  0.000447  1.000000  0.002469 -0.000130  0.001733 -0.000727   \n",
       "var_2    0.057339  0.005772  0.002469  1.000000  0.000771  0.000612  0.000792   \n",
       "var_3    0.011219  0.003607 -0.000130  0.000771  1.000000  0.000156  0.003662   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "var_195  0.028054  0.002069  0.000724  0.000584  0.002108  0.005189 -0.001078   \n",
       "var_196  0.024125  0.002914  0.000386  0.004006 -0.001852 -0.000160  0.001153   \n",
       "var_197 -0.036136  0.000658 -0.004665  0.002382  0.001307 -0.000746 -0.001695   \n",
       "var_198 -0.051309 -0.004247 -0.005277  0.000207 -0.003154 -0.000949 -0.000902   \n",
       "var_199  0.024045  0.002421  0.002958  0.004883 -0.000276 -0.000064  0.001943   \n",
       "\n",
       "            var_6     var_7     var_8  ...   var_190   var_191   var_192  \\\n",
       "target   0.067612 -0.002929  0.019535  ...  0.054470  0.047234 -0.041799   \n",
       "var_0    0.006565  0.002388  0.003740  ...  0.002344  0.000057 -0.005919   \n",
       "var_1    0.002896  0.001547  0.003268  ...  0.006455  0.003558 -0.001848   \n",
       "var_2    0.000188 -0.001774  0.001454  ... -0.000375  0.001336 -0.002770   \n",
       "var_3   -0.000779  0.001929  0.003534  ... -0.000231  0.001728 -0.002122   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "var_195  0.000565  0.002112  0.000198  ...  0.003629  0.002050 -0.003227   \n",
       "var_196  0.006531  0.000535 -0.003881  ... -0.001792  0.001177 -0.003472   \n",
       "var_197 -0.004202  0.004578 -0.004864  ... -0.005261  0.000397 -0.001156   \n",
       "var_198 -0.001469  0.000850  0.004268  ... -0.000754  0.001345  0.004206   \n",
       "var_199  0.004995 -0.001976  0.000210  ... -0.000696  0.003707  0.000844   \n",
       "\n",
       "          var_193   var_194   var_195   var_196   var_197   var_198   var_199  \n",
       "target  -0.018757 -0.022275  0.028054  0.024125 -0.036136 -0.051309  0.024045  \n",
       "var_0    0.002756 -0.001463  0.002069  0.002914  0.000658 -0.004247  0.002421  \n",
       "var_1    0.000736 -0.002533  0.000724  0.000386 -0.004665 -0.005277  0.002958  \n",
       "var_2    0.002097  0.002122  0.000584  0.004006  0.002382  0.000207  0.004883  \n",
       "var_3    0.001135 -0.000593  0.002108 -0.001852  0.001307 -0.003154 -0.000276  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "var_195 -0.003516 -0.000303  1.000000  0.002843 -0.002592 -0.000202  0.002546  \n",
       "var_196 -0.006053 -0.003678  0.002843  1.000000 -0.001325 -0.000204  0.001853  \n",
       "var_197  0.005578  0.001027 -0.002592 -0.001325  1.000000  0.000251  0.005727  \n",
       "var_198  0.001747  0.003350 -0.000202 -0.000204  0.000251  1.000000 -0.005660  \n",
       "var_199 -0.001420 -0.004930  0.002546  0.001853  0.005727 -0.005660  1.000000  \n",
       "\n",
       "[201 rows x 201 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorr = df_cleaned.corr(numeric_only=True)\n",
    "scorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19bf67e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 correlated pairs:\n",
      " var_81   target     0.080109\n",
      "target   var_139    0.073132\n",
      "var_12   target     0.068957\n",
      "var_6    target     0.067612\n",
      "var_53   target     0.062227\n",
      "var_26   target     0.062202\n",
      "target   var_110    0.061564\n",
      "         var_146    0.060576\n",
      "var_174  target     0.059820\n",
      "var_76   target     0.059430\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "np.fill_diagonal(scorr.values, 0)\n",
    "top_pairs = scorr.abs().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "top_4_pairs = top_pairs.head(10)\n",
    "print(\"Top 4 correlated pairs:\\n\", top_4_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288c2563",
   "metadata": {},
   "source": [
    "Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1914d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features of the inbalanced dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1f8757b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features of the balanced dataset (downsample)\n",
    "scaler = StandardScaler()\n",
    "X_resampled_train_scaled = scaler.fit_transform(X_resampled_down)\n",
    "X_resampled_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d4c5cf",
   "metadata": {},
   "source": [
    "### Models fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878c855",
   "metadata": {},
   "source": [
    "Trying the models for the sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89a59c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/logistic_regression_sampled.pkl\n"
     ]
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=LogisticRegression(),\n",
    "    model_name=\"logistic_regression\",\n",
    "    X_train=X_resampled_train_scaled,\n",
    "    y_train=y_resampled_down,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2e6c788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dea0c_row0_col0, #T_dea0c_row1_col1, #T_dea0c_row4_col0 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_dea0c_row0_col1, #T_dea0c_row0_col2, #T_dea0c_row2_col2, #T_dea0c_row3_col0, #T_dea0c_row3_col1, #T_dea0c_row3_col2, #T_dea0c_row4_col1, #T_dea0c_row4_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_dea0c_row1_col0, #T_dea0c_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_dea0c_row2_col0, #T_dea0c_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dea0c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dea0c_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_dea0c_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_dea0c_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_dea0c_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dea0c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_dea0c_row0_col0\" class=\"data row0 col0\" >0.981600</td>\n",
       "      <td id=\"T_dea0c_row0_col1\" class=\"data row0 col1\" >0.560100</td>\n",
       "      <td id=\"T_dea0c_row0_col2\" class=\"data row0 col2\" >0.713200</td>\n",
       "      <td id=\"T_dea0c_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dea0c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_dea0c_row1_col0\" class=\"data row1 col0\" >0.181900</td>\n",
       "      <td id=\"T_dea0c_row1_col1\" class=\"data row1 col1\" >0.903200</td>\n",
       "      <td id=\"T_dea0c_row1_col2\" class=\"data row1 col2\" >0.302800</td>\n",
       "      <td id=\"T_dea0c_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dea0c_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_dea0c_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_dea0c_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_dea0c_row2_col2\" class=\"data row2 col2\" >0.593615</td>\n",
       "      <td id=\"T_dea0c_row2_col3\" class=\"data row2 col3\" >0.593600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dea0c_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_dea0c_row3_col0\" class=\"data row3 col0\" >0.581800</td>\n",
       "      <td id=\"T_dea0c_row3_col1\" class=\"data row3 col1\" >0.731700</td>\n",
       "      <td id=\"T_dea0c_row3_col2\" class=\"data row3 col2\" >0.508000</td>\n",
       "      <td id=\"T_dea0c_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dea0c_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_dea0c_row4_col0\" class=\"data row4 col0\" >0.903500</td>\n",
       "      <td id=\"T_dea0c_row4_col1\" class=\"data row4 col1\" >0.593600</td>\n",
       "      <td id=\"T_dea0c_row4_col2\" class=\"data row4 col2\" >0.673100</td>\n",
       "      <td id=\"T_dea0c_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123db65d0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "436f80cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13684, number of negative: 13684\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51000\n",
      "[LightGBM] [Info] Number of data points in the train set: 27368, number of used features: 200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Model saved to: results/lgbm_classifier_sampled.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olutolaoloruntobipaul/Desktop/Projects/Hands-on-ML/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e2866_row0_col0, #T_e2866_row1_col1, #T_e2866_row4_col0 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_e2866_row0_col1, #T_e2866_row0_col2, #T_e2866_row2_col2, #T_e2866_row3_col0, #T_e2866_row3_col1, #T_e2866_row3_col2, #T_e2866_row4_col1, #T_e2866_row4_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_e2866_row1_col0, #T_e2866_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_e2866_row2_col0, #T_e2866_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e2866\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e2866_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_e2866_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_e2866_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_e2866_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e2866_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e2866_row0_col0\" class=\"data row0 col0\" >0.983200</td>\n",
       "      <td id=\"T_e2866_row0_col1\" class=\"data row0 col1\" >0.570200</td>\n",
       "      <td id=\"T_e2866_row0_col2\" class=\"data row0 col2\" >0.721800</td>\n",
       "      <td id=\"T_e2866_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e2866_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e2866_row1_col0\" class=\"data row1 col0\" >0.186500</td>\n",
       "      <td id=\"T_e2866_row1_col1\" class=\"data row1 col1\" >0.910000</td>\n",
       "      <td id=\"T_e2866_row1_col2\" class=\"data row1 col2\" >0.309500</td>\n",
       "      <td id=\"T_e2866_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e2866_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_e2866_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_e2866_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_e2866_row2_col2\" class=\"data row2 col2\" >0.603381</td>\n",
       "      <td id=\"T_e2866_row2_col3\" class=\"data row2 col3\" >0.603400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e2866_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_e2866_row3_col0\" class=\"data row3 col0\" >0.584800</td>\n",
       "      <td id=\"T_e2866_row3_col1\" class=\"data row3 col1\" >0.740100</td>\n",
       "      <td id=\"T_e2866_row3_col2\" class=\"data row3 col2\" >0.515600</td>\n",
       "      <td id=\"T_e2866_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e2866_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_e2866_row4_col0\" class=\"data row4 col0\" >0.905400</td>\n",
       "      <td id=\"T_e2866_row4_col1\" class=\"data row4 col1\" >0.603400</td>\n",
       "      <td id=\"T_e2866_row4_col2\" class=\"data row4 col2\" >0.681500</td>\n",
       "      <td id=\"T_e2866_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123db6850>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=LGBMClassifier(),\n",
    "    model_name=\"lgbm_classifier\",\n",
    "    X_train=X_resampled_train_scaled,\n",
    "    y_train=y_resampled_down,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=True\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10b27da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.042329\n",
      "0:\tlearn: 0.6899350\ttotal: 25.6ms\tremaining: 25.6s\n",
      "1:\tlearn: 0.6869408\ttotal: 37.8ms\tremaining: 18.9s\n",
      "2:\tlearn: 0.6842736\ttotal: 48.6ms\tremaining: 16.2s\n",
      "3:\tlearn: 0.6820932\ttotal: 63.4ms\tremaining: 15.8s\n",
      "4:\tlearn: 0.6795688\ttotal: 112ms\tremaining: 22.3s\n",
      "5:\tlearn: 0.6772110\ttotal: 131ms\tremaining: 21.8s\n",
      "6:\tlearn: 0.6746945\ttotal: 143ms\tremaining: 20.3s\n",
      "7:\tlearn: 0.6722055\ttotal: 152ms\tremaining: 18.8s\n",
      "8:\tlearn: 0.6700897\ttotal: 161ms\tremaining: 17.7s\n",
      "9:\tlearn: 0.6680501\ttotal: 170ms\tremaining: 16.8s\n",
      "10:\tlearn: 0.6658896\ttotal: 178ms\tremaining: 16s\n",
      "11:\tlearn: 0.6637848\ttotal: 188ms\tremaining: 15.5s\n",
      "12:\tlearn: 0.6617870\ttotal: 198ms\tremaining: 15s\n",
      "13:\tlearn: 0.6598926\ttotal: 209ms\tremaining: 14.7s\n",
      "14:\tlearn: 0.6580357\ttotal: 221ms\tremaining: 14.5s\n",
      "15:\tlearn: 0.6562945\ttotal: 232ms\tremaining: 14.3s\n",
      "16:\tlearn: 0.6544258\ttotal: 241ms\tremaining: 13.9s\n",
      "17:\tlearn: 0.6526491\ttotal: 250ms\tremaining: 13.6s\n",
      "18:\tlearn: 0.6509555\ttotal: 258ms\tremaining: 13.3s\n",
      "19:\tlearn: 0.6491692\ttotal: 267ms\tremaining: 13.1s\n",
      "20:\tlearn: 0.6476175\ttotal: 277ms\tremaining: 12.9s\n",
      "21:\tlearn: 0.6460027\ttotal: 286ms\tremaining: 12.7s\n",
      "22:\tlearn: 0.6443512\ttotal: 295ms\tremaining: 12.5s\n",
      "23:\tlearn: 0.6427711\ttotal: 304ms\tremaining: 12.4s\n",
      "24:\tlearn: 0.6412169\ttotal: 313ms\tremaining: 12.2s\n",
      "25:\tlearn: 0.6397941\ttotal: 321ms\tremaining: 12s\n",
      "26:\tlearn: 0.6383913\ttotal: 330ms\tremaining: 11.9s\n",
      "27:\tlearn: 0.6368969\ttotal: 339ms\tremaining: 11.8s\n",
      "28:\tlearn: 0.6355652\ttotal: 348ms\tremaining: 11.6s\n",
      "29:\tlearn: 0.6341732\ttotal: 356ms\tremaining: 11.5s\n",
      "30:\tlearn: 0.6326985\ttotal: 366ms\tremaining: 11.4s\n",
      "31:\tlearn: 0.6312780\ttotal: 375ms\tremaining: 11.4s\n",
      "32:\tlearn: 0.6297733\ttotal: 384ms\tremaining: 11.3s\n",
      "33:\tlearn: 0.6283145\ttotal: 394ms\tremaining: 11.2s\n",
      "34:\tlearn: 0.6269559\ttotal: 404ms\tremaining: 11.1s\n",
      "35:\tlearn: 0.6256225\ttotal: 415ms\tremaining: 11.1s\n",
      "36:\tlearn: 0.6243585\ttotal: 425ms\tremaining: 11.1s\n",
      "37:\tlearn: 0.6230110\ttotal: 434ms\tremaining: 11s\n",
      "38:\tlearn: 0.6217532\ttotal: 445ms\tremaining: 11s\n",
      "39:\tlearn: 0.6204841\ttotal: 458ms\tremaining: 11s\n",
      "40:\tlearn: 0.6192189\ttotal: 467ms\tremaining: 10.9s\n",
      "41:\tlearn: 0.6178807\ttotal: 476ms\tremaining: 10.9s\n",
      "42:\tlearn: 0.6166215\ttotal: 486ms\tremaining: 10.8s\n",
      "43:\tlearn: 0.6153678\ttotal: 494ms\tremaining: 10.7s\n",
      "44:\tlearn: 0.6141526\ttotal: 503ms\tremaining: 10.7s\n",
      "45:\tlearn: 0.6128900\ttotal: 512ms\tremaining: 10.6s\n",
      "46:\tlearn: 0.6117271\ttotal: 522ms\tremaining: 10.6s\n",
      "47:\tlearn: 0.6105377\ttotal: 532ms\tremaining: 10.5s\n",
      "48:\tlearn: 0.6093307\ttotal: 541ms\tremaining: 10.5s\n",
      "49:\tlearn: 0.6082745\ttotal: 550ms\tremaining: 10.4s\n",
      "50:\tlearn: 0.6071199\ttotal: 558ms\tremaining: 10.4s\n",
      "51:\tlearn: 0.6060246\ttotal: 568ms\tremaining: 10.4s\n",
      "52:\tlearn: 0.6048882\ttotal: 577ms\tremaining: 10.3s\n",
      "53:\tlearn: 0.6038352\ttotal: 586ms\tremaining: 10.3s\n",
      "54:\tlearn: 0.6028078\ttotal: 596ms\tremaining: 10.2s\n",
      "55:\tlearn: 0.6017147\ttotal: 606ms\tremaining: 10.2s\n",
      "56:\tlearn: 0.6006853\ttotal: 615ms\tremaining: 10.2s\n",
      "57:\tlearn: 0.5996071\ttotal: 625ms\tremaining: 10.1s\n",
      "58:\tlearn: 0.5985786\ttotal: 634ms\tremaining: 10.1s\n",
      "59:\tlearn: 0.5976043\ttotal: 643ms\tremaining: 10.1s\n",
      "60:\tlearn: 0.5965211\ttotal: 653ms\tremaining: 10s\n",
      "61:\tlearn: 0.5956412\ttotal: 662ms\tremaining: 10s\n",
      "62:\tlearn: 0.5946759\ttotal: 672ms\tremaining: 9.99s\n",
      "63:\tlearn: 0.5936391\ttotal: 681ms\tremaining: 9.96s\n",
      "64:\tlearn: 0.5926320\ttotal: 690ms\tremaining: 9.92s\n",
      "65:\tlearn: 0.5917396\ttotal: 699ms\tremaining: 9.89s\n",
      "66:\tlearn: 0.5908433\ttotal: 708ms\tremaining: 9.86s\n",
      "67:\tlearn: 0.5898915\ttotal: 718ms\tremaining: 9.84s\n",
      "68:\tlearn: 0.5889632\ttotal: 727ms\tremaining: 9.81s\n",
      "69:\tlearn: 0.5879971\ttotal: 738ms\tremaining: 9.81s\n",
      "70:\tlearn: 0.5871179\ttotal: 752ms\tremaining: 9.83s\n",
      "71:\tlearn: 0.5861377\ttotal: 761ms\tremaining: 9.8s\n",
      "72:\tlearn: 0.5852351\ttotal: 770ms\tremaining: 9.78s\n",
      "73:\tlearn: 0.5843070\ttotal: 782ms\tremaining: 9.78s\n",
      "74:\tlearn: 0.5834210\ttotal: 791ms\tremaining: 9.76s\n",
      "75:\tlearn: 0.5825018\ttotal: 802ms\tremaining: 9.75s\n",
      "76:\tlearn: 0.5816049\ttotal: 813ms\tremaining: 9.74s\n",
      "77:\tlearn: 0.5808016\ttotal: 824ms\tremaining: 9.74s\n",
      "78:\tlearn: 0.5799287\ttotal: 834ms\tremaining: 9.72s\n",
      "79:\tlearn: 0.5791226\ttotal: 845ms\tremaining: 9.71s\n",
      "80:\tlearn: 0.5782847\ttotal: 855ms\tremaining: 9.71s\n",
      "81:\tlearn: 0.5774647\ttotal: 865ms\tremaining: 9.69s\n",
      "82:\tlearn: 0.5766356\ttotal: 876ms\tremaining: 9.68s\n",
      "83:\tlearn: 0.5758298\ttotal: 886ms\tremaining: 9.66s\n",
      "84:\tlearn: 0.5750096\ttotal: 897ms\tremaining: 9.65s\n",
      "85:\tlearn: 0.5742266\ttotal: 907ms\tremaining: 9.64s\n",
      "86:\tlearn: 0.5734969\ttotal: 917ms\tremaining: 9.63s\n",
      "87:\tlearn: 0.5728156\ttotal: 928ms\tremaining: 9.61s\n",
      "88:\tlearn: 0.5720074\ttotal: 938ms\tremaining: 9.6s\n",
      "89:\tlearn: 0.5711782\ttotal: 948ms\tremaining: 9.59s\n",
      "90:\tlearn: 0.5704110\ttotal: 958ms\tremaining: 9.57s\n",
      "91:\tlearn: 0.5696947\ttotal: 968ms\tremaining: 9.55s\n",
      "92:\tlearn: 0.5690079\ttotal: 977ms\tremaining: 9.53s\n",
      "93:\tlearn: 0.5681915\ttotal: 986ms\tremaining: 9.5s\n",
      "94:\tlearn: 0.5674360\ttotal: 996ms\tremaining: 9.48s\n",
      "95:\tlearn: 0.5666762\ttotal: 1s\tremaining: 9.47s\n",
      "96:\tlearn: 0.5659186\ttotal: 1.01s\tremaining: 9.45s\n",
      "97:\tlearn: 0.5651250\ttotal: 1.03s\tremaining: 9.45s\n",
      "98:\tlearn: 0.5644035\ttotal: 1.04s\tremaining: 9.45s\n",
      "99:\tlearn: 0.5636605\ttotal: 1.05s\tremaining: 9.43s\n",
      "100:\tlearn: 0.5629791\ttotal: 1.06s\tremaining: 9.41s\n",
      "101:\tlearn: 0.5622426\ttotal: 1.07s\tremaining: 9.41s\n",
      "102:\tlearn: 0.5615777\ttotal: 1.08s\tremaining: 9.39s\n",
      "103:\tlearn: 0.5608630\ttotal: 1.09s\tremaining: 9.39s\n",
      "104:\tlearn: 0.5601099\ttotal: 1.1s\tremaining: 9.37s\n",
      "105:\tlearn: 0.5594384\ttotal: 1.11s\tremaining: 9.36s\n",
      "106:\tlearn: 0.5588159\ttotal: 1.12s\tremaining: 9.35s\n",
      "107:\tlearn: 0.5581150\ttotal: 1.13s\tremaining: 9.34s\n",
      "108:\tlearn: 0.5573737\ttotal: 1.14s\tremaining: 9.33s\n",
      "109:\tlearn: 0.5566254\ttotal: 1.15s\tremaining: 9.31s\n",
      "110:\tlearn: 0.5560327\ttotal: 1.16s\tremaining: 9.3s\n",
      "111:\tlearn: 0.5553577\ttotal: 1.17s\tremaining: 9.29s\n",
      "112:\tlearn: 0.5546007\ttotal: 1.18s\tremaining: 9.29s\n",
      "113:\tlearn: 0.5538704\ttotal: 1.2s\tremaining: 9.29s\n",
      "114:\tlearn: 0.5532401\ttotal: 1.21s\tremaining: 9.29s\n",
      "115:\tlearn: 0.5525714\ttotal: 1.22s\tremaining: 9.29s\n",
      "116:\tlearn: 0.5518899\ttotal: 1.23s\tremaining: 9.29s\n",
      "117:\tlearn: 0.5512707\ttotal: 1.24s\tremaining: 9.29s\n",
      "118:\tlearn: 0.5506013\ttotal: 1.25s\tremaining: 9.27s\n",
      "119:\tlearn: 0.5499081\ttotal: 1.26s\tremaining: 9.25s\n",
      "120:\tlearn: 0.5492602\ttotal: 1.27s\tremaining: 9.23s\n",
      "121:\tlearn: 0.5485325\ttotal: 1.28s\tremaining: 9.21s\n",
      "122:\tlearn: 0.5478870\ttotal: 1.29s\tremaining: 9.19s\n",
      "123:\tlearn: 0.5473435\ttotal: 1.3s\tremaining: 9.17s\n",
      "124:\tlearn: 0.5467244\ttotal: 1.31s\tremaining: 9.15s\n",
      "125:\tlearn: 0.5460873\ttotal: 1.32s\tremaining: 9.13s\n",
      "126:\tlearn: 0.5454775\ttotal: 1.33s\tremaining: 9.12s\n",
      "127:\tlearn: 0.5448993\ttotal: 1.33s\tremaining: 9.1s\n",
      "128:\tlearn: 0.5442359\ttotal: 1.34s\tremaining: 9.08s\n",
      "129:\tlearn: 0.5436493\ttotal: 1.35s\tremaining: 9.06s\n",
      "130:\tlearn: 0.5430012\ttotal: 1.36s\tremaining: 9.04s\n",
      "131:\tlearn: 0.5424411\ttotal: 1.37s\tremaining: 9.02s\n",
      "132:\tlearn: 0.5418836\ttotal: 1.38s\tremaining: 9s\n",
      "133:\tlearn: 0.5413087\ttotal: 1.39s\tremaining: 8.98s\n",
      "134:\tlearn: 0.5407705\ttotal: 1.4s\tremaining: 8.97s\n",
      "135:\tlearn: 0.5401641\ttotal: 1.41s\tremaining: 8.97s\n",
      "136:\tlearn: 0.5395861\ttotal: 1.42s\tremaining: 8.96s\n",
      "137:\tlearn: 0.5390421\ttotal: 1.43s\tremaining: 8.94s\n",
      "138:\tlearn: 0.5384387\ttotal: 1.44s\tremaining: 8.93s\n",
      "139:\tlearn: 0.5378828\ttotal: 1.45s\tremaining: 8.92s\n",
      "140:\tlearn: 0.5372731\ttotal: 1.46s\tremaining: 8.9s\n",
      "141:\tlearn: 0.5366479\ttotal: 1.47s\tremaining: 8.89s\n",
      "142:\tlearn: 0.5360524\ttotal: 1.49s\tremaining: 8.93s\n",
      "143:\tlearn: 0.5355106\ttotal: 1.51s\tremaining: 8.96s\n",
      "144:\tlearn: 0.5350238\ttotal: 1.53s\tremaining: 9.04s\n",
      "145:\tlearn: 0.5345358\ttotal: 1.55s\tremaining: 9.05s\n",
      "146:\tlearn: 0.5340238\ttotal: 1.56s\tremaining: 9.04s\n",
      "147:\tlearn: 0.5335167\ttotal: 1.57s\tremaining: 9.02s\n",
      "148:\tlearn: 0.5330176\ttotal: 1.58s\tremaining: 9.01s\n",
      "149:\tlearn: 0.5324508\ttotal: 1.58s\tremaining: 8.98s\n",
      "150:\tlearn: 0.5319086\ttotal: 1.59s\tremaining: 8.96s\n",
      "151:\tlearn: 0.5314184\ttotal: 1.6s\tremaining: 8.95s\n",
      "152:\tlearn: 0.5308819\ttotal: 1.61s\tremaining: 8.92s\n",
      "153:\tlearn: 0.5302823\ttotal: 1.62s\tremaining: 8.9s\n",
      "154:\tlearn: 0.5297015\ttotal: 1.63s\tremaining: 8.89s\n",
      "155:\tlearn: 0.5291087\ttotal: 1.64s\tremaining: 8.88s\n",
      "156:\tlearn: 0.5285739\ttotal: 1.65s\tremaining: 8.87s\n",
      "157:\tlearn: 0.5279702\ttotal: 1.66s\tremaining: 8.85s\n",
      "158:\tlearn: 0.5274172\ttotal: 1.67s\tremaining: 8.84s\n",
      "159:\tlearn: 0.5268812\ttotal: 1.68s\tremaining: 8.82s\n",
      "160:\tlearn: 0.5263349\ttotal: 1.69s\tremaining: 8.82s\n",
      "161:\tlearn: 0.5257592\ttotal: 1.7s\tremaining: 8.82s\n",
      "162:\tlearn: 0.5252456\ttotal: 1.71s\tremaining: 8.8s\n",
      "163:\tlearn: 0.5246580\ttotal: 1.72s\tremaining: 8.79s\n",
      "164:\tlearn: 0.5241200\ttotal: 1.73s\tremaining: 8.77s\n",
      "165:\tlearn: 0.5236388\ttotal: 1.74s\tremaining: 8.76s\n",
      "166:\tlearn: 0.5231022\ttotal: 1.75s\tremaining: 8.74s\n",
      "167:\tlearn: 0.5225862\ttotal: 1.76s\tremaining: 8.72s\n",
      "168:\tlearn: 0.5220765\ttotal: 1.77s\tremaining: 8.71s\n",
      "169:\tlearn: 0.5215654\ttotal: 1.78s\tremaining: 8.7s\n",
      "170:\tlearn: 0.5210190\ttotal: 1.79s\tremaining: 8.68s\n",
      "171:\tlearn: 0.5204894\ttotal: 1.8s\tremaining: 8.67s\n",
      "172:\tlearn: 0.5200162\ttotal: 1.81s\tremaining: 8.65s\n",
      "173:\tlearn: 0.5195292\ttotal: 1.82s\tremaining: 8.64s\n",
      "174:\tlearn: 0.5189716\ttotal: 1.83s\tremaining: 8.62s\n",
      "175:\tlearn: 0.5185635\ttotal: 1.84s\tremaining: 8.61s\n",
      "176:\tlearn: 0.5180387\ttotal: 1.85s\tremaining: 8.59s\n",
      "177:\tlearn: 0.5175349\ttotal: 1.86s\tremaining: 8.57s\n",
      "178:\tlearn: 0.5170244\ttotal: 1.87s\tremaining: 8.56s\n",
      "179:\tlearn: 0.5165442\ttotal: 1.88s\tremaining: 8.55s\n",
      "180:\tlearn: 0.5160466\ttotal: 1.89s\tremaining: 8.54s\n",
      "181:\tlearn: 0.5156241\ttotal: 1.9s\tremaining: 8.52s\n",
      "182:\tlearn: 0.5151119\ttotal: 1.9s\tremaining: 8.5s\n",
      "183:\tlearn: 0.5146500\ttotal: 1.91s\tremaining: 8.49s\n",
      "184:\tlearn: 0.5141525\ttotal: 1.92s\tremaining: 8.47s\n",
      "185:\tlearn: 0.5137101\ttotal: 1.93s\tremaining: 8.46s\n",
      "186:\tlearn: 0.5132302\ttotal: 1.94s\tremaining: 8.45s\n",
      "187:\tlearn: 0.5127806\ttotal: 1.95s\tremaining: 8.43s\n",
      "188:\tlearn: 0.5123637\ttotal: 1.96s\tremaining: 8.42s\n",
      "189:\tlearn: 0.5118995\ttotal: 1.97s\tremaining: 8.4s\n",
      "190:\tlearn: 0.5114445\ttotal: 1.98s\tremaining: 8.39s\n",
      "191:\tlearn: 0.5109492\ttotal: 1.99s\tremaining: 8.37s\n",
      "192:\tlearn: 0.5104843\ttotal: 2s\tremaining: 8.36s\n",
      "193:\tlearn: 0.5100180\ttotal: 2.01s\tremaining: 8.35s\n",
      "194:\tlearn: 0.5095746\ttotal: 2.02s\tremaining: 8.33s\n",
      "195:\tlearn: 0.5091315\ttotal: 2.03s\tremaining: 8.31s\n",
      "196:\tlearn: 0.5086825\ttotal: 2.04s\tremaining: 8.3s\n",
      "197:\tlearn: 0.5082609\ttotal: 2.05s\tremaining: 8.29s\n",
      "198:\tlearn: 0.5077904\ttotal: 2.06s\tremaining: 8.27s\n",
      "199:\tlearn: 0.5073579\ttotal: 2.06s\tremaining: 8.26s\n",
      "200:\tlearn: 0.5069564\ttotal: 2.07s\tremaining: 8.24s\n",
      "201:\tlearn: 0.5065312\ttotal: 2.08s\tremaining: 8.23s\n",
      "202:\tlearn: 0.5060745\ttotal: 2.09s\tremaining: 8.22s\n",
      "203:\tlearn: 0.5056228\ttotal: 2.1s\tremaining: 8.21s\n",
      "204:\tlearn: 0.5051667\ttotal: 2.11s\tremaining: 8.19s\n",
      "205:\tlearn: 0.5047692\ttotal: 2.12s\tremaining: 8.18s\n",
      "206:\tlearn: 0.5043048\ttotal: 2.13s\tremaining: 8.16s\n",
      "207:\tlearn: 0.5038734\ttotal: 2.14s\tremaining: 8.15s\n",
      "208:\tlearn: 0.5034470\ttotal: 2.15s\tremaining: 8.13s\n",
      "209:\tlearn: 0.5030467\ttotal: 2.16s\tremaining: 8.12s\n",
      "210:\tlearn: 0.5025950\ttotal: 2.17s\tremaining: 8.1s\n",
      "211:\tlearn: 0.5021870\ttotal: 2.18s\tremaining: 8.09s\n",
      "212:\tlearn: 0.5017497\ttotal: 2.19s\tremaining: 8.08s\n",
      "213:\tlearn: 0.5013674\ttotal: 2.2s\tremaining: 8.07s\n",
      "214:\tlearn: 0.5009521\ttotal: 2.21s\tremaining: 8.05s\n",
      "215:\tlearn: 0.5005625\ttotal: 2.21s\tremaining: 8.04s\n",
      "216:\tlearn: 0.5001308\ttotal: 2.22s\tremaining: 8.03s\n",
      "217:\tlearn: 0.4996812\ttotal: 2.23s\tremaining: 8.01s\n",
      "218:\tlearn: 0.4992793\ttotal: 2.24s\tremaining: 8s\n",
      "219:\tlearn: 0.4988696\ttotal: 2.25s\tremaining: 7.99s\n",
      "220:\tlearn: 0.4984778\ttotal: 2.26s\tremaining: 7.98s\n",
      "221:\tlearn: 0.4980552\ttotal: 2.27s\tremaining: 7.97s\n",
      "222:\tlearn: 0.4977004\ttotal: 2.28s\tremaining: 7.95s\n",
      "223:\tlearn: 0.4973194\ttotal: 2.29s\tremaining: 7.94s\n",
      "224:\tlearn: 0.4969143\ttotal: 2.3s\tremaining: 7.92s\n",
      "225:\tlearn: 0.4964950\ttotal: 2.31s\tremaining: 7.91s\n",
      "226:\tlearn: 0.4960847\ttotal: 2.32s\tremaining: 7.9s\n",
      "227:\tlearn: 0.4956685\ttotal: 2.33s\tremaining: 7.88s\n",
      "228:\tlearn: 0.4952436\ttotal: 2.34s\tremaining: 7.87s\n",
      "229:\tlearn: 0.4947826\ttotal: 2.35s\tremaining: 7.86s\n",
      "230:\tlearn: 0.4944040\ttotal: 2.36s\tremaining: 7.84s\n",
      "231:\tlearn: 0.4939945\ttotal: 2.37s\tremaining: 7.83s\n",
      "232:\tlearn: 0.4936057\ttotal: 2.37s\tremaining: 7.82s\n",
      "233:\tlearn: 0.4932408\ttotal: 2.38s\tremaining: 7.8s\n",
      "234:\tlearn: 0.4928421\ttotal: 2.39s\tremaining: 7.79s\n",
      "235:\tlearn: 0.4924095\ttotal: 2.4s\tremaining: 7.79s\n",
      "236:\tlearn: 0.4920403\ttotal: 2.44s\tremaining: 7.87s\n",
      "237:\tlearn: 0.4916430\ttotal: 2.48s\tremaining: 7.94s\n",
      "238:\tlearn: 0.4912533\ttotal: 2.52s\tremaining: 8.02s\n",
      "239:\tlearn: 0.4908505\ttotal: 2.53s\tremaining: 8.03s\n",
      "240:\tlearn: 0.4904011\ttotal: 2.55s\tremaining: 8.03s\n",
      "241:\tlearn: 0.4899674\ttotal: 2.56s\tremaining: 8.03s\n",
      "242:\tlearn: 0.4895744\ttotal: 2.57s\tremaining: 8.01s\n",
      "243:\tlearn: 0.4891940\ttotal: 2.58s\tremaining: 8s\n",
      "244:\tlearn: 0.4887642\ttotal: 2.59s\tremaining: 7.99s\n",
      "245:\tlearn: 0.4883501\ttotal: 2.6s\tremaining: 7.97s\n",
      "246:\tlearn: 0.4879449\ttotal: 2.61s\tremaining: 7.96s\n",
      "247:\tlearn: 0.4875381\ttotal: 2.62s\tremaining: 7.95s\n",
      "248:\tlearn: 0.4871410\ttotal: 2.63s\tremaining: 7.93s\n",
      "249:\tlearn: 0.4867463\ttotal: 2.64s\tremaining: 7.92s\n",
      "250:\tlearn: 0.4863439\ttotal: 2.65s\tremaining: 7.91s\n",
      "251:\tlearn: 0.4859558\ttotal: 2.66s\tremaining: 7.89s\n",
      "252:\tlearn: 0.4856099\ttotal: 2.67s\tremaining: 7.88s\n",
      "253:\tlearn: 0.4852092\ttotal: 2.68s\tremaining: 7.87s\n",
      "254:\tlearn: 0.4848227\ttotal: 2.69s\tremaining: 7.86s\n",
      "255:\tlearn: 0.4844230\ttotal: 2.7s\tremaining: 7.85s\n",
      "256:\tlearn: 0.4840354\ttotal: 2.71s\tremaining: 7.85s\n",
      "257:\tlearn: 0.4836245\ttotal: 2.73s\tremaining: 7.84s\n",
      "258:\tlearn: 0.4832711\ttotal: 2.74s\tremaining: 7.84s\n",
      "259:\tlearn: 0.4828755\ttotal: 2.75s\tremaining: 7.83s\n",
      "260:\tlearn: 0.4824912\ttotal: 2.76s\tremaining: 7.83s\n",
      "261:\tlearn: 0.4821047\ttotal: 2.78s\tremaining: 7.82s\n",
      "262:\tlearn: 0.4816835\ttotal: 2.8s\tremaining: 7.84s\n",
      "263:\tlearn: 0.4812876\ttotal: 2.81s\tremaining: 7.83s\n",
      "264:\tlearn: 0.4808880\ttotal: 2.82s\tremaining: 7.81s\n",
      "265:\tlearn: 0.4804823\ttotal: 2.83s\tremaining: 7.8s\n",
      "266:\tlearn: 0.4800791\ttotal: 2.84s\tremaining: 7.79s\n",
      "267:\tlearn: 0.4796877\ttotal: 2.85s\tremaining: 7.79s\n",
      "268:\tlearn: 0.4792787\ttotal: 2.86s\tremaining: 7.78s\n",
      "269:\tlearn: 0.4788867\ttotal: 2.87s\tremaining: 7.77s\n",
      "270:\tlearn: 0.4785126\ttotal: 2.88s\tremaining: 7.76s\n",
      "271:\tlearn: 0.4780946\ttotal: 2.89s\tremaining: 7.74s\n",
      "272:\tlearn: 0.4777348\ttotal: 2.9s\tremaining: 7.73s\n",
      "273:\tlearn: 0.4773350\ttotal: 2.91s\tremaining: 7.72s\n",
      "274:\tlearn: 0.4769645\ttotal: 2.92s\tremaining: 7.71s\n",
      "275:\tlearn: 0.4765917\ttotal: 2.94s\tremaining: 7.7s\n",
      "276:\tlearn: 0.4761930\ttotal: 2.95s\tremaining: 7.69s\n",
      "277:\tlearn: 0.4758167\ttotal: 2.96s\tremaining: 7.68s\n",
      "278:\tlearn: 0.4754373\ttotal: 2.96s\tremaining: 7.66s\n",
      "279:\tlearn: 0.4750983\ttotal: 2.98s\tremaining: 7.65s\n",
      "280:\tlearn: 0.4746830\ttotal: 2.98s\tremaining: 7.64s\n",
      "281:\tlearn: 0.4742973\ttotal: 3s\tremaining: 7.63s\n",
      "282:\tlearn: 0.4738799\ttotal: 3s\tremaining: 7.61s\n",
      "283:\tlearn: 0.4734805\ttotal: 3.02s\tremaining: 7.6s\n",
      "284:\tlearn: 0.4730822\ttotal: 3.02s\tremaining: 7.59s\n",
      "285:\tlearn: 0.4726930\ttotal: 3.04s\tremaining: 7.58s\n",
      "286:\tlearn: 0.4723228\ttotal: 3.04s\tremaining: 7.56s\n",
      "287:\tlearn: 0.4719629\ttotal: 3.05s\tremaining: 7.55s\n",
      "288:\tlearn: 0.4715918\ttotal: 3.06s\tremaining: 7.54s\n",
      "289:\tlearn: 0.4712027\ttotal: 3.07s\tremaining: 7.52s\n",
      "290:\tlearn: 0.4708175\ttotal: 3.08s\tremaining: 7.51s\n",
      "291:\tlearn: 0.4704292\ttotal: 3.09s\tremaining: 7.5s\n",
      "292:\tlearn: 0.4700445\ttotal: 3.1s\tremaining: 7.48s\n",
      "293:\tlearn: 0.4696661\ttotal: 3.11s\tremaining: 7.47s\n",
      "294:\tlearn: 0.4692732\ttotal: 3.12s\tremaining: 7.46s\n",
      "295:\tlearn: 0.4688881\ttotal: 3.13s\tremaining: 7.44s\n",
      "296:\tlearn: 0.4685308\ttotal: 3.14s\tremaining: 7.43s\n",
      "297:\tlearn: 0.4681354\ttotal: 3.15s\tremaining: 7.42s\n",
      "298:\tlearn: 0.4677376\ttotal: 3.16s\tremaining: 7.4s\n",
      "299:\tlearn: 0.4673431\ttotal: 3.17s\tremaining: 7.39s\n",
      "300:\tlearn: 0.4669398\ttotal: 3.18s\tremaining: 7.38s\n",
      "301:\tlearn: 0.4665398\ttotal: 3.19s\tremaining: 7.37s\n",
      "302:\tlearn: 0.4661814\ttotal: 3.2s\tremaining: 7.35s\n",
      "303:\tlearn: 0.4658204\ttotal: 3.21s\tremaining: 7.34s\n",
      "304:\tlearn: 0.4654552\ttotal: 3.21s\tremaining: 7.33s\n",
      "305:\tlearn: 0.4650836\ttotal: 3.23s\tremaining: 7.32s\n",
      "306:\tlearn: 0.4647246\ttotal: 3.24s\tremaining: 7.31s\n",
      "307:\tlearn: 0.4643624\ttotal: 3.25s\tremaining: 7.3s\n",
      "308:\tlearn: 0.4639997\ttotal: 3.26s\tremaining: 7.29s\n",
      "309:\tlearn: 0.4636276\ttotal: 3.27s\tremaining: 7.29s\n",
      "310:\tlearn: 0.4632886\ttotal: 3.28s\tremaining: 7.27s\n",
      "311:\tlearn: 0.4629156\ttotal: 3.29s\tremaining: 7.26s\n",
      "312:\tlearn: 0.4625361\ttotal: 3.3s\tremaining: 7.25s\n",
      "313:\tlearn: 0.4621827\ttotal: 3.31s\tremaining: 7.23s\n",
      "314:\tlearn: 0.4618314\ttotal: 3.32s\tremaining: 7.22s\n",
      "315:\tlearn: 0.4614876\ttotal: 3.33s\tremaining: 7.21s\n",
      "316:\tlearn: 0.4611027\ttotal: 3.34s\tremaining: 7.19s\n",
      "317:\tlearn: 0.4607305\ttotal: 3.35s\tremaining: 7.18s\n",
      "318:\tlearn: 0.4603385\ttotal: 3.36s\tremaining: 7.17s\n",
      "319:\tlearn: 0.4599802\ttotal: 3.37s\tremaining: 7.16s\n",
      "320:\tlearn: 0.4595900\ttotal: 3.38s\tremaining: 7.14s\n",
      "321:\tlearn: 0.4591951\ttotal: 3.39s\tremaining: 7.13s\n",
      "322:\tlearn: 0.4588196\ttotal: 3.4s\tremaining: 7.12s\n",
      "323:\tlearn: 0.4584667\ttotal: 3.41s\tremaining: 7.11s\n",
      "324:\tlearn: 0.4580911\ttotal: 3.42s\tremaining: 7.1s\n",
      "325:\tlearn: 0.4577417\ttotal: 3.43s\tremaining: 7.08s\n",
      "326:\tlearn: 0.4573721\ttotal: 3.44s\tremaining: 7.07s\n",
      "327:\tlearn: 0.4569802\ttotal: 3.44s\tremaining: 7.06s\n",
      "328:\tlearn: 0.4566280\ttotal: 3.45s\tremaining: 7.05s\n",
      "329:\tlearn: 0.4562638\ttotal: 3.46s\tremaining: 7.03s\n",
      "330:\tlearn: 0.4559218\ttotal: 3.48s\tremaining: 7.02s\n",
      "331:\tlearn: 0.4555900\ttotal: 3.48s\tremaining: 7.01s\n",
      "332:\tlearn: 0.4552665\ttotal: 3.49s\tremaining: 7s\n",
      "333:\tlearn: 0.4549292\ttotal: 3.5s\tremaining: 6.99s\n",
      "334:\tlearn: 0.4545825\ttotal: 3.51s\tremaining: 6.97s\n",
      "335:\tlearn: 0.4542252\ttotal: 3.52s\tremaining: 6.96s\n",
      "336:\tlearn: 0.4538806\ttotal: 3.53s\tremaining: 6.95s\n",
      "337:\tlearn: 0.4535222\ttotal: 3.54s\tremaining: 6.93s\n",
      "338:\tlearn: 0.4531778\ttotal: 3.55s\tremaining: 6.92s\n",
      "339:\tlearn: 0.4528334\ttotal: 3.56s\tremaining: 6.91s\n",
      "340:\tlearn: 0.4524701\ttotal: 3.57s\tremaining: 6.9s\n",
      "341:\tlearn: 0.4521370\ttotal: 3.58s\tremaining: 6.89s\n",
      "342:\tlearn: 0.4517747\ttotal: 3.59s\tremaining: 6.88s\n",
      "343:\tlearn: 0.4514104\ttotal: 3.6s\tremaining: 6.87s\n",
      "344:\tlearn: 0.4510730\ttotal: 3.61s\tremaining: 6.86s\n",
      "345:\tlearn: 0.4507498\ttotal: 3.62s\tremaining: 6.85s\n",
      "346:\tlearn: 0.4504000\ttotal: 3.63s\tremaining: 6.84s\n",
      "347:\tlearn: 0.4500717\ttotal: 3.64s\tremaining: 6.83s\n",
      "348:\tlearn: 0.4497275\ttotal: 3.65s\tremaining: 6.82s\n",
      "349:\tlearn: 0.4493649\ttotal: 3.67s\tremaining: 6.81s\n",
      "350:\tlearn: 0.4490455\ttotal: 3.68s\tremaining: 6.8s\n",
      "351:\tlearn: 0.4487001\ttotal: 3.69s\tremaining: 6.79s\n",
      "352:\tlearn: 0.4483828\ttotal: 3.7s\tremaining: 6.78s\n",
      "353:\tlearn: 0.4480529\ttotal: 3.71s\tremaining: 6.77s\n",
      "354:\tlearn: 0.4477262\ttotal: 3.72s\tremaining: 6.76s\n",
      "355:\tlearn: 0.4473801\ttotal: 3.73s\tremaining: 6.75s\n",
      "356:\tlearn: 0.4470511\ttotal: 3.74s\tremaining: 6.74s\n",
      "357:\tlearn: 0.4467209\ttotal: 3.75s\tremaining: 6.73s\n",
      "358:\tlearn: 0.4463881\ttotal: 3.76s\tremaining: 6.72s\n",
      "359:\tlearn: 0.4460487\ttotal: 3.77s\tremaining: 6.71s\n",
      "360:\tlearn: 0.4456922\ttotal: 3.78s\tremaining: 6.7s\n",
      "361:\tlearn: 0.4453670\ttotal: 3.79s\tremaining: 6.69s\n",
      "362:\tlearn: 0.4450328\ttotal: 3.81s\tremaining: 6.68s\n",
      "363:\tlearn: 0.4447246\ttotal: 3.82s\tremaining: 6.67s\n",
      "364:\tlearn: 0.4444067\ttotal: 3.83s\tremaining: 6.66s\n",
      "365:\tlearn: 0.4440660\ttotal: 3.84s\tremaining: 6.65s\n",
      "366:\tlearn: 0.4437495\ttotal: 3.85s\tremaining: 6.64s\n",
      "367:\tlearn: 0.4434168\ttotal: 3.86s\tremaining: 6.63s\n",
      "368:\tlearn: 0.4430939\ttotal: 3.87s\tremaining: 6.62s\n",
      "369:\tlearn: 0.4427421\ttotal: 3.88s\tremaining: 6.61s\n",
      "370:\tlearn: 0.4424017\ttotal: 3.89s\tremaining: 6.6s\n",
      "371:\tlearn: 0.4420711\ttotal: 3.9s\tremaining: 6.59s\n",
      "372:\tlearn: 0.4417557\ttotal: 3.91s\tremaining: 6.58s\n",
      "373:\tlearn: 0.4414086\ttotal: 3.92s\tremaining: 6.57s\n",
      "374:\tlearn: 0.4410815\ttotal: 3.94s\tremaining: 6.56s\n",
      "375:\tlearn: 0.4407645\ttotal: 3.95s\tremaining: 6.55s\n",
      "376:\tlearn: 0.4404417\ttotal: 3.96s\tremaining: 6.54s\n",
      "377:\tlearn: 0.4401353\ttotal: 3.97s\tremaining: 6.53s\n",
      "378:\tlearn: 0.4398078\ttotal: 3.98s\tremaining: 6.52s\n",
      "379:\tlearn: 0.4395024\ttotal: 3.99s\tremaining: 6.5s\n",
      "380:\tlearn: 0.4392140\ttotal: 4s\tremaining: 6.5s\n",
      "381:\tlearn: 0.4389161\ttotal: 4.01s\tremaining: 6.48s\n",
      "382:\tlearn: 0.4385857\ttotal: 4.02s\tremaining: 6.47s\n",
      "383:\tlearn: 0.4382740\ttotal: 4.03s\tremaining: 6.46s\n",
      "384:\tlearn: 0.4379746\ttotal: 4.04s\tremaining: 6.45s\n",
      "385:\tlearn: 0.4376402\ttotal: 4.05s\tremaining: 6.44s\n",
      "386:\tlearn: 0.4373386\ttotal: 4.06s\tremaining: 6.43s\n",
      "387:\tlearn: 0.4370177\ttotal: 4.07s\tremaining: 6.42s\n",
      "388:\tlearn: 0.4366825\ttotal: 4.08s\tremaining: 6.41s\n",
      "389:\tlearn: 0.4363800\ttotal: 4.09s\tremaining: 6.4s\n",
      "390:\tlearn: 0.4360459\ttotal: 4.1s\tremaining: 6.39s\n",
      "391:\tlearn: 0.4357310\ttotal: 4.11s\tremaining: 6.38s\n",
      "392:\tlearn: 0.4354304\ttotal: 4.12s\tremaining: 6.37s\n",
      "393:\tlearn: 0.4351323\ttotal: 4.13s\tremaining: 6.36s\n",
      "394:\tlearn: 0.4348290\ttotal: 4.14s\tremaining: 6.35s\n",
      "395:\tlearn: 0.4345302\ttotal: 4.15s\tremaining: 6.33s\n",
      "396:\tlearn: 0.4342406\ttotal: 4.16s\tremaining: 6.32s\n",
      "397:\tlearn: 0.4339212\ttotal: 4.17s\tremaining: 6.31s\n",
      "398:\tlearn: 0.4336074\ttotal: 4.18s\tremaining: 6.3s\n",
      "399:\tlearn: 0.4333268\ttotal: 4.19s\tremaining: 6.29s\n",
      "400:\tlearn: 0.4330159\ttotal: 4.21s\tremaining: 6.28s\n",
      "401:\tlearn: 0.4327130\ttotal: 4.21s\tremaining: 6.27s\n",
      "402:\tlearn: 0.4323985\ttotal: 4.22s\tremaining: 6.26s\n",
      "403:\tlearn: 0.4320804\ttotal: 4.24s\tremaining: 6.25s\n",
      "404:\tlearn: 0.4317568\ttotal: 4.25s\tremaining: 6.24s\n",
      "405:\tlearn: 0.4314642\ttotal: 4.26s\tremaining: 6.23s\n",
      "406:\tlearn: 0.4311479\ttotal: 4.27s\tremaining: 6.22s\n",
      "407:\tlearn: 0.4308666\ttotal: 4.28s\tremaining: 6.21s\n",
      "408:\tlearn: 0.4305821\ttotal: 4.29s\tremaining: 6.2s\n",
      "409:\tlearn: 0.4302722\ttotal: 4.3s\tremaining: 6.19s\n",
      "410:\tlearn: 0.4299736\ttotal: 4.31s\tremaining: 6.17s\n",
      "411:\tlearn: 0.4296813\ttotal: 4.32s\tremaining: 6.16s\n",
      "412:\tlearn: 0.4293718\ttotal: 4.33s\tremaining: 6.15s\n",
      "413:\tlearn: 0.4290496\ttotal: 4.34s\tremaining: 6.14s\n",
      "414:\tlearn: 0.4287447\ttotal: 4.35s\tremaining: 6.13s\n",
      "415:\tlearn: 0.4284377\ttotal: 4.36s\tremaining: 6.12s\n",
      "416:\tlearn: 0.4281319\ttotal: 4.37s\tremaining: 6.11s\n",
      "417:\tlearn: 0.4278203\ttotal: 4.38s\tremaining: 6.1s\n",
      "418:\tlearn: 0.4275272\ttotal: 4.39s\tremaining: 6.09s\n",
      "419:\tlearn: 0.4272483\ttotal: 4.4s\tremaining: 6.08s\n",
      "420:\tlearn: 0.4269512\ttotal: 4.41s\tremaining: 6.07s\n",
      "421:\tlearn: 0.4266603\ttotal: 4.42s\tremaining: 6.06s\n",
      "422:\tlearn: 0.4263900\ttotal: 4.43s\tremaining: 6.04s\n",
      "423:\tlearn: 0.4260987\ttotal: 4.44s\tremaining: 6.03s\n",
      "424:\tlearn: 0.4258235\ttotal: 4.45s\tremaining: 6.02s\n",
      "425:\tlearn: 0.4255208\ttotal: 4.46s\tremaining: 6.01s\n",
      "426:\tlearn: 0.4252201\ttotal: 4.47s\tremaining: 6s\n",
      "427:\tlearn: 0.4249182\ttotal: 4.48s\tremaining: 5.99s\n",
      "428:\tlearn: 0.4246153\ttotal: 4.49s\tremaining: 5.98s\n",
      "429:\tlearn: 0.4243420\ttotal: 4.5s\tremaining: 5.97s\n",
      "430:\tlearn: 0.4240382\ttotal: 4.51s\tremaining: 5.96s\n",
      "431:\tlearn: 0.4237619\ttotal: 4.52s\tremaining: 5.95s\n",
      "432:\tlearn: 0.4234854\ttotal: 4.53s\tremaining: 5.94s\n",
      "433:\tlearn: 0.4231825\ttotal: 4.54s\tremaining: 5.92s\n",
      "434:\tlearn: 0.4228928\ttotal: 4.55s\tremaining: 5.91s\n",
      "435:\tlearn: 0.4226033\ttotal: 4.56s\tremaining: 5.9s\n",
      "436:\tlearn: 0.4223332\ttotal: 4.57s\tremaining: 5.89s\n",
      "437:\tlearn: 0.4220488\ttotal: 4.58s\tremaining: 5.88s\n",
      "438:\tlearn: 0.4217629\ttotal: 4.59s\tremaining: 5.87s\n",
      "439:\tlearn: 0.4214744\ttotal: 4.6s\tremaining: 5.86s\n",
      "440:\tlearn: 0.4211897\ttotal: 4.61s\tremaining: 5.84s\n",
      "441:\tlearn: 0.4209344\ttotal: 4.62s\tremaining: 5.83s\n",
      "442:\tlearn: 0.4206442\ttotal: 4.63s\tremaining: 5.82s\n",
      "443:\tlearn: 0.4203545\ttotal: 4.64s\tremaining: 5.81s\n",
      "444:\tlearn: 0.4200643\ttotal: 4.65s\tremaining: 5.8s\n",
      "445:\tlearn: 0.4197650\ttotal: 4.66s\tremaining: 5.78s\n",
      "446:\tlearn: 0.4194658\ttotal: 4.67s\tremaining: 5.77s\n",
      "447:\tlearn: 0.4192028\ttotal: 4.67s\tremaining: 5.76s\n",
      "448:\tlearn: 0.4189303\ttotal: 4.68s\tremaining: 5.75s\n",
      "449:\tlearn: 0.4186486\ttotal: 4.7s\tremaining: 5.74s\n",
      "450:\tlearn: 0.4183691\ttotal: 4.71s\tremaining: 5.73s\n",
      "451:\tlearn: 0.4180923\ttotal: 4.71s\tremaining: 5.72s\n",
      "452:\tlearn: 0.4178175\ttotal: 4.72s\tremaining: 5.71s\n",
      "453:\tlearn: 0.4175123\ttotal: 4.73s\tremaining: 5.69s\n",
      "454:\tlearn: 0.4172372\ttotal: 4.74s\tremaining: 5.68s\n",
      "455:\tlearn: 0.4169462\ttotal: 4.75s\tremaining: 5.67s\n",
      "456:\tlearn: 0.4166797\ttotal: 4.76s\tremaining: 5.66s\n",
      "457:\tlearn: 0.4163894\ttotal: 4.77s\tremaining: 5.65s\n",
      "458:\tlearn: 0.4161083\ttotal: 4.78s\tremaining: 5.64s\n",
      "459:\tlearn: 0.4158363\ttotal: 4.79s\tremaining: 5.63s\n",
      "460:\tlearn: 0.4155666\ttotal: 4.8s\tremaining: 5.61s\n",
      "461:\tlearn: 0.4152909\ttotal: 4.81s\tremaining: 5.6s\n",
      "462:\tlearn: 0.4150240\ttotal: 4.82s\tremaining: 5.59s\n",
      "463:\tlearn: 0.4147300\ttotal: 4.83s\tremaining: 5.58s\n",
      "464:\tlearn: 0.4144522\ttotal: 4.84s\tremaining: 5.57s\n",
      "465:\tlearn: 0.4141725\ttotal: 4.85s\tremaining: 5.56s\n",
      "466:\tlearn: 0.4138995\ttotal: 4.86s\tremaining: 5.54s\n",
      "467:\tlearn: 0.4136313\ttotal: 4.87s\tremaining: 5.53s\n",
      "468:\tlearn: 0.4133803\ttotal: 4.88s\tremaining: 5.52s\n",
      "469:\tlearn: 0.4131085\ttotal: 4.88s\tremaining: 5.51s\n",
      "470:\tlearn: 0.4128475\ttotal: 4.89s\tremaining: 5.5s\n",
      "471:\tlearn: 0.4125860\ttotal: 4.9s\tremaining: 5.49s\n",
      "472:\tlearn: 0.4123073\ttotal: 4.91s\tremaining: 5.47s\n",
      "473:\tlearn: 0.4120329\ttotal: 4.92s\tremaining: 5.46s\n",
      "474:\tlearn: 0.4117710\ttotal: 4.93s\tremaining: 5.45s\n",
      "475:\tlearn: 0.4114989\ttotal: 4.94s\tremaining: 5.44s\n",
      "476:\tlearn: 0.4112197\ttotal: 4.95s\tremaining: 5.43s\n",
      "477:\tlearn: 0.4109571\ttotal: 4.96s\tremaining: 5.42s\n",
      "478:\tlearn: 0.4106857\ttotal: 4.97s\tremaining: 5.41s\n",
      "479:\tlearn: 0.4104211\ttotal: 4.98s\tremaining: 5.4s\n",
      "480:\tlearn: 0.4101248\ttotal: 4.99s\tremaining: 5.38s\n",
      "481:\tlearn: 0.4098315\ttotal: 5s\tremaining: 5.37s\n",
      "482:\tlearn: 0.4095611\ttotal: 5.01s\tremaining: 5.36s\n",
      "483:\tlearn: 0.4092897\ttotal: 5.02s\tremaining: 5.35s\n",
      "484:\tlearn: 0.4090397\ttotal: 5.03s\tremaining: 5.34s\n",
      "485:\tlearn: 0.4087632\ttotal: 5.04s\tremaining: 5.33s\n",
      "486:\tlearn: 0.4084958\ttotal: 5.05s\tremaining: 5.32s\n",
      "487:\tlearn: 0.4082309\ttotal: 5.05s\tremaining: 5.3s\n",
      "488:\tlearn: 0.4079897\ttotal: 5.06s\tremaining: 5.29s\n",
      "489:\tlearn: 0.4077262\ttotal: 5.07s\tremaining: 5.28s\n",
      "490:\tlearn: 0.4074679\ttotal: 5.08s\tremaining: 5.27s\n",
      "491:\tlearn: 0.4072011\ttotal: 5.09s\tremaining: 5.26s\n",
      "492:\tlearn: 0.4069394\ttotal: 5.1s\tremaining: 5.25s\n",
      "493:\tlearn: 0.4066813\ttotal: 5.11s\tremaining: 5.24s\n",
      "494:\tlearn: 0.4064312\ttotal: 5.12s\tremaining: 5.23s\n",
      "495:\tlearn: 0.4061487\ttotal: 5.13s\tremaining: 5.21s\n",
      "496:\tlearn: 0.4058992\ttotal: 5.14s\tremaining: 5.2s\n",
      "497:\tlearn: 0.4056354\ttotal: 5.15s\tremaining: 5.19s\n",
      "498:\tlearn: 0.4053695\ttotal: 5.16s\tremaining: 5.18s\n",
      "499:\tlearn: 0.4051288\ttotal: 5.17s\tremaining: 5.17s\n",
      "500:\tlearn: 0.4048565\ttotal: 5.18s\tremaining: 5.16s\n",
      "501:\tlearn: 0.4046211\ttotal: 5.19s\tremaining: 5.15s\n",
      "502:\tlearn: 0.4043690\ttotal: 5.2s\tremaining: 5.13s\n",
      "503:\tlearn: 0.4040947\ttotal: 5.21s\tremaining: 5.12s\n",
      "504:\tlearn: 0.4038530\ttotal: 5.22s\tremaining: 5.11s\n",
      "505:\tlearn: 0.4035987\ttotal: 5.22s\tremaining: 5.1s\n",
      "506:\tlearn: 0.4033666\ttotal: 5.24s\tremaining: 5.09s\n",
      "507:\tlearn: 0.4031133\ttotal: 5.24s\tremaining: 5.08s\n",
      "508:\tlearn: 0.4028331\ttotal: 5.25s\tremaining: 5.07s\n",
      "509:\tlearn: 0.4025665\ttotal: 5.26s\tremaining: 5.06s\n",
      "510:\tlearn: 0.4023134\ttotal: 5.27s\tremaining: 5.05s\n",
      "511:\tlearn: 0.4020523\ttotal: 5.28s\tremaining: 5.03s\n",
      "512:\tlearn: 0.4017854\ttotal: 5.29s\tremaining: 5.02s\n",
      "513:\tlearn: 0.4015497\ttotal: 5.3s\tremaining: 5.01s\n",
      "514:\tlearn: 0.4013214\ttotal: 5.31s\tremaining: 5s\n",
      "515:\tlearn: 0.4010400\ttotal: 5.32s\tremaining: 4.99s\n",
      "516:\tlearn: 0.4007765\ttotal: 5.33s\tremaining: 4.98s\n",
      "517:\tlearn: 0.4005373\ttotal: 5.34s\tremaining: 4.97s\n",
      "518:\tlearn: 0.4002761\ttotal: 5.35s\tremaining: 4.96s\n",
      "519:\tlearn: 0.4000132\ttotal: 5.36s\tremaining: 4.95s\n",
      "520:\tlearn: 0.3997735\ttotal: 5.37s\tremaining: 4.94s\n",
      "521:\tlearn: 0.3995193\ttotal: 5.38s\tremaining: 4.92s\n",
      "522:\tlearn: 0.3992853\ttotal: 5.39s\tremaining: 4.91s\n",
      "523:\tlearn: 0.3990478\ttotal: 5.4s\tremaining: 4.9s\n",
      "524:\tlearn: 0.3988010\ttotal: 5.41s\tremaining: 4.89s\n",
      "525:\tlearn: 0.3985652\ttotal: 5.42s\tremaining: 4.88s\n",
      "526:\tlearn: 0.3983147\ttotal: 5.42s\tremaining: 4.87s\n",
      "527:\tlearn: 0.3980588\ttotal: 5.43s\tremaining: 4.86s\n",
      "528:\tlearn: 0.3978175\ttotal: 5.44s\tremaining: 4.85s\n",
      "529:\tlearn: 0.3975838\ttotal: 5.45s\tremaining: 4.84s\n",
      "530:\tlearn: 0.3973523\ttotal: 5.46s\tremaining: 4.82s\n",
      "531:\tlearn: 0.3971169\ttotal: 5.47s\tremaining: 4.81s\n",
      "532:\tlearn: 0.3968920\ttotal: 5.48s\tremaining: 4.8s\n",
      "533:\tlearn: 0.3966444\ttotal: 5.49s\tremaining: 4.79s\n",
      "534:\tlearn: 0.3964011\ttotal: 5.5s\tremaining: 4.78s\n",
      "535:\tlearn: 0.3961360\ttotal: 5.51s\tremaining: 4.77s\n",
      "536:\tlearn: 0.3958757\ttotal: 5.52s\tremaining: 4.76s\n",
      "537:\tlearn: 0.3956414\ttotal: 5.53s\tremaining: 4.75s\n",
      "538:\tlearn: 0.3953846\ttotal: 5.54s\tremaining: 4.74s\n",
      "539:\tlearn: 0.3951321\ttotal: 5.55s\tremaining: 4.73s\n",
      "540:\tlearn: 0.3948829\ttotal: 5.56s\tremaining: 4.72s\n",
      "541:\tlearn: 0.3946258\ttotal: 5.57s\tremaining: 4.71s\n",
      "542:\tlearn: 0.3943870\ttotal: 5.58s\tremaining: 4.7s\n",
      "543:\tlearn: 0.3941431\ttotal: 5.59s\tremaining: 4.68s\n",
      "544:\tlearn: 0.3938971\ttotal: 5.6s\tremaining: 4.67s\n",
      "545:\tlearn: 0.3936639\ttotal: 5.61s\tremaining: 4.66s\n",
      "546:\tlearn: 0.3934367\ttotal: 5.62s\tremaining: 4.65s\n",
      "547:\tlearn: 0.3931931\ttotal: 5.63s\tremaining: 4.64s\n",
      "548:\tlearn: 0.3929381\ttotal: 5.63s\tremaining: 4.63s\n",
      "549:\tlearn: 0.3926994\ttotal: 5.64s\tremaining: 4.62s\n",
      "550:\tlearn: 0.3924692\ttotal: 5.65s\tremaining: 4.61s\n",
      "551:\tlearn: 0.3922109\ttotal: 5.66s\tremaining: 4.6s\n",
      "552:\tlearn: 0.3919686\ttotal: 5.67s\tremaining: 4.59s\n",
      "553:\tlearn: 0.3917316\ttotal: 5.68s\tremaining: 4.58s\n",
      "554:\tlearn: 0.3915118\ttotal: 5.69s\tremaining: 4.56s\n",
      "555:\tlearn: 0.3912581\ttotal: 5.7s\tremaining: 4.55s\n",
      "556:\tlearn: 0.3910237\ttotal: 5.71s\tremaining: 4.54s\n",
      "557:\tlearn: 0.3907598\ttotal: 5.72s\tremaining: 4.53s\n",
      "558:\tlearn: 0.3905130\ttotal: 5.73s\tremaining: 4.52s\n",
      "559:\tlearn: 0.3902774\ttotal: 5.74s\tremaining: 4.51s\n",
      "560:\tlearn: 0.3900429\ttotal: 5.75s\tremaining: 4.5s\n",
      "561:\tlearn: 0.3897959\ttotal: 5.76s\tremaining: 4.49s\n",
      "562:\tlearn: 0.3895590\ttotal: 5.77s\tremaining: 4.48s\n",
      "563:\tlearn: 0.3893348\ttotal: 5.78s\tremaining: 4.47s\n",
      "564:\tlearn: 0.3890628\ttotal: 5.79s\tremaining: 4.46s\n",
      "565:\tlearn: 0.3888328\ttotal: 5.8s\tremaining: 4.45s\n",
      "566:\tlearn: 0.3885847\ttotal: 5.81s\tremaining: 4.44s\n",
      "567:\tlearn: 0.3883619\ttotal: 5.82s\tremaining: 4.43s\n",
      "568:\tlearn: 0.3881403\ttotal: 5.83s\tremaining: 4.42s\n",
      "569:\tlearn: 0.3878978\ttotal: 5.84s\tremaining: 4.41s\n",
      "570:\tlearn: 0.3876643\ttotal: 5.85s\tremaining: 4.39s\n",
      "571:\tlearn: 0.3874077\ttotal: 5.86s\tremaining: 4.38s\n",
      "572:\tlearn: 0.3871803\ttotal: 5.87s\tremaining: 4.37s\n",
      "573:\tlearn: 0.3869642\ttotal: 5.88s\tremaining: 4.36s\n",
      "574:\tlearn: 0.3867267\ttotal: 5.89s\tremaining: 4.35s\n",
      "575:\tlearn: 0.3864819\ttotal: 5.9s\tremaining: 4.34s\n",
      "576:\tlearn: 0.3862724\ttotal: 5.91s\tremaining: 4.33s\n",
      "577:\tlearn: 0.3860249\ttotal: 5.92s\tremaining: 4.32s\n",
      "578:\tlearn: 0.3857991\ttotal: 5.93s\tremaining: 4.31s\n",
      "579:\tlearn: 0.3855689\ttotal: 5.94s\tremaining: 4.3s\n",
      "580:\tlearn: 0.3853676\ttotal: 5.95s\tremaining: 4.29s\n",
      "581:\tlearn: 0.3851346\ttotal: 5.96s\tremaining: 4.28s\n",
      "582:\tlearn: 0.3849246\ttotal: 5.97s\tremaining: 4.27s\n",
      "583:\tlearn: 0.3846766\ttotal: 5.98s\tremaining: 4.26s\n",
      "584:\tlearn: 0.3844407\ttotal: 5.99s\tremaining: 4.25s\n",
      "585:\tlearn: 0.3842299\ttotal: 6s\tremaining: 4.24s\n",
      "586:\tlearn: 0.3839842\ttotal: 6.01s\tremaining: 4.23s\n",
      "587:\tlearn: 0.3837712\ttotal: 6.02s\tremaining: 4.22s\n",
      "588:\tlearn: 0.3835411\ttotal: 6.03s\tremaining: 4.21s\n",
      "589:\tlearn: 0.3833169\ttotal: 6.04s\tremaining: 4.2s\n",
      "590:\tlearn: 0.3831005\ttotal: 6.05s\tremaining: 4.18s\n",
      "591:\tlearn: 0.3828652\ttotal: 6.06s\tremaining: 4.17s\n",
      "592:\tlearn: 0.3826352\ttotal: 6.07s\tremaining: 4.16s\n",
      "593:\tlearn: 0.3823966\ttotal: 6.07s\tremaining: 4.15s\n",
      "594:\tlearn: 0.3821528\ttotal: 6.08s\tremaining: 4.14s\n",
      "595:\tlearn: 0.3819138\ttotal: 6.09s\tremaining: 4.13s\n",
      "596:\tlearn: 0.3817025\ttotal: 6.1s\tremaining: 4.12s\n",
      "597:\tlearn: 0.3814649\ttotal: 6.11s\tremaining: 4.11s\n",
      "598:\tlearn: 0.3812290\ttotal: 6.12s\tremaining: 4.1s\n",
      "599:\tlearn: 0.3810132\ttotal: 6.13s\tremaining: 4.09s\n",
      "600:\tlearn: 0.3807873\ttotal: 6.15s\tremaining: 4.08s\n",
      "601:\tlearn: 0.3805616\ttotal: 6.17s\tremaining: 4.08s\n",
      "602:\tlearn: 0.3803484\ttotal: 6.18s\tremaining: 4.07s\n",
      "603:\tlearn: 0.3801238\ttotal: 6.19s\tremaining: 4.06s\n",
      "604:\tlearn: 0.3799168\ttotal: 6.2s\tremaining: 4.05s\n",
      "605:\tlearn: 0.3797067\ttotal: 6.21s\tremaining: 4.04s\n",
      "606:\tlearn: 0.3794988\ttotal: 6.22s\tremaining: 4.03s\n",
      "607:\tlearn: 0.3793007\ttotal: 6.23s\tremaining: 4.02s\n",
      "608:\tlearn: 0.3790882\ttotal: 6.24s\tremaining: 4.01s\n",
      "609:\tlearn: 0.3788611\ttotal: 6.25s\tremaining: 4s\n",
      "610:\tlearn: 0.3786307\ttotal: 6.27s\tremaining: 3.99s\n",
      "611:\tlearn: 0.3783732\ttotal: 6.28s\tremaining: 3.98s\n",
      "612:\tlearn: 0.3781625\ttotal: 6.29s\tremaining: 3.97s\n",
      "613:\tlearn: 0.3779332\ttotal: 6.3s\tremaining: 3.96s\n",
      "614:\tlearn: 0.3777301\ttotal: 6.31s\tremaining: 3.95s\n",
      "615:\tlearn: 0.3775062\ttotal: 6.32s\tremaining: 3.94s\n",
      "616:\tlearn: 0.3772828\ttotal: 6.33s\tremaining: 3.93s\n",
      "617:\tlearn: 0.3770900\ttotal: 6.34s\tremaining: 3.92s\n",
      "618:\tlearn: 0.3768399\ttotal: 6.35s\tremaining: 3.91s\n",
      "619:\tlearn: 0.3766058\ttotal: 6.36s\tremaining: 3.9s\n",
      "620:\tlearn: 0.3763685\ttotal: 6.37s\tremaining: 3.89s\n",
      "621:\tlearn: 0.3761327\ttotal: 6.38s\tremaining: 3.88s\n",
      "622:\tlearn: 0.3759192\ttotal: 6.39s\tremaining: 3.87s\n",
      "623:\tlearn: 0.3757030\ttotal: 6.41s\tremaining: 3.86s\n",
      "624:\tlearn: 0.3754924\ttotal: 6.41s\tremaining: 3.85s\n",
      "625:\tlearn: 0.3752656\ttotal: 6.42s\tremaining: 3.84s\n",
      "626:\tlearn: 0.3750495\ttotal: 6.43s\tremaining: 3.83s\n",
      "627:\tlearn: 0.3748109\ttotal: 6.44s\tremaining: 3.82s\n",
      "628:\tlearn: 0.3745951\ttotal: 6.45s\tremaining: 3.81s\n",
      "629:\tlearn: 0.3743638\ttotal: 6.46s\tremaining: 3.79s\n",
      "630:\tlearn: 0.3741780\ttotal: 6.47s\tremaining: 3.78s\n",
      "631:\tlearn: 0.3739740\ttotal: 6.48s\tremaining: 3.77s\n",
      "632:\tlearn: 0.3737526\ttotal: 6.49s\tremaining: 3.76s\n",
      "633:\tlearn: 0.3735213\ttotal: 6.5s\tremaining: 3.75s\n",
      "634:\tlearn: 0.3732957\ttotal: 6.51s\tremaining: 3.74s\n",
      "635:\tlearn: 0.3730701\ttotal: 6.52s\tremaining: 3.73s\n",
      "636:\tlearn: 0.3728678\ttotal: 6.53s\tremaining: 3.72s\n",
      "637:\tlearn: 0.3726232\ttotal: 6.54s\tremaining: 3.71s\n",
      "638:\tlearn: 0.3724031\ttotal: 6.55s\tremaining: 3.7s\n",
      "639:\tlearn: 0.3721752\ttotal: 6.56s\tremaining: 3.69s\n",
      "640:\tlearn: 0.3719502\ttotal: 6.57s\tremaining: 3.68s\n",
      "641:\tlearn: 0.3717323\ttotal: 6.58s\tremaining: 3.67s\n",
      "642:\tlearn: 0.3715317\ttotal: 6.58s\tremaining: 3.66s\n",
      "643:\tlearn: 0.3713006\ttotal: 6.59s\tremaining: 3.65s\n",
      "644:\tlearn: 0.3711092\ttotal: 6.61s\tremaining: 3.63s\n",
      "645:\tlearn: 0.3708841\ttotal: 6.62s\tremaining: 3.63s\n",
      "646:\tlearn: 0.3706930\ttotal: 6.63s\tremaining: 3.62s\n",
      "647:\tlearn: 0.3704932\ttotal: 6.64s\tremaining: 3.6s\n",
      "648:\tlearn: 0.3702837\ttotal: 6.65s\tremaining: 3.6s\n",
      "649:\tlearn: 0.3700851\ttotal: 6.66s\tremaining: 3.58s\n",
      "650:\tlearn: 0.3698764\ttotal: 6.67s\tremaining: 3.57s\n",
      "651:\tlearn: 0.3696694\ttotal: 6.68s\tremaining: 3.56s\n",
      "652:\tlearn: 0.3694644\ttotal: 6.69s\tremaining: 3.55s\n",
      "653:\tlearn: 0.3692625\ttotal: 6.7s\tremaining: 3.54s\n",
      "654:\tlearn: 0.3690514\ttotal: 6.71s\tremaining: 3.53s\n",
      "655:\tlearn: 0.3688231\ttotal: 6.72s\tremaining: 3.52s\n",
      "656:\tlearn: 0.3686389\ttotal: 6.73s\tremaining: 3.51s\n",
      "657:\tlearn: 0.3684472\ttotal: 6.74s\tremaining: 3.5s\n",
      "658:\tlearn: 0.3682339\ttotal: 6.75s\tremaining: 3.49s\n",
      "659:\tlearn: 0.3680271\ttotal: 6.76s\tremaining: 3.48s\n",
      "660:\tlearn: 0.3678110\ttotal: 6.77s\tremaining: 3.47s\n",
      "661:\tlearn: 0.3675666\ttotal: 6.78s\tremaining: 3.46s\n",
      "662:\tlearn: 0.3673407\ttotal: 6.79s\tremaining: 3.45s\n",
      "663:\tlearn: 0.3671421\ttotal: 6.8s\tremaining: 3.44s\n",
      "664:\tlearn: 0.3669272\ttotal: 6.81s\tremaining: 3.43s\n",
      "665:\tlearn: 0.3666967\ttotal: 6.82s\tremaining: 3.42s\n",
      "666:\tlearn: 0.3664826\ttotal: 6.83s\tremaining: 3.41s\n",
      "667:\tlearn: 0.3662578\ttotal: 6.84s\tremaining: 3.4s\n",
      "668:\tlearn: 0.3660710\ttotal: 6.85s\tremaining: 3.39s\n",
      "669:\tlearn: 0.3658521\ttotal: 6.86s\tremaining: 3.38s\n",
      "670:\tlearn: 0.3656606\ttotal: 6.87s\tremaining: 3.37s\n",
      "671:\tlearn: 0.3654443\ttotal: 6.88s\tremaining: 3.36s\n",
      "672:\tlearn: 0.3652220\ttotal: 6.89s\tremaining: 3.35s\n",
      "673:\tlearn: 0.3650188\ttotal: 6.9s\tremaining: 3.34s\n",
      "674:\tlearn: 0.3647897\ttotal: 6.91s\tremaining: 3.33s\n",
      "675:\tlearn: 0.3645786\ttotal: 6.92s\tremaining: 3.31s\n",
      "676:\tlearn: 0.3643670\ttotal: 6.93s\tremaining: 3.3s\n",
      "677:\tlearn: 0.3641708\ttotal: 6.94s\tremaining: 3.29s\n",
      "678:\tlearn: 0.3639749\ttotal: 6.95s\tremaining: 3.29s\n",
      "679:\tlearn: 0.3637982\ttotal: 6.96s\tremaining: 3.27s\n",
      "680:\tlearn: 0.3635807\ttotal: 6.97s\tremaining: 3.26s\n",
      "681:\tlearn: 0.3633701\ttotal: 6.98s\tremaining: 3.25s\n",
      "682:\tlearn: 0.3631329\ttotal: 6.99s\tremaining: 3.25s\n",
      "683:\tlearn: 0.3629254\ttotal: 7s\tremaining: 3.24s\n",
      "684:\tlearn: 0.3627008\ttotal: 7.02s\tremaining: 3.23s\n",
      "685:\tlearn: 0.3624890\ttotal: 7.03s\tremaining: 3.22s\n",
      "686:\tlearn: 0.3622910\ttotal: 7.04s\tremaining: 3.21s\n",
      "687:\tlearn: 0.3620816\ttotal: 7.05s\tremaining: 3.2s\n",
      "688:\tlearn: 0.3618660\ttotal: 7.06s\tremaining: 3.19s\n",
      "689:\tlearn: 0.3617017\ttotal: 7.07s\tremaining: 3.18s\n",
      "690:\tlearn: 0.3615046\ttotal: 7.08s\tremaining: 3.17s\n",
      "691:\tlearn: 0.3613153\ttotal: 7.09s\tremaining: 3.16s\n",
      "692:\tlearn: 0.3611074\ttotal: 7.1s\tremaining: 3.15s\n",
      "693:\tlearn: 0.3609144\ttotal: 7.11s\tremaining: 3.14s\n",
      "694:\tlearn: 0.3607007\ttotal: 7.12s\tremaining: 3.13s\n",
      "695:\tlearn: 0.3605115\ttotal: 7.13s\tremaining: 3.12s\n",
      "696:\tlearn: 0.3602955\ttotal: 7.14s\tremaining: 3.1s\n",
      "697:\tlearn: 0.3600894\ttotal: 7.16s\tremaining: 3.1s\n",
      "698:\tlearn: 0.3598971\ttotal: 7.17s\tremaining: 3.08s\n",
      "699:\tlearn: 0.3596991\ttotal: 7.17s\tremaining: 3.08s\n",
      "700:\tlearn: 0.3594680\ttotal: 7.19s\tremaining: 3.06s\n",
      "701:\tlearn: 0.3592602\ttotal: 7.2s\tremaining: 3.06s\n",
      "702:\tlearn: 0.3590527\ttotal: 7.21s\tremaining: 3.04s\n",
      "703:\tlearn: 0.3588619\ttotal: 7.22s\tremaining: 3.03s\n",
      "704:\tlearn: 0.3586810\ttotal: 7.23s\tremaining: 3.02s\n",
      "705:\tlearn: 0.3584768\ttotal: 7.24s\tremaining: 3.01s\n",
      "706:\tlearn: 0.3582525\ttotal: 7.25s\tremaining: 3s\n",
      "707:\tlearn: 0.3580420\ttotal: 7.26s\tremaining: 2.99s\n",
      "708:\tlearn: 0.3578372\ttotal: 7.27s\tremaining: 2.98s\n",
      "709:\tlearn: 0.3576341\ttotal: 7.28s\tremaining: 2.97s\n",
      "710:\tlearn: 0.3574362\ttotal: 7.29s\tremaining: 2.96s\n",
      "711:\tlearn: 0.3572202\ttotal: 7.3s\tremaining: 2.95s\n",
      "712:\tlearn: 0.3570065\ttotal: 7.31s\tremaining: 2.94s\n",
      "713:\tlearn: 0.3568177\ttotal: 7.32s\tremaining: 2.93s\n",
      "714:\tlearn: 0.3566189\ttotal: 7.33s\tremaining: 2.92s\n",
      "715:\tlearn: 0.3564142\ttotal: 7.34s\tremaining: 2.91s\n",
      "716:\tlearn: 0.3562112\ttotal: 7.36s\tremaining: 2.9s\n",
      "717:\tlearn: 0.3560146\ttotal: 7.37s\tremaining: 2.89s\n",
      "718:\tlearn: 0.3558022\ttotal: 7.38s\tremaining: 2.88s\n",
      "719:\tlearn: 0.3555779\ttotal: 7.39s\tremaining: 2.87s\n",
      "720:\tlearn: 0.3553516\ttotal: 7.4s\tremaining: 2.86s\n",
      "721:\tlearn: 0.3551613\ttotal: 7.41s\tremaining: 2.85s\n",
      "722:\tlearn: 0.3549791\ttotal: 7.42s\tremaining: 2.84s\n",
      "723:\tlearn: 0.3547735\ttotal: 7.43s\tremaining: 2.83s\n",
      "724:\tlearn: 0.3545669\ttotal: 7.44s\tremaining: 2.82s\n",
      "725:\tlearn: 0.3543592\ttotal: 7.45s\tremaining: 2.81s\n",
      "726:\tlearn: 0.3541600\ttotal: 7.46s\tremaining: 2.8s\n",
      "727:\tlearn: 0.3539662\ttotal: 7.47s\tremaining: 2.79s\n",
      "728:\tlearn: 0.3537760\ttotal: 7.48s\tremaining: 2.78s\n",
      "729:\tlearn: 0.3535652\ttotal: 7.49s\tremaining: 2.77s\n",
      "730:\tlearn: 0.3533707\ttotal: 7.5s\tremaining: 2.76s\n",
      "731:\tlearn: 0.3531620\ttotal: 7.51s\tremaining: 2.75s\n",
      "732:\tlearn: 0.3529747\ttotal: 7.52s\tremaining: 2.74s\n",
      "733:\tlearn: 0.3527863\ttotal: 7.53s\tremaining: 2.73s\n",
      "734:\tlearn: 0.3525796\ttotal: 7.54s\tremaining: 2.72s\n",
      "735:\tlearn: 0.3524017\ttotal: 7.55s\tremaining: 2.71s\n",
      "736:\tlearn: 0.3522074\ttotal: 7.57s\tremaining: 2.7s\n",
      "737:\tlearn: 0.3519930\ttotal: 7.58s\tremaining: 2.69s\n",
      "738:\tlearn: 0.3517709\ttotal: 7.59s\tremaining: 2.68s\n",
      "739:\tlearn: 0.3515565\ttotal: 7.6s\tremaining: 2.67s\n",
      "740:\tlearn: 0.3513668\ttotal: 7.61s\tremaining: 2.66s\n",
      "741:\tlearn: 0.3511958\ttotal: 7.62s\tremaining: 2.65s\n",
      "742:\tlearn: 0.3510002\ttotal: 7.63s\tremaining: 2.64s\n",
      "743:\tlearn: 0.3508180\ttotal: 7.64s\tremaining: 2.63s\n",
      "744:\tlearn: 0.3505989\ttotal: 7.65s\tremaining: 2.62s\n",
      "745:\tlearn: 0.3504354\ttotal: 7.66s\tremaining: 2.61s\n",
      "746:\tlearn: 0.3502527\ttotal: 7.67s\tremaining: 2.6s\n",
      "747:\tlearn: 0.3500485\ttotal: 7.68s\tremaining: 2.59s\n",
      "748:\tlearn: 0.3498662\ttotal: 7.69s\tremaining: 2.58s\n",
      "749:\tlearn: 0.3496426\ttotal: 7.71s\tremaining: 2.57s\n",
      "750:\tlearn: 0.3494327\ttotal: 7.71s\tremaining: 2.56s\n",
      "751:\tlearn: 0.3492392\ttotal: 7.73s\tremaining: 2.55s\n",
      "752:\tlearn: 0.3490591\ttotal: 7.74s\tremaining: 2.54s\n",
      "753:\tlearn: 0.3488588\ttotal: 7.75s\tremaining: 2.53s\n",
      "754:\tlearn: 0.3486720\ttotal: 7.75s\tremaining: 2.52s\n",
      "755:\tlearn: 0.3484777\ttotal: 7.77s\tremaining: 2.51s\n",
      "756:\tlearn: 0.3482956\ttotal: 7.78s\tremaining: 2.5s\n",
      "757:\tlearn: 0.3480996\ttotal: 7.79s\tremaining: 2.49s\n",
      "758:\tlearn: 0.3478942\ttotal: 7.8s\tremaining: 2.48s\n",
      "759:\tlearn: 0.3477028\ttotal: 7.81s\tremaining: 2.46s\n",
      "760:\tlearn: 0.3475166\ttotal: 7.82s\tremaining: 2.46s\n",
      "761:\tlearn: 0.3473135\ttotal: 7.83s\tremaining: 2.44s\n",
      "762:\tlearn: 0.3471284\ttotal: 7.84s\tremaining: 2.44s\n",
      "763:\tlearn: 0.3469358\ttotal: 7.85s\tremaining: 2.42s\n",
      "764:\tlearn: 0.3467047\ttotal: 7.86s\tremaining: 2.42s\n",
      "765:\tlearn: 0.3465096\ttotal: 7.88s\tremaining: 2.4s\n",
      "766:\tlearn: 0.3463414\ttotal: 7.89s\tremaining: 2.4s\n",
      "767:\tlearn: 0.3461681\ttotal: 7.9s\tremaining: 2.38s\n",
      "768:\tlearn: 0.3459780\ttotal: 7.91s\tremaining: 2.37s\n",
      "769:\tlearn: 0.3458048\ttotal: 7.91s\tremaining: 2.36s\n",
      "770:\tlearn: 0.3456353\ttotal: 7.92s\tremaining: 2.35s\n",
      "771:\tlearn: 0.3454547\ttotal: 7.93s\tremaining: 2.34s\n",
      "772:\tlearn: 0.3452595\ttotal: 7.94s\tremaining: 2.33s\n",
      "773:\tlearn: 0.3450634\ttotal: 7.96s\tremaining: 2.32s\n",
      "774:\tlearn: 0.3448838\ttotal: 7.97s\tremaining: 2.31s\n",
      "775:\tlearn: 0.3447178\ttotal: 7.98s\tremaining: 2.3s\n",
      "776:\tlearn: 0.3445337\ttotal: 7.99s\tremaining: 2.29s\n",
      "777:\tlearn: 0.3443634\ttotal: 8s\tremaining: 2.28s\n",
      "778:\tlearn: 0.3441532\ttotal: 8.02s\tremaining: 2.27s\n",
      "779:\tlearn: 0.3439563\ttotal: 8.03s\tremaining: 2.26s\n",
      "780:\tlearn: 0.3437578\ttotal: 8.04s\tremaining: 2.25s\n",
      "781:\tlearn: 0.3435640\ttotal: 8.05s\tremaining: 2.24s\n",
      "782:\tlearn: 0.3433647\ttotal: 8.06s\tremaining: 2.23s\n",
      "783:\tlearn: 0.3431592\ttotal: 8.07s\tremaining: 2.22s\n",
      "784:\tlearn: 0.3430041\ttotal: 8.08s\tremaining: 2.21s\n",
      "785:\tlearn: 0.3428369\ttotal: 8.09s\tremaining: 2.2s\n",
      "786:\tlearn: 0.3426567\ttotal: 8.1s\tremaining: 2.19s\n",
      "787:\tlearn: 0.3424577\ttotal: 8.11s\tremaining: 2.18s\n",
      "788:\tlearn: 0.3422854\ttotal: 8.12s\tremaining: 2.17s\n",
      "789:\tlearn: 0.3420726\ttotal: 8.13s\tremaining: 2.16s\n",
      "790:\tlearn: 0.3418898\ttotal: 8.14s\tremaining: 2.15s\n",
      "791:\tlearn: 0.3417067\ttotal: 8.15s\tremaining: 2.14s\n",
      "792:\tlearn: 0.3415255\ttotal: 8.16s\tremaining: 2.13s\n",
      "793:\tlearn: 0.3413374\ttotal: 8.17s\tremaining: 2.12s\n",
      "794:\tlearn: 0.3411548\ttotal: 8.18s\tremaining: 2.11s\n",
      "795:\tlearn: 0.3409736\ttotal: 8.19s\tremaining: 2.1s\n",
      "796:\tlearn: 0.3407952\ttotal: 8.2s\tremaining: 2.09s\n",
      "797:\tlearn: 0.3406135\ttotal: 8.21s\tremaining: 2.08s\n",
      "798:\tlearn: 0.3404579\ttotal: 8.22s\tremaining: 2.07s\n",
      "799:\tlearn: 0.3402669\ttotal: 8.27s\tremaining: 2.07s\n",
      "800:\tlearn: 0.3400788\ttotal: 8.29s\tremaining: 2.06s\n",
      "801:\tlearn: 0.3399134\ttotal: 8.3s\tremaining: 2.05s\n",
      "802:\tlearn: 0.3397266\ttotal: 8.31s\tremaining: 2.04s\n",
      "803:\tlearn: 0.3395421\ttotal: 8.32s\tremaining: 2.03s\n",
      "804:\tlearn: 0.3393686\ttotal: 8.33s\tremaining: 2.02s\n",
      "805:\tlearn: 0.3391811\ttotal: 8.34s\tremaining: 2.01s\n",
      "806:\tlearn: 0.3389828\ttotal: 8.35s\tremaining: 2s\n",
      "807:\tlearn: 0.3388000\ttotal: 8.36s\tremaining: 1.99s\n",
      "808:\tlearn: 0.3386322\ttotal: 8.37s\tremaining: 1.98s\n",
      "809:\tlearn: 0.3384458\ttotal: 8.38s\tremaining: 1.97s\n",
      "810:\tlearn: 0.3382699\ttotal: 8.4s\tremaining: 1.96s\n",
      "811:\tlearn: 0.3380887\ttotal: 8.41s\tremaining: 1.95s\n",
      "812:\tlearn: 0.3379431\ttotal: 8.42s\tremaining: 1.94s\n",
      "813:\tlearn: 0.3377489\ttotal: 8.43s\tremaining: 1.93s\n",
      "814:\tlearn: 0.3375693\ttotal: 8.44s\tremaining: 1.92s\n",
      "815:\tlearn: 0.3373805\ttotal: 8.45s\tremaining: 1.91s\n",
      "816:\tlearn: 0.3372141\ttotal: 8.47s\tremaining: 1.9s\n",
      "817:\tlearn: 0.3370160\ttotal: 8.48s\tremaining: 1.89s\n",
      "818:\tlearn: 0.3368198\ttotal: 8.49s\tremaining: 1.88s\n",
      "819:\tlearn: 0.3366662\ttotal: 8.51s\tremaining: 1.87s\n",
      "820:\tlearn: 0.3364830\ttotal: 8.52s\tremaining: 1.86s\n",
      "821:\tlearn: 0.3362789\ttotal: 8.53s\tremaining: 1.85s\n",
      "822:\tlearn: 0.3361206\ttotal: 8.54s\tremaining: 1.84s\n",
      "823:\tlearn: 0.3359414\ttotal: 8.55s\tremaining: 1.83s\n",
      "824:\tlearn: 0.3357545\ttotal: 8.57s\tremaining: 1.82s\n",
      "825:\tlearn: 0.3355827\ttotal: 8.58s\tremaining: 1.81s\n",
      "826:\tlearn: 0.3354079\ttotal: 8.59s\tremaining: 1.8s\n",
      "827:\tlearn: 0.3352402\ttotal: 8.61s\tremaining: 1.79s\n",
      "828:\tlearn: 0.3350510\ttotal: 8.62s\tremaining: 1.78s\n",
      "829:\tlearn: 0.3348896\ttotal: 8.63s\tremaining: 1.77s\n",
      "830:\tlearn: 0.3346969\ttotal: 8.64s\tremaining: 1.76s\n",
      "831:\tlearn: 0.3345362\ttotal: 8.65s\tremaining: 1.75s\n",
      "832:\tlearn: 0.3343685\ttotal: 8.66s\tremaining: 1.74s\n",
      "833:\tlearn: 0.3342013\ttotal: 8.67s\tremaining: 1.73s\n",
      "834:\tlearn: 0.3340222\ttotal: 8.68s\tremaining: 1.72s\n",
      "835:\tlearn: 0.3338275\ttotal: 8.69s\tremaining: 1.7s\n",
      "836:\tlearn: 0.3336454\ttotal: 8.7s\tremaining: 1.69s\n",
      "837:\tlearn: 0.3334592\ttotal: 8.71s\tremaining: 1.68s\n",
      "838:\tlearn: 0.3332892\ttotal: 8.72s\tremaining: 1.67s\n",
      "839:\tlearn: 0.3330821\ttotal: 8.73s\tremaining: 1.66s\n",
      "840:\tlearn: 0.3328991\ttotal: 8.74s\tremaining: 1.65s\n",
      "841:\tlearn: 0.3327307\ttotal: 8.75s\tremaining: 1.64s\n",
      "842:\tlearn: 0.3325581\ttotal: 8.76s\tremaining: 1.63s\n",
      "843:\tlearn: 0.3323805\ttotal: 8.77s\tremaining: 1.62s\n",
      "844:\tlearn: 0.3321807\ttotal: 8.78s\tremaining: 1.61s\n",
      "845:\tlearn: 0.3319849\ttotal: 8.79s\tremaining: 1.6s\n",
      "846:\tlearn: 0.3318295\ttotal: 8.8s\tremaining: 1.59s\n",
      "847:\tlearn: 0.3316379\ttotal: 8.81s\tremaining: 1.58s\n",
      "848:\tlearn: 0.3314333\ttotal: 8.82s\tremaining: 1.57s\n",
      "849:\tlearn: 0.3312642\ttotal: 8.83s\tremaining: 1.56s\n",
      "850:\tlearn: 0.3310710\ttotal: 8.84s\tremaining: 1.55s\n",
      "851:\tlearn: 0.3308933\ttotal: 8.85s\tremaining: 1.54s\n",
      "852:\tlearn: 0.3307430\ttotal: 8.86s\tremaining: 1.53s\n",
      "853:\tlearn: 0.3305647\ttotal: 8.87s\tremaining: 1.52s\n",
      "854:\tlearn: 0.3303873\ttotal: 8.88s\tremaining: 1.5s\n",
      "855:\tlearn: 0.3302026\ttotal: 8.89s\tremaining: 1.5s\n",
      "856:\tlearn: 0.3300341\ttotal: 8.9s\tremaining: 1.48s\n",
      "857:\tlearn: 0.3298643\ttotal: 8.91s\tremaining: 1.47s\n",
      "858:\tlearn: 0.3296706\ttotal: 8.92s\tremaining: 1.46s\n",
      "859:\tlearn: 0.3295004\ttotal: 8.93s\tremaining: 1.45s\n",
      "860:\tlearn: 0.3293006\ttotal: 8.94s\tremaining: 1.44s\n",
      "861:\tlearn: 0.3291298\ttotal: 8.95s\tremaining: 1.43s\n",
      "862:\tlearn: 0.3289676\ttotal: 8.96s\tremaining: 1.42s\n",
      "863:\tlearn: 0.3287954\ttotal: 8.97s\tremaining: 1.41s\n",
      "864:\tlearn: 0.3286379\ttotal: 8.98s\tremaining: 1.4s\n",
      "865:\tlearn: 0.3284678\ttotal: 8.99s\tremaining: 1.39s\n",
      "866:\tlearn: 0.3282891\ttotal: 9s\tremaining: 1.38s\n",
      "867:\tlearn: 0.3281009\ttotal: 9.01s\tremaining: 1.37s\n",
      "868:\tlearn: 0.3279511\ttotal: 9.02s\tremaining: 1.36s\n",
      "869:\tlearn: 0.3277727\ttotal: 9.03s\tremaining: 1.35s\n",
      "870:\tlearn: 0.3276050\ttotal: 9.04s\tremaining: 1.34s\n",
      "871:\tlearn: 0.3274425\ttotal: 9.05s\tremaining: 1.33s\n",
      "872:\tlearn: 0.3272812\ttotal: 9.06s\tremaining: 1.32s\n",
      "873:\tlearn: 0.3271166\ttotal: 9.07s\tremaining: 1.31s\n",
      "874:\tlearn: 0.3269461\ttotal: 9.08s\tremaining: 1.3s\n",
      "875:\tlearn: 0.3267888\ttotal: 9.09s\tremaining: 1.29s\n",
      "876:\tlearn: 0.3266358\ttotal: 9.1s\tremaining: 1.28s\n",
      "877:\tlearn: 0.3264719\ttotal: 9.11s\tremaining: 1.26s\n",
      "878:\tlearn: 0.3263069\ttotal: 9.12s\tremaining: 1.25s\n",
      "879:\tlearn: 0.3261236\ttotal: 9.13s\tremaining: 1.25s\n",
      "880:\tlearn: 0.3259496\ttotal: 9.14s\tremaining: 1.24s\n",
      "881:\tlearn: 0.3258110\ttotal: 9.15s\tremaining: 1.22s\n",
      "882:\tlearn: 0.3256392\ttotal: 9.16s\tremaining: 1.21s\n",
      "883:\tlearn: 0.3254677\ttotal: 9.18s\tremaining: 1.2s\n",
      "884:\tlearn: 0.3253120\ttotal: 9.19s\tremaining: 1.19s\n",
      "885:\tlearn: 0.3251580\ttotal: 9.2s\tremaining: 1.18s\n",
      "886:\tlearn: 0.3249769\ttotal: 9.21s\tremaining: 1.17s\n",
      "887:\tlearn: 0.3248001\ttotal: 9.22s\tremaining: 1.16s\n",
      "888:\tlearn: 0.3246268\ttotal: 9.23s\tremaining: 1.15s\n",
      "889:\tlearn: 0.3244479\ttotal: 9.24s\tremaining: 1.14s\n",
      "890:\tlearn: 0.3242777\ttotal: 9.25s\tremaining: 1.13s\n",
      "891:\tlearn: 0.3241118\ttotal: 9.26s\tremaining: 1.12s\n",
      "892:\tlearn: 0.3239388\ttotal: 9.27s\tremaining: 1.11s\n",
      "893:\tlearn: 0.3237875\ttotal: 9.28s\tremaining: 1.1s\n",
      "894:\tlearn: 0.3236118\ttotal: 9.29s\tremaining: 1.09s\n",
      "895:\tlearn: 0.3234438\ttotal: 9.3s\tremaining: 1.08s\n",
      "896:\tlearn: 0.3232501\ttotal: 9.31s\tremaining: 1.07s\n",
      "897:\tlearn: 0.3230744\ttotal: 9.32s\tremaining: 1.06s\n",
      "898:\tlearn: 0.3229101\ttotal: 9.33s\tremaining: 1.05s\n",
      "899:\tlearn: 0.3227357\ttotal: 9.34s\tremaining: 1.04s\n",
      "900:\tlearn: 0.3225816\ttotal: 9.35s\tremaining: 1.03s\n",
      "901:\tlearn: 0.3224066\ttotal: 9.36s\tremaining: 1.02s\n",
      "902:\tlearn: 0.3222331\ttotal: 9.37s\tremaining: 1.01s\n",
      "903:\tlearn: 0.3220707\ttotal: 9.38s\tremaining: 996ms\n",
      "904:\tlearn: 0.3218884\ttotal: 9.39s\tremaining: 986ms\n",
      "905:\tlearn: 0.3217181\ttotal: 9.4s\tremaining: 976ms\n",
      "906:\tlearn: 0.3215685\ttotal: 9.41s\tremaining: 965ms\n",
      "907:\tlearn: 0.3214221\ttotal: 9.42s\tremaining: 955ms\n",
      "908:\tlearn: 0.3212451\ttotal: 9.43s\tremaining: 944ms\n",
      "909:\tlearn: 0.3210605\ttotal: 9.44s\tremaining: 934ms\n",
      "910:\tlearn: 0.3208647\ttotal: 9.45s\tremaining: 924ms\n",
      "911:\tlearn: 0.3207277\ttotal: 9.46s\tremaining: 913ms\n",
      "912:\tlearn: 0.3205595\ttotal: 9.47s\tremaining: 903ms\n",
      "913:\tlearn: 0.3203801\ttotal: 9.48s\tremaining: 892ms\n",
      "914:\tlearn: 0.3202224\ttotal: 9.49s\tremaining: 882ms\n",
      "915:\tlearn: 0.3200706\ttotal: 9.5s\tremaining: 872ms\n",
      "916:\tlearn: 0.3198954\ttotal: 9.51s\tremaining: 861ms\n",
      "917:\tlearn: 0.3197435\ttotal: 9.52s\tremaining: 851ms\n",
      "918:\tlearn: 0.3195505\ttotal: 9.53s\tremaining: 840ms\n",
      "919:\tlearn: 0.3193707\ttotal: 9.54s\tremaining: 830ms\n",
      "920:\tlearn: 0.3192281\ttotal: 9.55s\tremaining: 819ms\n",
      "921:\tlearn: 0.3190786\ttotal: 9.56s\tremaining: 809ms\n",
      "922:\tlearn: 0.3188826\ttotal: 9.57s\tremaining: 799ms\n",
      "923:\tlearn: 0.3187134\ttotal: 9.58s\tremaining: 788ms\n",
      "924:\tlearn: 0.3185560\ttotal: 9.6s\tremaining: 778ms\n",
      "925:\tlearn: 0.3183858\ttotal: 9.61s\tremaining: 768ms\n",
      "926:\tlearn: 0.3182029\ttotal: 9.62s\tremaining: 758ms\n",
      "927:\tlearn: 0.3180547\ttotal: 9.63s\tremaining: 747ms\n",
      "928:\tlearn: 0.3178741\ttotal: 9.64s\tremaining: 737ms\n",
      "929:\tlearn: 0.3176977\ttotal: 9.65s\tremaining: 726ms\n",
      "930:\tlearn: 0.3175344\ttotal: 9.66s\tremaining: 716ms\n",
      "931:\tlearn: 0.3173842\ttotal: 9.67s\tremaining: 705ms\n",
      "932:\tlearn: 0.3171987\ttotal: 9.68s\tremaining: 695ms\n",
      "933:\tlearn: 0.3170153\ttotal: 9.69s\tremaining: 685ms\n",
      "934:\tlearn: 0.3168515\ttotal: 9.7s\tremaining: 674ms\n",
      "935:\tlearn: 0.3167001\ttotal: 9.71s\tremaining: 664ms\n",
      "936:\tlearn: 0.3165275\ttotal: 9.72s\tremaining: 653ms\n",
      "937:\tlearn: 0.3163650\ttotal: 9.73s\tremaining: 643ms\n",
      "938:\tlearn: 0.3162021\ttotal: 9.74s\tremaining: 633ms\n",
      "939:\tlearn: 0.3160290\ttotal: 9.75s\tremaining: 622ms\n",
      "940:\tlearn: 0.3158921\ttotal: 9.76s\tremaining: 612ms\n",
      "941:\tlearn: 0.3157261\ttotal: 9.77s\tremaining: 601ms\n",
      "942:\tlearn: 0.3155751\ttotal: 9.78s\tremaining: 591ms\n",
      "943:\tlearn: 0.3154106\ttotal: 9.83s\tremaining: 583ms\n",
      "944:\tlearn: 0.3152268\ttotal: 9.84s\tremaining: 573ms\n",
      "945:\tlearn: 0.3150617\ttotal: 9.86s\tremaining: 563ms\n",
      "946:\tlearn: 0.3148992\ttotal: 9.87s\tremaining: 552ms\n",
      "947:\tlearn: 0.3147489\ttotal: 9.88s\tremaining: 542ms\n",
      "948:\tlearn: 0.3145884\ttotal: 9.89s\tremaining: 531ms\n",
      "949:\tlearn: 0.3144606\ttotal: 9.9s\tremaining: 521ms\n",
      "950:\tlearn: 0.3142883\ttotal: 9.91s\tremaining: 511ms\n",
      "951:\tlearn: 0.3141420\ttotal: 9.92s\tremaining: 500ms\n",
      "952:\tlearn: 0.3139878\ttotal: 9.93s\tremaining: 490ms\n",
      "953:\tlearn: 0.3138443\ttotal: 9.94s\tremaining: 479ms\n",
      "954:\tlearn: 0.3136620\ttotal: 9.95s\tremaining: 469ms\n",
      "955:\tlearn: 0.3135083\ttotal: 9.96s\tremaining: 458ms\n",
      "956:\tlearn: 0.3133624\ttotal: 9.97s\tremaining: 448ms\n",
      "957:\tlearn: 0.3132139\ttotal: 9.98s\tremaining: 438ms\n",
      "958:\tlearn: 0.3130617\ttotal: 9.99s\tremaining: 427ms\n",
      "959:\tlearn: 0.3129045\ttotal: 10s\tremaining: 417ms\n",
      "960:\tlearn: 0.3127423\ttotal: 10s\tremaining: 407ms\n",
      "961:\tlearn: 0.3125944\ttotal: 10s\tremaining: 396ms\n",
      "962:\tlearn: 0.3124490\ttotal: 10s\tremaining: 386ms\n",
      "963:\tlearn: 0.3122989\ttotal: 10s\tremaining: 375ms\n",
      "964:\tlearn: 0.3121390\ttotal: 10.1s\tremaining: 365ms\n",
      "965:\tlearn: 0.3119693\ttotal: 10.1s\tremaining: 354ms\n",
      "966:\tlearn: 0.3118084\ttotal: 10.1s\tremaining: 344ms\n",
      "967:\tlearn: 0.3116361\ttotal: 10.1s\tremaining: 333ms\n",
      "968:\tlearn: 0.3114746\ttotal: 10.1s\tremaining: 323ms\n",
      "969:\tlearn: 0.3113267\ttotal: 10.1s\tremaining: 313ms\n",
      "970:\tlearn: 0.3111744\ttotal: 10.1s\tremaining: 302ms\n",
      "971:\tlearn: 0.3110091\ttotal: 10.1s\tremaining: 292ms\n",
      "972:\tlearn: 0.3108458\ttotal: 10.1s\tremaining: 281ms\n",
      "973:\tlearn: 0.3106761\ttotal: 10.2s\tremaining: 271ms\n",
      "974:\tlearn: 0.3105266\ttotal: 10.2s\tremaining: 261ms\n",
      "975:\tlearn: 0.3103624\ttotal: 10.2s\tremaining: 250ms\n",
      "976:\tlearn: 0.3102208\ttotal: 10.2s\tremaining: 240ms\n",
      "977:\tlearn: 0.3100453\ttotal: 10.2s\tremaining: 229ms\n",
      "978:\tlearn: 0.3098864\ttotal: 10.2s\tremaining: 219ms\n",
      "979:\tlearn: 0.3097518\ttotal: 10.2s\tremaining: 208ms\n",
      "980:\tlearn: 0.3095911\ttotal: 10.2s\tremaining: 198ms\n",
      "981:\tlearn: 0.3094382\ttotal: 10.2s\tremaining: 187ms\n",
      "982:\tlearn: 0.3092776\ttotal: 10.2s\tremaining: 177ms\n",
      "983:\tlearn: 0.3091082\ttotal: 10.2s\tremaining: 167ms\n",
      "984:\tlearn: 0.3089499\ttotal: 10.3s\tremaining: 156ms\n",
      "985:\tlearn: 0.3088250\ttotal: 10.3s\tremaining: 146ms\n",
      "986:\tlearn: 0.3086721\ttotal: 10.3s\tremaining: 135ms\n",
      "987:\tlearn: 0.3085314\ttotal: 10.3s\tremaining: 125ms\n",
      "988:\tlearn: 0.3083547\ttotal: 10.3s\tremaining: 114ms\n",
      "989:\tlearn: 0.3081796\ttotal: 10.3s\tremaining: 104ms\n",
      "990:\tlearn: 0.3079948\ttotal: 10.3s\tremaining: 93.7ms\n",
      "991:\tlearn: 0.3078336\ttotal: 10.3s\tremaining: 83.2ms\n",
      "992:\tlearn: 0.3076564\ttotal: 10.3s\tremaining: 72.8ms\n",
      "993:\tlearn: 0.3075199\ttotal: 10.3s\tremaining: 62.4ms\n",
      "994:\tlearn: 0.3073444\ttotal: 10.3s\tremaining: 52ms\n",
      "995:\tlearn: 0.3071753\ttotal: 10.4s\tremaining: 41.6ms\n",
      "996:\tlearn: 0.3070287\ttotal: 10.4s\tremaining: 31.2ms\n",
      "997:\tlearn: 0.3068808\ttotal: 10.4s\tremaining: 20.8ms\n",
      "998:\tlearn: 0.3067054\ttotal: 10.4s\tremaining: 10.4ms\n",
      "999:\tlearn: 0.3065510\ttotal: 10.4s\tremaining: 0us\n",
      "Model saved to: results/cat_classifier_sampled.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_83e0e_row0_col0, #T_83e0e_row1_col1, #T_83e0e_row4_col0 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_83e0e_row0_col1, #T_83e0e_row0_col2, #T_83e0e_row2_col2, #T_83e0e_row3_col0, #T_83e0e_row3_col1, #T_83e0e_row3_col2, #T_83e0e_row4_col1, #T_83e0e_row4_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_83e0e_row1_col0, #T_83e0e_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_83e0e_row2_col0, #T_83e0e_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_83e0e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_83e0e_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_83e0e_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_83e0e_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_83e0e_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_83e0e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_83e0e_row0_col0\" class=\"data row0 col0\" >0.986300</td>\n",
       "      <td id=\"T_83e0e_row0_col1\" class=\"data row0 col1\" >0.603300</td>\n",
       "      <td id=\"T_83e0e_row0_col2\" class=\"data row0 col2\" >0.748700</td>\n",
       "      <td id=\"T_83e0e_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83e0e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_83e0e_row1_col0\" class=\"data row1 col0\" >0.201100</td>\n",
       "      <td id=\"T_83e0e_row1_col1\" class=\"data row1 col1\" >0.922500</td>\n",
       "      <td id=\"T_83e0e_row1_col2\" class=\"data row1 col2\" >0.330300</td>\n",
       "      <td id=\"T_83e0e_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83e0e_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_83e0e_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_83e0e_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_83e0e_row2_col2\" class=\"data row2 col2\" >0.634505</td>\n",
       "      <td id=\"T_83e0e_row2_col3\" class=\"data row2 col3\" >0.634500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83e0e_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_83e0e_row3_col0\" class=\"data row3 col0\" >0.593700</td>\n",
       "      <td id=\"T_83e0e_row3_col1\" class=\"data row3 col1\" >0.762900</td>\n",
       "      <td id=\"T_83e0e_row3_col2\" class=\"data row3 col2\" >0.539500</td>\n",
       "      <td id=\"T_83e0e_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83e0e_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_83e0e_row4_col0\" class=\"data row4 col0\" >0.909600</td>\n",
       "      <td id=\"T_83e0e_row4_col1\" class=\"data row4 col1\" >0.634500</td>\n",
       "      <td id=\"T_83e0e_row4_col2\" class=\"data row4 col2\" >0.707800</td>\n",
       "      <td id=\"T_83e0e_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123db7390>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=CatBoostClassifier(),\n",
    "    model_name=\"cat_classifier\",\n",
    "    X_train=X_resampled_train_scaled,\n",
    "    y_train=y_resampled_down,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=True\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b87c44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/linear_svc_classifier_sampled.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f82d5_row0_col0, #T_f82d5_row1_col1, #T_f82d5_row4_col0 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_f82d5_row0_col1, #T_f82d5_row0_col2, #T_f82d5_row2_col2, #T_f82d5_row3_col0, #T_f82d5_row3_col1, #T_f82d5_row3_col2, #T_f82d5_row4_col1, #T_f82d5_row4_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_f82d5_row1_col0, #T_f82d5_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_f82d5_row2_col0, #T_f82d5_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f82d5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f82d5_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_f82d5_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_f82d5_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_f82d5_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f82d5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f82d5_row0_col0\" class=\"data row0 col0\" >0.981800</td>\n",
       "      <td id=\"T_f82d5_row0_col1\" class=\"data row0 col1\" >0.561000</td>\n",
       "      <td id=\"T_f82d5_row0_col2\" class=\"data row0 col2\" >0.714000</td>\n",
       "      <td id=\"T_f82d5_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f82d5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f82d5_row1_col0\" class=\"data row1 col0\" >0.182300</td>\n",
       "      <td id=\"T_f82d5_row1_col1\" class=\"data row1 col1\" >0.903800</td>\n",
       "      <td id=\"T_f82d5_row1_col2\" class=\"data row1 col2\" >0.303300</td>\n",
       "      <td id=\"T_f82d5_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f82d5_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_f82d5_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_f82d5_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_f82d5_row2_col2\" class=\"data row2 col2\" >0.594472</td>\n",
       "      <td id=\"T_f82d5_row2_col3\" class=\"data row2 col3\" >0.594500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f82d5_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_f82d5_row3_col0\" class=\"data row3 col0\" >0.582000</td>\n",
       "      <td id=\"T_f82d5_row3_col1\" class=\"data row3 col1\" >0.732400</td>\n",
       "      <td id=\"T_f82d5_row3_col2\" class=\"data row3 col2\" >0.508700</td>\n",
       "      <td id=\"T_f82d5_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f82d5_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_f82d5_row4_col0\" class=\"data row4 col0\" >0.903700</td>\n",
       "      <td id=\"T_f82d5_row4_col1\" class=\"data row4 col1\" >0.594500</td>\n",
       "      <td id=\"T_f82d5_row4_col2\" class=\"data row4 col2\" >0.673900</td>\n",
       "      <td id=\"T_f82d5_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123db6d50>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=LinearSVC(),\n",
    "    model_name=\"linear_svc_classifier\",\n",
    "    X_train=X_resampled_train_scaled,\n",
    "    y_train=y_resampled_down,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=True\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ac7068f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/rf_classifier_sampled.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_30e54_row0_col0, #T_30e54_row1_col1, #T_30e54_row4_col0 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_30e54_row0_col1, #T_30e54_row0_col2, #T_30e54_row2_col2, #T_30e54_row3_col0, #T_30e54_row3_col1, #T_30e54_row3_col2, #T_30e54_row4_col1, #T_30e54_row4_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_30e54_row1_col0, #T_30e54_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_30e54_row2_col0, #T_30e54_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_30e54\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_30e54_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_30e54_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_30e54_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_30e54_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_30e54_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_30e54_row0_col0\" class=\"data row0 col0\" >0.975600</td>\n",
       "      <td id=\"T_30e54_row0_col1\" class=\"data row0 col1\" >0.560100</td>\n",
       "      <td id=\"T_30e54_row0_col2\" class=\"data row0 col2\" >0.711600</td>\n",
       "      <td id=\"T_30e54_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_30e54_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_30e54_row1_col0\" class=\"data row1 col0\" >0.176500</td>\n",
       "      <td id=\"T_30e54_row1_col1\" class=\"data row1 col1\" >0.870800</td>\n",
       "      <td id=\"T_30e54_row1_col2\" class=\"data row1 col2\" >0.293500</td>\n",
       "      <td id=\"T_30e54_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_30e54_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_30e54_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_30e54_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_30e54_row2_col2\" class=\"data row2 col2\" >0.590446</td>\n",
       "      <td id=\"T_30e54_row2_col3\" class=\"data row2 col3\" >0.590400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_30e54_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_30e54_row3_col0\" class=\"data row3 col0\" >0.576100</td>\n",
       "      <td id=\"T_30e54_row3_col1\" class=\"data row3 col1\" >0.715400</td>\n",
       "      <td id=\"T_30e54_row3_col2\" class=\"data row3 col2\" >0.502600</td>\n",
       "      <td id=\"T_30e54_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_30e54_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_30e54_row4_col0\" class=\"data row4 col0\" >0.897600</td>\n",
       "      <td id=\"T_30e54_row4_col1\" class=\"data row4 col1\" >0.590400</td>\n",
       "      <td id=\"T_30e54_row4_col2\" class=\"data row4 col2\" >0.670800</td>\n",
       "      <td id=\"T_30e54_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123db7110>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=RandomForestClassifier(),\n",
    "    model_name=\"rf_classifier\",\n",
    "    X_train=X_resampled_train_scaled,\n",
    "    y_train=y_resampled_down,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=True\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99d63fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/nb_classifier_sampled.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3095b_row0_col0, #T_3095b_row1_col1, #T_3095b_row4_col0 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_3095b_row0_col1, #T_3095b_row0_col2, #T_3095b_row2_col2, #T_3095b_row3_col0, #T_3095b_row3_col1, #T_3095b_row3_col2, #T_3095b_row4_col1, #T_3095b_row4_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_3095b_row1_col0, #T_3095b_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_3095b_row2_col0, #T_3095b_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3095b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3095b_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_3095b_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_3095b_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_3095b_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3095b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3095b_row0_col0\" class=\"data row0 col0\" >0.986400</td>\n",
       "      <td id=\"T_3095b_row0_col1\" class=\"data row0 col1\" >0.566700</td>\n",
       "      <td id=\"T_3095b_row0_col2\" class=\"data row0 col2\" >0.719800</td>\n",
       "      <td id=\"T_3095b_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3095b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3095b_row1_col0\" class=\"data row1 col0\" >0.188200</td>\n",
       "      <td id=\"T_3095b_row1_col1\" class=\"data row1 col1\" >0.928100</td>\n",
       "      <td id=\"T_3095b_row1_col2\" class=\"data row1 col2\" >0.313000</td>\n",
       "      <td id=\"T_3095b_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3095b_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_3095b_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_3095b_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_3095b_row2_col2\" class=\"data row2 col2\" >0.601982</td>\n",
       "      <td id=\"T_3095b_row2_col3\" class=\"data row2 col3\" >0.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3095b_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_3095b_row3_col0\" class=\"data row3 col0\" >0.587300</td>\n",
       "      <td id=\"T_3095b_row3_col1\" class=\"data row3 col1\" >0.747400</td>\n",
       "      <td id=\"T_3095b_row3_col2\" class=\"data row3 col2\" >0.516400</td>\n",
       "      <td id=\"T_3095b_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3095b_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_3095b_row4_col0\" class=\"data row4 col0\" >0.908500</td>\n",
       "      <td id=\"T_3095b_row4_col1\" class=\"data row4 col1\" >0.602000</td>\n",
       "      <td id=\"T_3095b_row4_col2\" class=\"data row4 col2\" >0.680100</td>\n",
       "      <td id=\"T_3095b_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123db7250>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=GaussianNB(),\n",
    "    model_name=\"nb_classifier\",\n",
    "    X_train=X_resampled_train_scaled,\n",
    "    y_train=y_resampled_down,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=True\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c7893313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/gb_classifier_sampled.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2812f_row0_col0, #T_2812f_row1_col1, #T_2812f_row4_col0 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_2812f_row0_col1, #T_2812f_row0_col2, #T_2812f_row2_col2, #T_2812f_row3_col0, #T_2812f_row3_col1, #T_2812f_row3_col2, #T_2812f_row4_col1, #T_2812f_row4_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_2812f_row1_col0, #T_2812f_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_2812f_row2_col0, #T_2812f_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2812f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2812f_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_2812f_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_2812f_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_2812f_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2812f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2812f_row0_col0\" class=\"data row0 col0\" >0.975700</td>\n",
       "      <td id=\"T_2812f_row0_col1\" class=\"data row0 col1\" >0.615300</td>\n",
       "      <td id=\"T_2812f_row0_col2\" class=\"data row0 col2\" >0.754700</td>\n",
       "      <td id=\"T_2812f_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2812f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2812f_row1_col0\" class=\"data row1 col0\" >0.194600</td>\n",
       "      <td id=\"T_2812f_row1_col1\" class=\"data row1 col1\" >0.858500</td>\n",
       "      <td id=\"T_2812f_row1_col2\" class=\"data row1 col2\" >0.317300</td>\n",
       "      <td id=\"T_2812f_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2812f_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_2812f_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_2812f_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_2812f_row2_col2\" class=\"data row2 col2\" >0.639102</td>\n",
       "      <td id=\"T_2812f_row2_col3\" class=\"data row2 col3\" >0.639100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2812f_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_2812f_row3_col0\" class=\"data row3 col0\" >0.585200</td>\n",
       "      <td id=\"T_2812f_row3_col1\" class=\"data row3 col1\" >0.736900</td>\n",
       "      <td id=\"T_2812f_row3_col2\" class=\"data row3 col2\" >0.536000</td>\n",
       "      <td id=\"T_2812f_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2812f_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_2812f_row4_col0\" class=\"data row4 col0\" >0.899400</td>\n",
       "      <td id=\"T_2812f_row4_col1\" class=\"data row4 col1\" >0.639100</td>\n",
       "      <td id=\"T_2812f_row4_col2\" class=\"data row4 col2\" >0.712000</td>\n",
       "      <td id=\"T_2812f_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123db7750>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=GradientBoostingClassifier(),\n",
    "    model_name=\"gb_classifier\",\n",
    "    X_train=X_resampled_train_scaled,\n",
    "    y_train=y_resampled_down,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=True\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3cb13988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/sv_classifier_sampled.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f3805_row0_col0, #T_f3805_row1_col1, #T_f3805_row4_col0 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_f3805_row0_col1, #T_f3805_row0_col2, #T_f3805_row2_col2, #T_f3805_row3_col0, #T_f3805_row3_col1, #T_f3805_row3_col2, #T_f3805_row4_col1, #T_f3805_row4_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_f3805_row1_col0, #T_f3805_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_f3805_row2_col0, #T_f3805_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f3805\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f3805_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_f3805_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_f3805_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_f3805_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f3805_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f3805_row0_col0\" class=\"data row0 col0\" >0.985600</td>\n",
       "      <td id=\"T_f3805_row0_col1\" class=\"data row0 col1\" >0.561200</td>\n",
       "      <td id=\"T_f3805_row0_col2\" class=\"data row0 col2\" >0.715200</td>\n",
       "      <td id=\"T_f3805_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3805_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f3805_row1_col0\" class=\"data row1 col0\" >0.185700</td>\n",
       "      <td id=\"T_f3805_row1_col1\" class=\"data row1 col1\" >0.924300</td>\n",
       "      <td id=\"T_f3805_row1_col2\" class=\"data row1 col2\" >0.309300</td>\n",
       "      <td id=\"T_f3805_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3805_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_f3805_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_f3805_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_f3805_row2_col2\" class=\"data row2 col2\" >0.596699</td>\n",
       "      <td id=\"T_f3805_row2_col3\" class=\"data row2 col3\" >0.596700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3805_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_f3805_row3_col0\" class=\"data row3 col0\" >0.585700</td>\n",
       "      <td id=\"T_f3805_row3_col1\" class=\"data row3 col1\" >0.742800</td>\n",
       "      <td id=\"T_f3805_row3_col2\" class=\"data row3 col2\" >0.512200</td>\n",
       "      <td id=\"T_f3805_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3805_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_f3805_row4_col0\" class=\"data row4 col0\" >0.907500</td>\n",
       "      <td id=\"T_f3805_row4_col1\" class=\"data row4 col1\" >0.596700</td>\n",
       "      <td id=\"T_f3805_row4_col2\" class=\"data row4 col2\" >0.675600</td>\n",
       "      <td id=\"T_f3805_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123db7890>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=SVC(),\n",
    "    model_name=\"sv_classifier\",\n",
    "    X_train=X_resampled_train_scaled,\n",
    "    y_train=y_resampled_down,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=True\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cf490d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/knn_classifier_sampled.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_35d39_row0_col0, #T_35d39_row0_col1, #T_35d39_row0_col2, #T_35d39_row2_col2, #T_35d39_row4_col0, #T_35d39_row4_col1, #T_35d39_row4_col2 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_35d39_row1_col0, #T_35d39_row1_col1, #T_35d39_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_35d39_row2_col0, #T_35d39_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_35d39_row3_col0, #T_35d39_row3_col1, #T_35d39_row3_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_35d39\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_35d39_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_35d39_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_35d39_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_35d39_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_35d39_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_35d39_row0_col0\" class=\"data row0 col0\" >0.916700</td>\n",
       "      <td id=\"T_35d39_row0_col1\" class=\"data row0 col1\" >0.899600</td>\n",
       "      <td id=\"T_35d39_row0_col2\" class=\"data row0 col2\" >0.908000</td>\n",
       "      <td id=\"T_35d39_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35d39_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_35d39_row1_col0\" class=\"data row1 col0\" >0.208700</td>\n",
       "      <td id=\"T_35d39_row1_col1\" class=\"data row1 col1\" >0.244700</td>\n",
       "      <td id=\"T_35d39_row1_col2\" class=\"data row1 col2\" >0.225200</td>\n",
       "      <td id=\"T_35d39_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35d39_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_35d39_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_35d39_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_35d39_row2_col2\" class=\"data row2 col2\" >0.835584</td>\n",
       "      <td id=\"T_35d39_row2_col3\" class=\"data row2 col3\" >0.835600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35d39_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_35d39_row3_col0\" class=\"data row3 col0\" >0.562700</td>\n",
       "      <td id=\"T_35d39_row3_col1\" class=\"data row3 col1\" >0.572100</td>\n",
       "      <td id=\"T_35d39_row3_col2\" class=\"data row3 col2\" >0.566600</td>\n",
       "      <td id=\"T_35d39_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35d39_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_35d39_row4_col0\" class=\"data row4 col0\" >0.847500</td>\n",
       "      <td id=\"T_35d39_row4_col1\" class=\"data row4 col1\" >0.835600</td>\n",
       "      <td id=\"T_35d39_row4_col2\" class=\"data row4 col2\" >0.841300</td>\n",
       "      <td id=\"T_35d39_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123db7b10>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=KNeighborsClassifier(),\n",
    "    model_name=\"knn_classifier\",\n",
    "    X_train=X_resampled_train_scaled,\n",
    "    y_train=y_resampled_down,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=True\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "68f6d6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/nn_classifier_sampled.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a62e4_row0_col0, #T_a62e4_row1_col1, #T_a62e4_row4_col0 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_a62e4_row0_col1, #T_a62e4_row0_col2, #T_a62e4_row2_col2, #T_a62e4_row3_col0, #T_a62e4_row3_col1, #T_a62e4_row4_col1, #T_a62e4_row4_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_a62e4_row1_col0, #T_a62e4_row1_col2, #T_a62e4_row3_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_a62e4_row2_col0, #T_a62e4_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a62e4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a62e4_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_a62e4_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_a62e4_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_a62e4_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a62e4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a62e4_row0_col0\" class=\"data row0 col0\" >0.966700</td>\n",
       "      <td id=\"T_a62e4_row0_col1\" class=\"data row0 col1\" >0.548200</td>\n",
       "      <td id=\"T_a62e4_row0_col2\" class=\"data row0 col2\" >0.699700</td>\n",
       "      <td id=\"T_a62e4_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a62e4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a62e4_row1_col0\" class=\"data row1 col0\" >0.165100</td>\n",
       "      <td id=\"T_a62e4_row1_col1\" class=\"data row1 col1\" >0.825500</td>\n",
       "      <td id=\"T_a62e4_row1_col2\" class=\"data row1 col2\" >0.275200</td>\n",
       "      <td id=\"T_a62e4_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a62e4_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_a62e4_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_a62e4_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_a62e4_row2_col2\" class=\"data row2 col2\" >0.575312</td>\n",
       "      <td id=\"T_a62e4_row2_col3\" class=\"data row2 col3\" >0.575300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a62e4_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_a62e4_row3_col0\" class=\"data row3 col0\" >0.565900</td>\n",
       "      <td id=\"T_a62e4_row3_col1\" class=\"data row3 col1\" >0.686900</td>\n",
       "      <td id=\"T_a62e4_row3_col2\" class=\"data row3 col2\" >0.487400</td>\n",
       "      <td id=\"T_a62e4_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a62e4_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_a62e4_row4_col0\" class=\"data row4 col0\" >0.888400</td>\n",
       "      <td id=\"T_a62e4_row4_col1\" class=\"data row4 col1\" >0.575300</td>\n",
       "      <td id=\"T_a62e4_row4_col2\" class=\"data row4 col2\" >0.658200</td>\n",
       "      <td id=\"T_a62e4_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123db7610>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=MLPClassifier(),\n",
    "    model_name=\"nn_classifier\",\n",
    "    X_train=X_resampled_train_scaled,\n",
    "    y_train=y_resampled_down,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=True\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a58299ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/xgb_classifier_sampled.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_67d38_row0_col0, #T_67d38_row1_col1, #T_67d38_row4_col0 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_67d38_row0_col1, #T_67d38_row0_col2, #T_67d38_row2_col2, #T_67d38_row3_col0, #T_67d38_row3_col1, #T_67d38_row3_col2, #T_67d38_row4_col1, #T_67d38_row4_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_67d38_row1_col0, #T_67d38_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_67d38_row2_col0, #T_67d38_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_67d38\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_67d38_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_67d38_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_67d38_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_67d38_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_67d38_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_67d38_row0_col0\" class=\"data row0 col0\" >0.979400</td>\n",
       "      <td id=\"T_67d38_row0_col1\" class=\"data row0 col1\" >0.587000</td>\n",
       "      <td id=\"T_67d38_row0_col2\" class=\"data row0 col2\" >0.734000</td>\n",
       "      <td id=\"T_67d38_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67d38_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_67d38_row1_col0\" class=\"data row1 col0\" >0.188500</td>\n",
       "      <td id=\"T_67d38_row1_col1\" class=\"data row1 col1\" >0.886000</td>\n",
       "      <td id=\"T_67d38_row1_col2\" class=\"data row1 col2\" >0.310800</td>\n",
       "      <td id=\"T_67d38_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67d38_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_67d38_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_67d38_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_67d38_row2_col2\" class=\"data row2 col2\" >0.616202</td>\n",
       "      <td id=\"T_67d38_row2_col3\" class=\"data row2 col3\" >0.616200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67d38_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_67d38_row3_col0\" class=\"data row3 col0\" >0.583900</td>\n",
       "      <td id=\"T_67d38_row3_col1\" class=\"data row3 col1\" >0.736500</td>\n",
       "      <td id=\"T_67d38_row3_col2\" class=\"data row3 col2\" >0.522400</td>\n",
       "      <td id=\"T_67d38_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67d38_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_67d38_row4_col0\" class=\"data row4 col0\" >0.902100</td>\n",
       "      <td id=\"T_67d38_row4_col1\" class=\"data row4 col1\" >0.616200</td>\n",
       "      <td id=\"T_67d38_row4_col2\" class=\"data row4 col2\" >0.692700</td>\n",
       "      <td id=\"T_67d38_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123db7c50>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=XGBClassifier(),\n",
    "    model_name=\"xgb_classifier\",\n",
    "    X_train=X_resampled_train_scaled,\n",
    "    y_train=y_resampled_down,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=True\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664f0f34",
   "metadata": {},
   "source": [
    "Without downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "54f834f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/logistic_regression.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_db27f_row0_col0, #T_db27f_row0_col1, #T_db27f_row0_col2, #T_db27f_row2_col2, #T_db27f_row4_col0, #T_db27f_row4_col1, #T_db27f_row4_col2 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_db27f_row1_col0, #T_db27f_row3_col0, #T_db27f_row3_col1, #T_db27f_row3_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_db27f_row1_col1, #T_db27f_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_db27f_row2_col0, #T_db27f_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_db27f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_db27f_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_db27f_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_db27f_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_db27f_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_db27f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_db27f_row0_col0\" class=\"data row0 col0\" >0.923600</td>\n",
       "      <td id=\"T_db27f_row0_col1\" class=\"data row0 col1\" >0.986200</td>\n",
       "      <td id=\"T_db27f_row0_col2\" class=\"data row0 col2\" >0.953900</td>\n",
       "      <td id=\"T_db27f_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db27f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_db27f_row1_col0\" class=\"data row1 col0\" >0.658800</td>\n",
       "      <td id=\"T_db27f_row1_col1\" class=\"data row1 col1\" >0.246100</td>\n",
       "      <td id=\"T_db27f_row1_col2\" class=\"data row1 col2\" >0.358400</td>\n",
       "      <td id=\"T_db27f_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db27f_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_db27f_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_db27f_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_db27f_row2_col2\" class=\"data row2 col2\" >0.913909</td>\n",
       "      <td id=\"T_db27f_row2_col3\" class=\"data row2 col3\" >0.913900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db27f_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_db27f_row3_col0\" class=\"data row3 col0\" >0.791200</td>\n",
       "      <td id=\"T_db27f_row3_col1\" class=\"data row3 col1\" >0.616200</td>\n",
       "      <td id=\"T_db27f_row3_col2\" class=\"data row3 col2\" >0.656100</td>\n",
       "      <td id=\"T_db27f_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db27f_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_db27f_row4_col0\" class=\"data row4 col0\" >0.897700</td>\n",
       "      <td id=\"T_db27f_row4_col1\" class=\"data row4 col1\" >0.913900</td>\n",
       "      <td id=\"T_db27f_row4_col2\" class=\"data row4 col2\" >0.895700</td>\n",
       "      <td id=\"T_db27f_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1246802d0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=LogisticRegression(),\n",
    "    model_name=\"logistic_regression\",\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=False\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "790d8cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.085004\n",
      "0:\tlearn: 0.6202387\ttotal: 76.7ms\tremaining: 1m 16s\n",
      "1:\tlearn: 0.5605550\ttotal: 138ms\tremaining: 1m 8s\n",
      "2:\tlearn: 0.5134037\ttotal: 181ms\tremaining: 1m\n",
      "3:\tlearn: 0.4747550\ttotal: 210ms\tremaining: 52.4s\n",
      "4:\tlearn: 0.4436102\ttotal: 238ms\tremaining: 47.4s\n",
      "5:\tlearn: 0.4178338\ttotal: 268ms\tremaining: 44.4s\n",
      "6:\tlearn: 0.3976184\ttotal: 289ms\tremaining: 41s\n",
      "7:\tlearn: 0.3804486\ttotal: 310ms\tremaining: 38.5s\n",
      "8:\tlearn: 0.3667035\ttotal: 339ms\tremaining: 37.3s\n",
      "9:\tlearn: 0.3547619\ttotal: 368ms\tremaining: 36.5s\n",
      "10:\tlearn: 0.3448884\ttotal: 398ms\tremaining: 35.8s\n",
      "11:\tlearn: 0.3370717\ttotal: 426ms\tremaining: 35.1s\n",
      "12:\tlearn: 0.3301312\ttotal: 454ms\tremaining: 34.5s\n",
      "13:\tlearn: 0.3243403\ttotal: 482ms\tremaining: 34s\n",
      "14:\tlearn: 0.3193883\ttotal: 511ms\tremaining: 33.5s\n",
      "15:\tlearn: 0.3152606\ttotal: 536ms\tremaining: 33s\n",
      "16:\tlearn: 0.3117148\ttotal: 560ms\tremaining: 32.4s\n",
      "17:\tlearn: 0.3086310\ttotal: 588ms\tremaining: 32.1s\n",
      "18:\tlearn: 0.3059481\ttotal: 604ms\tremaining: 31.2s\n",
      "19:\tlearn: 0.3033872\ttotal: 626ms\tremaining: 30.7s\n",
      "20:\tlearn: 0.3012443\ttotal: 645ms\tremaining: 30.1s\n",
      "21:\tlearn: 0.2991691\ttotal: 663ms\tremaining: 29.5s\n",
      "22:\tlearn: 0.2974825\ttotal: 681ms\tremaining: 28.9s\n",
      "23:\tlearn: 0.2957783\ttotal: 699ms\tremaining: 28.4s\n",
      "24:\tlearn: 0.2942922\ttotal: 716ms\tremaining: 27.9s\n",
      "25:\tlearn: 0.2929927\ttotal: 733ms\tremaining: 27.5s\n",
      "26:\tlearn: 0.2917219\ttotal: 751ms\tremaining: 27.1s\n",
      "27:\tlearn: 0.2905227\ttotal: 769ms\tremaining: 26.7s\n",
      "28:\tlearn: 0.2893693\ttotal: 786ms\tremaining: 26.3s\n",
      "29:\tlearn: 0.2882321\ttotal: 804ms\tremaining: 26s\n",
      "30:\tlearn: 0.2872530\ttotal: 822ms\tremaining: 25.7s\n",
      "31:\tlearn: 0.2862326\ttotal: 842ms\tremaining: 25.5s\n",
      "32:\tlearn: 0.2852704\ttotal: 859ms\tremaining: 25.2s\n",
      "33:\tlearn: 0.2843875\ttotal: 878ms\tremaining: 24.9s\n",
      "34:\tlearn: 0.2835537\ttotal: 895ms\tremaining: 24.7s\n",
      "35:\tlearn: 0.2827298\ttotal: 914ms\tremaining: 24.5s\n",
      "36:\tlearn: 0.2818909\ttotal: 932ms\tremaining: 24.3s\n",
      "37:\tlearn: 0.2810186\ttotal: 952ms\tremaining: 24.1s\n",
      "38:\tlearn: 0.2802192\ttotal: 973ms\tremaining: 24s\n",
      "39:\tlearn: 0.2794438\ttotal: 991ms\tremaining: 23.8s\n",
      "40:\tlearn: 0.2786654\ttotal: 1.01s\tremaining: 23.6s\n",
      "41:\tlearn: 0.2779133\ttotal: 1.03s\tremaining: 23.4s\n",
      "42:\tlearn: 0.2772067\ttotal: 1.04s\tremaining: 23.2s\n",
      "43:\tlearn: 0.2765154\ttotal: 1.06s\tremaining: 23s\n",
      "44:\tlearn: 0.2759033\ttotal: 1.08s\tremaining: 22.9s\n",
      "45:\tlearn: 0.2752147\ttotal: 1.1s\tremaining: 22.7s\n",
      "46:\tlearn: 0.2745399\ttotal: 1.11s\tremaining: 22.6s\n",
      "47:\tlearn: 0.2738832\ttotal: 1.13s\tremaining: 22.5s\n",
      "48:\tlearn: 0.2732271\ttotal: 1.15s\tremaining: 22.3s\n",
      "49:\tlearn: 0.2725295\ttotal: 1.17s\tremaining: 22.3s\n",
      "50:\tlearn: 0.2718497\ttotal: 1.19s\tremaining: 22.1s\n",
      "51:\tlearn: 0.2712693\ttotal: 1.21s\tremaining: 22s\n",
      "52:\tlearn: 0.2706994\ttotal: 1.22s\tremaining: 21.9s\n",
      "53:\tlearn: 0.2700826\ttotal: 1.25s\tremaining: 21.8s\n",
      "54:\tlearn: 0.2694503\ttotal: 1.26s\tremaining: 21.7s\n",
      "55:\tlearn: 0.2688903\ttotal: 1.28s\tremaining: 21.6s\n",
      "56:\tlearn: 0.2683014\ttotal: 1.3s\tremaining: 21.5s\n",
      "57:\tlearn: 0.2677580\ttotal: 1.32s\tremaining: 21.4s\n",
      "58:\tlearn: 0.2671705\ttotal: 1.33s\tremaining: 21.3s\n",
      "59:\tlearn: 0.2666001\ttotal: 1.35s\tremaining: 21.2s\n",
      "60:\tlearn: 0.2660551\ttotal: 1.37s\tremaining: 21.1s\n",
      "61:\tlearn: 0.2654760\ttotal: 1.39s\tremaining: 21s\n",
      "62:\tlearn: 0.2648510\ttotal: 1.43s\tremaining: 21.3s\n",
      "63:\tlearn: 0.2643628\ttotal: 1.46s\tremaining: 21.4s\n",
      "64:\tlearn: 0.2638588\ttotal: 1.48s\tremaining: 21.3s\n",
      "65:\tlearn: 0.2633530\ttotal: 1.5s\tremaining: 21.2s\n",
      "66:\tlearn: 0.2628333\ttotal: 1.52s\tremaining: 21.2s\n",
      "67:\tlearn: 0.2623283\ttotal: 1.54s\tremaining: 21.1s\n",
      "68:\tlearn: 0.2618281\ttotal: 1.55s\tremaining: 21s\n",
      "69:\tlearn: 0.2613359\ttotal: 1.57s\tremaining: 20.9s\n",
      "70:\tlearn: 0.2608543\ttotal: 1.59s\tremaining: 20.8s\n",
      "71:\tlearn: 0.2603350\ttotal: 1.61s\tremaining: 20.8s\n",
      "72:\tlearn: 0.2598310\ttotal: 1.63s\tremaining: 20.7s\n",
      "73:\tlearn: 0.2593259\ttotal: 1.65s\tremaining: 20.7s\n",
      "74:\tlearn: 0.2588538\ttotal: 1.67s\tremaining: 20.6s\n",
      "75:\tlearn: 0.2584164\ttotal: 1.69s\tremaining: 20.5s\n",
      "76:\tlearn: 0.2579795\ttotal: 1.71s\tremaining: 20.5s\n",
      "77:\tlearn: 0.2575234\ttotal: 1.72s\tremaining: 20.4s\n",
      "78:\tlearn: 0.2570890\ttotal: 1.74s\tremaining: 20.3s\n",
      "79:\tlearn: 0.2566323\ttotal: 1.76s\tremaining: 20.2s\n",
      "80:\tlearn: 0.2562309\ttotal: 1.78s\tremaining: 20.2s\n",
      "81:\tlearn: 0.2558193\ttotal: 1.81s\tremaining: 20.2s\n",
      "82:\tlearn: 0.2554138\ttotal: 1.83s\tremaining: 20.2s\n",
      "83:\tlearn: 0.2550101\ttotal: 1.85s\tremaining: 20.2s\n",
      "84:\tlearn: 0.2545643\ttotal: 1.87s\tremaining: 20.1s\n",
      "85:\tlearn: 0.2541402\ttotal: 1.89s\tremaining: 20.1s\n",
      "86:\tlearn: 0.2537521\ttotal: 1.91s\tremaining: 20.1s\n",
      "87:\tlearn: 0.2533649\ttotal: 1.94s\tremaining: 20.1s\n",
      "88:\tlearn: 0.2529591\ttotal: 1.96s\tremaining: 20s\n",
      "89:\tlearn: 0.2525656\ttotal: 1.98s\tremaining: 20s\n",
      "90:\tlearn: 0.2521694\ttotal: 2s\tremaining: 20s\n",
      "91:\tlearn: 0.2518005\ttotal: 2.02s\tremaining: 19.9s\n",
      "92:\tlearn: 0.2514067\ttotal: 2.04s\tremaining: 19.9s\n",
      "93:\tlearn: 0.2510270\ttotal: 2.06s\tremaining: 19.9s\n",
      "94:\tlearn: 0.2506572\ttotal: 2.08s\tremaining: 19.9s\n",
      "95:\tlearn: 0.2502620\ttotal: 2.11s\tremaining: 19.8s\n",
      "96:\tlearn: 0.2498757\ttotal: 2.13s\tremaining: 19.8s\n",
      "97:\tlearn: 0.2495069\ttotal: 2.15s\tremaining: 19.8s\n",
      "98:\tlearn: 0.2491400\ttotal: 2.17s\tremaining: 19.7s\n",
      "99:\tlearn: 0.2487787\ttotal: 2.19s\tremaining: 19.7s\n",
      "100:\tlearn: 0.2484330\ttotal: 2.21s\tremaining: 19.7s\n",
      "101:\tlearn: 0.2480878\ttotal: 2.23s\tremaining: 19.6s\n",
      "102:\tlearn: 0.2477098\ttotal: 2.25s\tremaining: 19.6s\n",
      "103:\tlearn: 0.2473489\ttotal: 2.27s\tremaining: 19.6s\n",
      "104:\tlearn: 0.2469778\ttotal: 2.29s\tremaining: 19.5s\n",
      "105:\tlearn: 0.2466296\ttotal: 2.31s\tremaining: 19.5s\n",
      "106:\tlearn: 0.2462492\ttotal: 2.33s\tremaining: 19.5s\n",
      "107:\tlearn: 0.2458972\ttotal: 2.35s\tremaining: 19.5s\n",
      "108:\tlearn: 0.2455397\ttotal: 2.38s\tremaining: 19.5s\n",
      "109:\tlearn: 0.2452313\ttotal: 2.4s\tremaining: 19.4s\n",
      "110:\tlearn: 0.2449055\ttotal: 2.42s\tremaining: 19.4s\n",
      "111:\tlearn: 0.2445684\ttotal: 2.44s\tremaining: 19.3s\n",
      "112:\tlearn: 0.2442497\ttotal: 2.46s\tremaining: 19.3s\n",
      "113:\tlearn: 0.2439031\ttotal: 2.48s\tremaining: 19.3s\n",
      "114:\tlearn: 0.2435838\ttotal: 2.5s\tremaining: 19.2s\n",
      "115:\tlearn: 0.2432811\ttotal: 2.52s\tremaining: 19.2s\n",
      "116:\tlearn: 0.2429657\ttotal: 2.53s\tremaining: 19.1s\n",
      "117:\tlearn: 0.2426452\ttotal: 2.55s\tremaining: 19.1s\n",
      "118:\tlearn: 0.2423339\ttotal: 2.57s\tremaining: 19s\n",
      "119:\tlearn: 0.2420522\ttotal: 2.59s\tremaining: 19s\n",
      "120:\tlearn: 0.2417546\ttotal: 2.61s\tremaining: 19s\n",
      "121:\tlearn: 0.2414249\ttotal: 2.63s\tremaining: 18.9s\n",
      "122:\tlearn: 0.2411364\ttotal: 2.65s\tremaining: 18.9s\n",
      "123:\tlearn: 0.2408209\ttotal: 2.67s\tremaining: 18.8s\n",
      "124:\tlearn: 0.2404993\ttotal: 2.69s\tremaining: 18.8s\n",
      "125:\tlearn: 0.2402118\ttotal: 2.71s\tremaining: 18.8s\n",
      "126:\tlearn: 0.2399424\ttotal: 2.74s\tremaining: 18.9s\n",
      "127:\tlearn: 0.2396648\ttotal: 2.76s\tremaining: 18.8s\n",
      "128:\tlearn: 0.2393771\ttotal: 2.78s\tremaining: 18.8s\n",
      "129:\tlearn: 0.2390898\ttotal: 2.86s\tremaining: 19.2s\n",
      "130:\tlearn: 0.2387740\ttotal: 2.9s\tremaining: 19.2s\n",
      "131:\tlearn: 0.2384501\ttotal: 2.92s\tremaining: 19.2s\n",
      "132:\tlearn: 0.2381604\ttotal: 2.95s\tremaining: 19.2s\n",
      "133:\tlearn: 0.2378762\ttotal: 2.98s\tremaining: 19.2s\n",
      "134:\tlearn: 0.2376020\ttotal: 3s\tremaining: 19.3s\n",
      "135:\tlearn: 0.2373282\ttotal: 3.03s\tremaining: 19.3s\n",
      "136:\tlearn: 0.2370486\ttotal: 3.06s\tremaining: 19.3s\n",
      "137:\tlearn: 0.2367755\ttotal: 3.09s\tremaining: 19.3s\n",
      "138:\tlearn: 0.2364942\ttotal: 3.12s\tremaining: 19.3s\n",
      "139:\tlearn: 0.2362027\ttotal: 3.14s\tremaining: 19.3s\n",
      "140:\tlearn: 0.2359327\ttotal: 3.17s\tremaining: 19.3s\n",
      "141:\tlearn: 0.2356778\ttotal: 3.19s\tremaining: 19.3s\n",
      "142:\tlearn: 0.2354024\ttotal: 3.22s\tremaining: 19.3s\n",
      "143:\tlearn: 0.2351287\ttotal: 3.25s\tremaining: 19.3s\n",
      "144:\tlearn: 0.2348724\ttotal: 3.27s\tremaining: 19.3s\n",
      "145:\tlearn: 0.2346024\ttotal: 3.29s\tremaining: 19.3s\n",
      "146:\tlearn: 0.2343532\ttotal: 3.31s\tremaining: 19.2s\n",
      "147:\tlearn: 0.2341093\ttotal: 3.33s\tremaining: 19.2s\n",
      "148:\tlearn: 0.2338623\ttotal: 3.35s\tremaining: 19.2s\n",
      "149:\tlearn: 0.2336078\ttotal: 3.38s\tremaining: 19.1s\n",
      "150:\tlearn: 0.2333449\ttotal: 3.4s\tremaining: 19.1s\n",
      "151:\tlearn: 0.2330682\ttotal: 3.42s\tremaining: 19.1s\n",
      "152:\tlearn: 0.2328060\ttotal: 3.45s\tremaining: 19.1s\n",
      "153:\tlearn: 0.2325614\ttotal: 3.47s\tremaining: 19s\n",
      "154:\tlearn: 0.2323055\ttotal: 3.49s\tremaining: 19s\n",
      "155:\tlearn: 0.2320331\ttotal: 3.51s\tremaining: 19s\n",
      "156:\tlearn: 0.2317647\ttotal: 3.53s\tremaining: 19s\n",
      "157:\tlearn: 0.2315024\ttotal: 3.55s\tremaining: 18.9s\n",
      "158:\tlearn: 0.2312612\ttotal: 3.57s\tremaining: 18.9s\n",
      "159:\tlearn: 0.2310153\ttotal: 3.59s\tremaining: 18.8s\n",
      "160:\tlearn: 0.2307490\ttotal: 3.61s\tremaining: 18.8s\n",
      "161:\tlearn: 0.2304898\ttotal: 3.63s\tremaining: 18.8s\n",
      "162:\tlearn: 0.2302283\ttotal: 3.65s\tremaining: 18.7s\n",
      "163:\tlearn: 0.2299891\ttotal: 3.67s\tremaining: 18.7s\n",
      "164:\tlearn: 0.2297357\ttotal: 3.69s\tremaining: 18.7s\n",
      "165:\tlearn: 0.2295041\ttotal: 3.71s\tremaining: 18.6s\n",
      "166:\tlearn: 0.2292576\ttotal: 3.73s\tremaining: 18.6s\n",
      "167:\tlearn: 0.2289991\ttotal: 3.75s\tremaining: 18.6s\n",
      "168:\tlearn: 0.2287791\ttotal: 3.77s\tremaining: 18.5s\n",
      "169:\tlearn: 0.2285512\ttotal: 3.79s\tremaining: 18.5s\n",
      "170:\tlearn: 0.2283139\ttotal: 3.8s\tremaining: 18.4s\n",
      "171:\tlearn: 0.2280636\ttotal: 3.82s\tremaining: 18.4s\n",
      "172:\tlearn: 0.2278401\ttotal: 3.84s\tremaining: 18.4s\n",
      "173:\tlearn: 0.2276338\ttotal: 3.86s\tremaining: 18.3s\n",
      "174:\tlearn: 0.2273906\ttotal: 3.88s\tremaining: 18.3s\n",
      "175:\tlearn: 0.2271510\ttotal: 3.9s\tremaining: 18.3s\n",
      "176:\tlearn: 0.2269292\ttotal: 3.92s\tremaining: 18.3s\n",
      "177:\tlearn: 0.2267041\ttotal: 3.94s\tremaining: 18.2s\n",
      "178:\tlearn: 0.2264635\ttotal: 3.97s\tremaining: 18.2s\n",
      "179:\tlearn: 0.2262348\ttotal: 3.99s\tremaining: 18.2s\n",
      "180:\tlearn: 0.2259971\ttotal: 4s\tremaining: 18.1s\n",
      "181:\tlearn: 0.2257573\ttotal: 4.03s\tremaining: 18.1s\n",
      "182:\tlearn: 0.2255303\ttotal: 4.04s\tremaining: 18.1s\n",
      "183:\tlearn: 0.2253073\ttotal: 4.06s\tremaining: 18s\n",
      "184:\tlearn: 0.2250857\ttotal: 4.08s\tremaining: 18s\n",
      "185:\tlearn: 0.2248479\ttotal: 4.11s\tremaining: 18s\n",
      "186:\tlearn: 0.2246250\ttotal: 4.13s\tremaining: 17.9s\n",
      "187:\tlearn: 0.2244149\ttotal: 4.14s\tremaining: 17.9s\n",
      "188:\tlearn: 0.2241843\ttotal: 4.17s\tremaining: 17.9s\n",
      "189:\tlearn: 0.2239581\ttotal: 4.18s\tremaining: 17.8s\n",
      "190:\tlearn: 0.2237484\ttotal: 4.2s\tremaining: 17.8s\n",
      "191:\tlearn: 0.2235450\ttotal: 4.22s\tremaining: 17.8s\n",
      "192:\tlearn: 0.2233322\ttotal: 4.24s\tremaining: 17.7s\n",
      "193:\tlearn: 0.2231118\ttotal: 4.26s\tremaining: 17.7s\n",
      "194:\tlearn: 0.2229178\ttotal: 4.28s\tremaining: 17.7s\n",
      "195:\tlearn: 0.2226784\ttotal: 4.3s\tremaining: 17.6s\n",
      "196:\tlearn: 0.2224501\ttotal: 4.32s\tremaining: 17.6s\n",
      "197:\tlearn: 0.2222234\ttotal: 4.34s\tremaining: 17.6s\n",
      "198:\tlearn: 0.2220166\ttotal: 4.37s\tremaining: 17.6s\n",
      "199:\tlearn: 0.2218029\ttotal: 4.39s\tremaining: 17.6s\n",
      "200:\tlearn: 0.2215848\ttotal: 4.42s\tremaining: 17.6s\n",
      "201:\tlearn: 0.2213634\ttotal: 4.44s\tremaining: 17.5s\n",
      "202:\tlearn: 0.2211655\ttotal: 4.47s\tremaining: 17.5s\n",
      "203:\tlearn: 0.2209499\ttotal: 4.5s\tremaining: 17.6s\n",
      "204:\tlearn: 0.2207270\ttotal: 4.53s\tremaining: 17.6s\n",
      "205:\tlearn: 0.2205189\ttotal: 4.56s\tremaining: 17.6s\n",
      "206:\tlearn: 0.2203123\ttotal: 4.58s\tremaining: 17.6s\n",
      "207:\tlearn: 0.2201239\ttotal: 4.6s\tremaining: 17.5s\n",
      "208:\tlearn: 0.2199045\ttotal: 4.63s\tremaining: 17.5s\n",
      "209:\tlearn: 0.2196760\ttotal: 4.66s\tremaining: 17.5s\n",
      "210:\tlearn: 0.2194582\ttotal: 4.68s\tremaining: 17.5s\n",
      "211:\tlearn: 0.2192497\ttotal: 4.7s\tremaining: 17.5s\n",
      "212:\tlearn: 0.2190532\ttotal: 4.72s\tremaining: 17.4s\n",
      "213:\tlearn: 0.2188814\ttotal: 4.74s\tremaining: 17.4s\n",
      "214:\tlearn: 0.2186697\ttotal: 4.77s\tremaining: 17.4s\n",
      "215:\tlearn: 0.2184681\ttotal: 4.79s\tremaining: 17.4s\n",
      "216:\tlearn: 0.2182934\ttotal: 4.82s\tremaining: 17.4s\n",
      "217:\tlearn: 0.2181024\ttotal: 4.84s\tremaining: 17.4s\n",
      "218:\tlearn: 0.2179112\ttotal: 4.87s\tremaining: 17.4s\n",
      "219:\tlearn: 0.2177170\ttotal: 4.89s\tremaining: 17.4s\n",
      "220:\tlearn: 0.2175308\ttotal: 4.92s\tremaining: 17.3s\n",
      "221:\tlearn: 0.2173391\ttotal: 4.95s\tremaining: 17.3s\n",
      "222:\tlearn: 0.2171650\ttotal: 4.97s\tremaining: 17.3s\n",
      "223:\tlearn: 0.2169714\ttotal: 5s\tremaining: 17.3s\n",
      "224:\tlearn: 0.2167815\ttotal: 5.02s\tremaining: 17.3s\n",
      "225:\tlearn: 0.2165799\ttotal: 5.05s\tremaining: 17.3s\n",
      "226:\tlearn: 0.2164115\ttotal: 5.07s\tremaining: 17.3s\n",
      "227:\tlearn: 0.2162138\ttotal: 5.1s\tremaining: 17.3s\n",
      "228:\tlearn: 0.2160334\ttotal: 5.12s\tremaining: 17.2s\n",
      "229:\tlearn: 0.2158447\ttotal: 5.15s\tremaining: 17.2s\n",
      "230:\tlearn: 0.2156578\ttotal: 5.17s\tremaining: 17.2s\n",
      "231:\tlearn: 0.2154768\ttotal: 5.2s\tremaining: 17.2s\n",
      "232:\tlearn: 0.2153010\ttotal: 5.22s\tremaining: 17.2s\n",
      "233:\tlearn: 0.2151144\ttotal: 5.24s\tremaining: 17.2s\n",
      "234:\tlearn: 0.2149362\ttotal: 5.26s\tremaining: 17.1s\n",
      "235:\tlearn: 0.2147561\ttotal: 5.29s\tremaining: 17.1s\n",
      "236:\tlearn: 0.2145764\ttotal: 5.31s\tremaining: 17.1s\n",
      "237:\tlearn: 0.2143927\ttotal: 5.34s\tremaining: 17.1s\n",
      "238:\tlearn: 0.2142225\ttotal: 5.36s\tremaining: 17.1s\n",
      "239:\tlearn: 0.2140352\ttotal: 5.39s\tremaining: 17.1s\n",
      "240:\tlearn: 0.2138605\ttotal: 5.41s\tremaining: 17s\n",
      "241:\tlearn: 0.2136863\ttotal: 5.43s\tremaining: 17s\n",
      "242:\tlearn: 0.2135190\ttotal: 5.46s\tremaining: 17s\n",
      "243:\tlearn: 0.2133459\ttotal: 5.49s\tremaining: 17s\n",
      "244:\tlearn: 0.2131627\ttotal: 5.51s\tremaining: 17s\n",
      "245:\tlearn: 0.2129850\ttotal: 5.54s\tremaining: 17s\n",
      "246:\tlearn: 0.2128152\ttotal: 5.56s\tremaining: 17s\n",
      "247:\tlearn: 0.2126465\ttotal: 5.58s\tremaining: 16.9s\n",
      "248:\tlearn: 0.2124721\ttotal: 5.61s\tremaining: 16.9s\n",
      "249:\tlearn: 0.2123175\ttotal: 5.63s\tremaining: 16.9s\n",
      "250:\tlearn: 0.2121400\ttotal: 5.66s\tremaining: 16.9s\n",
      "251:\tlearn: 0.2119900\ttotal: 5.68s\tremaining: 16.9s\n",
      "252:\tlearn: 0.2118114\ttotal: 5.71s\tremaining: 16.9s\n",
      "253:\tlearn: 0.2116374\ttotal: 5.74s\tremaining: 16.8s\n",
      "254:\tlearn: 0.2114608\ttotal: 5.76s\tremaining: 16.8s\n",
      "255:\tlearn: 0.2112918\ttotal: 5.79s\tremaining: 16.8s\n",
      "256:\tlearn: 0.2111243\ttotal: 5.81s\tremaining: 16.8s\n",
      "257:\tlearn: 0.2109597\ttotal: 5.84s\tremaining: 16.8s\n",
      "258:\tlearn: 0.2107981\ttotal: 5.86s\tremaining: 16.8s\n",
      "259:\tlearn: 0.2106346\ttotal: 5.88s\tremaining: 16.7s\n",
      "260:\tlearn: 0.2104569\ttotal: 5.91s\tremaining: 16.7s\n",
      "261:\tlearn: 0.2102970\ttotal: 5.93s\tremaining: 16.7s\n",
      "262:\tlearn: 0.2101526\ttotal: 5.95s\tremaining: 16.7s\n",
      "263:\tlearn: 0.2099906\ttotal: 5.97s\tremaining: 16.7s\n",
      "264:\tlearn: 0.2098225\ttotal: 6s\tremaining: 16.6s\n",
      "265:\tlearn: 0.2096729\ttotal: 6.01s\tremaining: 16.6s\n",
      "266:\tlearn: 0.2095020\ttotal: 6.03s\tremaining: 16.6s\n",
      "267:\tlearn: 0.2093356\ttotal: 6.05s\tremaining: 16.5s\n",
      "268:\tlearn: 0.2091825\ttotal: 6.08s\tremaining: 16.5s\n",
      "269:\tlearn: 0.2090190\ttotal: 6.1s\tremaining: 16.5s\n",
      "270:\tlearn: 0.2088662\ttotal: 6.12s\tremaining: 16.5s\n",
      "271:\tlearn: 0.2086966\ttotal: 6.14s\tremaining: 16.4s\n",
      "272:\tlearn: 0.2085467\ttotal: 6.17s\tremaining: 16.4s\n",
      "273:\tlearn: 0.2083793\ttotal: 6.19s\tremaining: 16.4s\n",
      "274:\tlearn: 0.2082250\ttotal: 6.22s\tremaining: 16.4s\n",
      "275:\tlearn: 0.2080776\ttotal: 6.24s\tremaining: 16.4s\n",
      "276:\tlearn: 0.2079430\ttotal: 6.26s\tremaining: 16.3s\n",
      "277:\tlearn: 0.2078031\ttotal: 6.34s\tremaining: 16.5s\n",
      "278:\tlearn: 0.2076441\ttotal: 6.37s\tremaining: 16.4s\n",
      "279:\tlearn: 0.2075063\ttotal: 6.39s\tremaining: 16.4s\n",
      "280:\tlearn: 0.2073456\ttotal: 6.41s\tremaining: 16.4s\n",
      "281:\tlearn: 0.2071864\ttotal: 6.44s\tremaining: 16.4s\n",
      "282:\tlearn: 0.2070475\ttotal: 6.46s\tremaining: 16.4s\n",
      "283:\tlearn: 0.2069081\ttotal: 6.48s\tremaining: 16.3s\n",
      "284:\tlearn: 0.2067506\ttotal: 6.5s\tremaining: 16.3s\n",
      "285:\tlearn: 0.2065922\ttotal: 6.52s\tremaining: 16.3s\n",
      "286:\tlearn: 0.2064396\ttotal: 6.54s\tremaining: 16.3s\n",
      "287:\tlearn: 0.2062904\ttotal: 6.57s\tremaining: 16.2s\n",
      "288:\tlearn: 0.2061283\ttotal: 6.6s\tremaining: 16.2s\n",
      "289:\tlearn: 0.2059722\ttotal: 6.63s\tremaining: 16.2s\n",
      "290:\tlearn: 0.2058357\ttotal: 6.65s\tremaining: 16.2s\n",
      "291:\tlearn: 0.2056706\ttotal: 6.67s\tremaining: 16.2s\n",
      "292:\tlearn: 0.2055251\ttotal: 6.7s\tremaining: 16.2s\n",
      "293:\tlearn: 0.2053701\ttotal: 6.72s\tremaining: 16.1s\n",
      "294:\tlearn: 0.2052246\ttotal: 6.75s\tremaining: 16.1s\n",
      "295:\tlearn: 0.2050699\ttotal: 6.76s\tremaining: 16.1s\n",
      "296:\tlearn: 0.2049134\ttotal: 6.79s\tremaining: 16.1s\n",
      "297:\tlearn: 0.2047504\ttotal: 6.81s\tremaining: 16s\n",
      "298:\tlearn: 0.2046160\ttotal: 6.83s\tremaining: 16s\n",
      "299:\tlearn: 0.2044692\ttotal: 6.85s\tremaining: 16s\n",
      "300:\tlearn: 0.2043369\ttotal: 6.87s\tremaining: 16s\n",
      "301:\tlearn: 0.2042097\ttotal: 6.89s\tremaining: 15.9s\n",
      "302:\tlearn: 0.2040764\ttotal: 6.91s\tremaining: 15.9s\n",
      "303:\tlearn: 0.2039281\ttotal: 6.93s\tremaining: 15.9s\n",
      "304:\tlearn: 0.2037713\ttotal: 6.95s\tremaining: 15.8s\n",
      "305:\tlearn: 0.2036197\ttotal: 6.97s\tremaining: 15.8s\n",
      "306:\tlearn: 0.2034745\ttotal: 6.99s\tremaining: 15.8s\n",
      "307:\tlearn: 0.2033223\ttotal: 7.01s\tremaining: 15.8s\n",
      "308:\tlearn: 0.2031563\ttotal: 7.03s\tremaining: 15.7s\n",
      "309:\tlearn: 0.2030165\ttotal: 7.05s\tremaining: 15.7s\n",
      "310:\tlearn: 0.2028881\ttotal: 7.07s\tremaining: 15.7s\n",
      "311:\tlearn: 0.2027529\ttotal: 7.09s\tremaining: 15.6s\n",
      "312:\tlearn: 0.2026289\ttotal: 7.11s\tremaining: 15.6s\n",
      "313:\tlearn: 0.2024976\ttotal: 7.13s\tremaining: 15.6s\n",
      "314:\tlearn: 0.2023522\ttotal: 7.16s\tremaining: 15.6s\n",
      "315:\tlearn: 0.2022167\ttotal: 7.18s\tremaining: 15.5s\n",
      "316:\tlearn: 0.2020848\ttotal: 7.2s\tremaining: 15.5s\n",
      "317:\tlearn: 0.2019532\ttotal: 7.23s\tremaining: 15.5s\n",
      "318:\tlearn: 0.2018093\ttotal: 7.25s\tremaining: 15.5s\n",
      "319:\tlearn: 0.2016810\ttotal: 7.28s\tremaining: 15.5s\n",
      "320:\tlearn: 0.2015480\ttotal: 7.3s\tremaining: 15.4s\n",
      "321:\tlearn: 0.2014085\ttotal: 7.32s\tremaining: 15.4s\n",
      "322:\tlearn: 0.2012558\ttotal: 7.34s\tremaining: 15.4s\n",
      "323:\tlearn: 0.2011294\ttotal: 7.36s\tremaining: 15.4s\n",
      "324:\tlearn: 0.2009904\ttotal: 7.38s\tremaining: 15.3s\n",
      "325:\tlearn: 0.2008544\ttotal: 7.4s\tremaining: 15.3s\n",
      "326:\tlearn: 0.2007219\ttotal: 7.42s\tremaining: 15.3s\n",
      "327:\tlearn: 0.2005936\ttotal: 7.44s\tremaining: 15.2s\n",
      "328:\tlearn: 0.2004681\ttotal: 7.46s\tremaining: 15.2s\n",
      "329:\tlearn: 0.2003216\ttotal: 7.48s\tremaining: 15.2s\n",
      "330:\tlearn: 0.2001678\ttotal: 7.5s\tremaining: 15.2s\n",
      "331:\tlearn: 0.2000335\ttotal: 7.52s\tremaining: 15.1s\n",
      "332:\tlearn: 0.1999159\ttotal: 7.54s\tremaining: 15.1s\n",
      "333:\tlearn: 0.1997809\ttotal: 7.57s\tremaining: 15.1s\n",
      "334:\tlearn: 0.1996486\ttotal: 7.59s\tremaining: 15.1s\n",
      "335:\tlearn: 0.1995088\ttotal: 7.62s\tremaining: 15s\n",
      "336:\tlearn: 0.1993914\ttotal: 7.64s\tremaining: 15s\n",
      "337:\tlearn: 0.1992617\ttotal: 7.66s\tremaining: 15s\n",
      "338:\tlearn: 0.1991217\ttotal: 7.69s\tremaining: 15s\n",
      "339:\tlearn: 0.1989877\ttotal: 7.72s\tremaining: 15s\n",
      "340:\tlearn: 0.1988517\ttotal: 7.74s\tremaining: 15s\n",
      "341:\tlearn: 0.1987189\ttotal: 7.76s\tremaining: 14.9s\n",
      "342:\tlearn: 0.1985972\ttotal: 7.79s\tremaining: 14.9s\n",
      "343:\tlearn: 0.1984620\ttotal: 7.82s\tremaining: 14.9s\n",
      "344:\tlearn: 0.1983448\ttotal: 7.84s\tremaining: 14.9s\n",
      "345:\tlearn: 0.1982107\ttotal: 7.87s\tremaining: 14.9s\n",
      "346:\tlearn: 0.1980691\ttotal: 7.89s\tremaining: 14.9s\n",
      "347:\tlearn: 0.1979364\ttotal: 7.92s\tremaining: 14.8s\n",
      "348:\tlearn: 0.1978009\ttotal: 7.94s\tremaining: 14.8s\n",
      "349:\tlearn: 0.1976702\ttotal: 7.96s\tremaining: 14.8s\n",
      "350:\tlearn: 0.1975396\ttotal: 7.98s\tremaining: 14.8s\n",
      "351:\tlearn: 0.1974229\ttotal: 8.01s\tremaining: 14.7s\n",
      "352:\tlearn: 0.1972934\ttotal: 8.04s\tremaining: 14.7s\n",
      "353:\tlearn: 0.1971639\ttotal: 8.06s\tremaining: 14.7s\n",
      "354:\tlearn: 0.1970463\ttotal: 8.08s\tremaining: 14.7s\n",
      "355:\tlearn: 0.1969092\ttotal: 8.11s\tremaining: 14.7s\n",
      "356:\tlearn: 0.1967813\ttotal: 8.13s\tremaining: 14.6s\n",
      "357:\tlearn: 0.1966731\ttotal: 8.15s\tremaining: 14.6s\n",
      "358:\tlearn: 0.1965493\ttotal: 8.18s\tremaining: 14.6s\n",
      "359:\tlearn: 0.1964257\ttotal: 8.2s\tremaining: 14.6s\n",
      "360:\tlearn: 0.1962958\ttotal: 8.22s\tremaining: 14.6s\n",
      "361:\tlearn: 0.1961775\ttotal: 8.24s\tremaining: 14.5s\n",
      "362:\tlearn: 0.1960493\ttotal: 8.27s\tremaining: 14.5s\n",
      "363:\tlearn: 0.1959292\ttotal: 8.29s\tremaining: 14.5s\n",
      "364:\tlearn: 0.1958011\ttotal: 8.32s\tremaining: 14.5s\n",
      "365:\tlearn: 0.1956804\ttotal: 8.34s\tremaining: 14.5s\n",
      "366:\tlearn: 0.1955672\ttotal: 8.37s\tremaining: 14.4s\n",
      "367:\tlearn: 0.1954559\ttotal: 8.39s\tremaining: 14.4s\n",
      "368:\tlearn: 0.1953509\ttotal: 8.41s\tremaining: 14.4s\n",
      "369:\tlearn: 0.1952173\ttotal: 8.43s\tremaining: 14.4s\n",
      "370:\tlearn: 0.1951001\ttotal: 8.45s\tremaining: 14.3s\n",
      "371:\tlearn: 0.1949764\ttotal: 8.48s\tremaining: 14.3s\n",
      "372:\tlearn: 0.1948573\ttotal: 8.5s\tremaining: 14.3s\n",
      "373:\tlearn: 0.1947387\ttotal: 8.52s\tremaining: 14.3s\n",
      "374:\tlearn: 0.1946321\ttotal: 8.55s\tremaining: 14.2s\n",
      "375:\tlearn: 0.1945098\ttotal: 8.57s\tremaining: 14.2s\n",
      "376:\tlearn: 0.1943862\ttotal: 8.6s\tremaining: 14.2s\n",
      "377:\tlearn: 0.1942794\ttotal: 8.62s\tremaining: 14.2s\n",
      "378:\tlearn: 0.1941782\ttotal: 8.64s\tremaining: 14.2s\n",
      "379:\tlearn: 0.1940656\ttotal: 8.67s\tremaining: 14.1s\n",
      "380:\tlearn: 0.1939541\ttotal: 8.69s\tremaining: 14.1s\n",
      "381:\tlearn: 0.1938449\ttotal: 8.72s\tremaining: 14.1s\n",
      "382:\tlearn: 0.1937294\ttotal: 8.74s\tremaining: 14.1s\n",
      "383:\tlearn: 0.1936116\ttotal: 8.77s\tremaining: 14.1s\n",
      "384:\tlearn: 0.1934816\ttotal: 8.79s\tremaining: 14s\n",
      "385:\tlearn: 0.1933616\ttotal: 8.82s\tremaining: 14s\n",
      "386:\tlearn: 0.1932523\ttotal: 8.85s\tremaining: 14s\n",
      "387:\tlearn: 0.1931387\ttotal: 8.87s\tremaining: 14s\n",
      "388:\tlearn: 0.1930037\ttotal: 8.9s\tremaining: 14s\n",
      "389:\tlearn: 0.1928816\ttotal: 8.92s\tremaining: 14s\n",
      "390:\tlearn: 0.1927568\ttotal: 8.95s\tremaining: 13.9s\n",
      "391:\tlearn: 0.1926516\ttotal: 8.97s\tremaining: 13.9s\n",
      "392:\tlearn: 0.1925473\ttotal: 8.98s\tremaining: 13.9s\n",
      "393:\tlearn: 0.1924402\ttotal: 9.01s\tremaining: 13.9s\n",
      "394:\tlearn: 0.1923322\ttotal: 9.03s\tremaining: 13.8s\n",
      "395:\tlearn: 0.1922130\ttotal: 9.05s\tremaining: 13.8s\n",
      "396:\tlearn: 0.1921259\ttotal: 9.08s\tremaining: 13.8s\n",
      "397:\tlearn: 0.1920310\ttotal: 9.1s\tremaining: 13.8s\n",
      "398:\tlearn: 0.1919292\ttotal: 9.12s\tremaining: 13.7s\n",
      "399:\tlearn: 0.1918202\ttotal: 9.14s\tremaining: 13.7s\n",
      "400:\tlearn: 0.1917059\ttotal: 9.17s\tremaining: 13.7s\n",
      "401:\tlearn: 0.1915994\ttotal: 9.19s\tremaining: 13.7s\n",
      "402:\tlearn: 0.1914967\ttotal: 9.21s\tremaining: 13.6s\n",
      "403:\tlearn: 0.1913880\ttotal: 9.23s\tremaining: 13.6s\n",
      "404:\tlearn: 0.1912789\ttotal: 9.26s\tremaining: 13.6s\n",
      "405:\tlearn: 0.1911553\ttotal: 9.28s\tremaining: 13.6s\n",
      "406:\tlearn: 0.1910398\ttotal: 9.31s\tremaining: 13.6s\n",
      "407:\tlearn: 0.1909289\ttotal: 9.33s\tremaining: 13.5s\n",
      "408:\tlearn: 0.1908187\ttotal: 9.35s\tremaining: 13.5s\n",
      "409:\tlearn: 0.1907028\ttotal: 9.38s\tremaining: 13.5s\n",
      "410:\tlearn: 0.1906035\ttotal: 9.4s\tremaining: 13.5s\n",
      "411:\tlearn: 0.1904955\ttotal: 9.42s\tremaining: 13.4s\n",
      "412:\tlearn: 0.1903839\ttotal: 9.44s\tremaining: 13.4s\n",
      "413:\tlearn: 0.1902664\ttotal: 9.46s\tremaining: 13.4s\n",
      "414:\tlearn: 0.1901485\ttotal: 9.48s\tremaining: 13.4s\n",
      "415:\tlearn: 0.1900635\ttotal: 9.51s\tremaining: 13.3s\n",
      "416:\tlearn: 0.1899779\ttotal: 9.53s\tremaining: 13.3s\n",
      "417:\tlearn: 0.1898835\ttotal: 9.55s\tremaining: 13.3s\n",
      "418:\tlearn: 0.1897626\ttotal: 9.58s\tremaining: 13.3s\n",
      "419:\tlearn: 0.1896457\ttotal: 9.6s\tremaining: 13.3s\n",
      "420:\tlearn: 0.1895235\ttotal: 9.62s\tremaining: 13.2s\n",
      "421:\tlearn: 0.1894197\ttotal: 9.65s\tremaining: 13.2s\n",
      "422:\tlearn: 0.1892991\ttotal: 9.68s\tremaining: 13.2s\n",
      "423:\tlearn: 0.1891781\ttotal: 9.7s\tremaining: 13.2s\n",
      "424:\tlearn: 0.1890733\ttotal: 9.72s\tremaining: 13.2s\n",
      "425:\tlearn: 0.1889642\ttotal: 9.75s\tremaining: 13.1s\n",
      "426:\tlearn: 0.1888656\ttotal: 9.78s\tremaining: 13.1s\n",
      "427:\tlearn: 0.1887448\ttotal: 9.8s\tremaining: 13.1s\n",
      "428:\tlearn: 0.1886339\ttotal: 9.83s\tremaining: 13.1s\n",
      "429:\tlearn: 0.1885250\ttotal: 9.85s\tremaining: 13.1s\n",
      "430:\tlearn: 0.1884115\ttotal: 9.87s\tremaining: 13s\n",
      "431:\tlearn: 0.1883014\ttotal: 9.89s\tremaining: 13s\n",
      "432:\tlearn: 0.1881979\ttotal: 9.91s\tremaining: 13s\n",
      "433:\tlearn: 0.1880779\ttotal: 9.94s\tremaining: 13s\n",
      "434:\tlearn: 0.1879888\ttotal: 9.96s\tremaining: 12.9s\n",
      "435:\tlearn: 0.1878831\ttotal: 9.99s\tremaining: 12.9s\n",
      "436:\tlearn: 0.1877658\ttotal: 10s\tremaining: 12.9s\n",
      "437:\tlearn: 0.1876685\ttotal: 10s\tremaining: 12.9s\n",
      "438:\tlearn: 0.1875531\ttotal: 10.1s\tremaining: 12.9s\n",
      "439:\tlearn: 0.1874606\ttotal: 10.1s\tremaining: 12.8s\n",
      "440:\tlearn: 0.1873706\ttotal: 10.1s\tremaining: 12.8s\n",
      "441:\tlearn: 0.1872752\ttotal: 10.1s\tremaining: 12.8s\n",
      "442:\tlearn: 0.1871793\ttotal: 10.2s\tremaining: 12.8s\n",
      "443:\tlearn: 0.1870798\ttotal: 10.2s\tremaining: 12.8s\n",
      "444:\tlearn: 0.1869845\ttotal: 10.2s\tremaining: 12.7s\n",
      "445:\tlearn: 0.1868860\ttotal: 10.2s\tremaining: 12.7s\n",
      "446:\tlearn: 0.1867805\ttotal: 10.3s\tremaining: 12.7s\n",
      "447:\tlearn: 0.1866812\ttotal: 10.3s\tremaining: 12.7s\n",
      "448:\tlearn: 0.1865948\ttotal: 10.3s\tremaining: 12.6s\n",
      "449:\tlearn: 0.1864900\ttotal: 10.3s\tremaining: 12.6s\n",
      "450:\tlearn: 0.1863784\ttotal: 10.3s\tremaining: 12.6s\n",
      "451:\tlearn: 0.1862660\ttotal: 10.4s\tremaining: 12.6s\n",
      "452:\tlearn: 0.1861762\ttotal: 10.4s\tremaining: 12.5s\n",
      "453:\tlearn: 0.1860787\ttotal: 10.4s\tremaining: 12.5s\n",
      "454:\tlearn: 0.1859859\ttotal: 10.4s\tremaining: 12.5s\n",
      "455:\tlearn: 0.1858690\ttotal: 10.4s\tremaining: 12.4s\n",
      "456:\tlearn: 0.1857781\ttotal: 10.4s\tremaining: 12.4s\n",
      "457:\tlearn: 0.1856813\ttotal: 10.5s\tremaining: 12.4s\n",
      "458:\tlearn: 0.1855956\ttotal: 10.5s\tremaining: 12.4s\n",
      "459:\tlearn: 0.1855050\ttotal: 10.5s\tremaining: 12.3s\n",
      "460:\tlearn: 0.1854035\ttotal: 10.5s\tremaining: 12.3s\n",
      "461:\tlearn: 0.1853180\ttotal: 10.6s\tremaining: 12.3s\n",
      "462:\tlearn: 0.1852177\ttotal: 10.6s\tremaining: 12.3s\n",
      "463:\tlearn: 0.1851188\ttotal: 10.6s\tremaining: 12.3s\n",
      "464:\tlearn: 0.1850285\ttotal: 10.6s\tremaining: 12.2s\n",
      "465:\tlearn: 0.1849230\ttotal: 10.7s\tremaining: 12.2s\n",
      "466:\tlearn: 0.1848320\ttotal: 10.7s\tremaining: 12.2s\n",
      "467:\tlearn: 0.1847370\ttotal: 10.7s\tremaining: 12.2s\n",
      "468:\tlearn: 0.1846339\ttotal: 10.7s\tremaining: 12.1s\n",
      "469:\tlearn: 0.1845383\ttotal: 10.7s\tremaining: 12.1s\n",
      "470:\tlearn: 0.1844380\ttotal: 10.8s\tremaining: 12.1s\n",
      "471:\tlearn: 0.1843464\ttotal: 10.8s\tremaining: 12.1s\n",
      "472:\tlearn: 0.1842349\ttotal: 10.8s\tremaining: 12s\n",
      "473:\tlearn: 0.1841389\ttotal: 10.8s\tremaining: 12s\n",
      "474:\tlearn: 0.1840403\ttotal: 10.8s\tremaining: 12s\n",
      "475:\tlearn: 0.1839338\ttotal: 10.9s\tremaining: 12s\n",
      "476:\tlearn: 0.1838426\ttotal: 10.9s\tremaining: 11.9s\n",
      "477:\tlearn: 0.1837619\ttotal: 10.9s\tremaining: 11.9s\n",
      "478:\tlearn: 0.1836564\ttotal: 10.9s\tremaining: 11.9s\n",
      "479:\tlearn: 0.1835576\ttotal: 10.9s\tremaining: 11.9s\n",
      "480:\tlearn: 0.1834551\ttotal: 11s\tremaining: 11.8s\n",
      "481:\tlearn: 0.1833527\ttotal: 11s\tremaining: 11.8s\n",
      "482:\tlearn: 0.1832417\ttotal: 11s\tremaining: 11.8s\n",
      "483:\tlearn: 0.1831421\ttotal: 11s\tremaining: 11.8s\n",
      "484:\tlearn: 0.1830439\ttotal: 11.1s\tremaining: 11.8s\n",
      "485:\tlearn: 0.1829503\ttotal: 11.1s\tremaining: 11.7s\n",
      "486:\tlearn: 0.1828526\ttotal: 11.1s\tremaining: 11.7s\n",
      "487:\tlearn: 0.1827505\ttotal: 11.1s\tremaining: 11.7s\n",
      "488:\tlearn: 0.1826661\ttotal: 11.2s\tremaining: 11.7s\n",
      "489:\tlearn: 0.1825642\ttotal: 11.2s\tremaining: 11.6s\n",
      "490:\tlearn: 0.1824722\ttotal: 11.2s\tremaining: 11.6s\n",
      "491:\tlearn: 0.1823898\ttotal: 11.2s\tremaining: 11.6s\n",
      "492:\tlearn: 0.1822966\ttotal: 11.3s\tremaining: 11.6s\n",
      "493:\tlearn: 0.1822037\ttotal: 11.3s\tremaining: 11.6s\n",
      "494:\tlearn: 0.1821016\ttotal: 11.3s\tremaining: 11.5s\n",
      "495:\tlearn: 0.1819955\ttotal: 11.3s\tremaining: 11.5s\n",
      "496:\tlearn: 0.1818943\ttotal: 11.4s\tremaining: 11.5s\n",
      "497:\tlearn: 0.1818054\ttotal: 11.4s\tremaining: 11.5s\n",
      "498:\tlearn: 0.1817147\ttotal: 11.4s\tremaining: 11.4s\n",
      "499:\tlearn: 0.1816331\ttotal: 11.4s\tremaining: 11.4s\n",
      "500:\tlearn: 0.1815420\ttotal: 11.4s\tremaining: 11.4s\n",
      "501:\tlearn: 0.1814430\ttotal: 11.5s\tremaining: 11.4s\n",
      "502:\tlearn: 0.1813543\ttotal: 11.5s\tremaining: 11.4s\n",
      "503:\tlearn: 0.1812588\ttotal: 11.5s\tremaining: 11.3s\n",
      "504:\tlearn: 0.1811707\ttotal: 11.6s\tremaining: 11.3s\n",
      "505:\tlearn: 0.1810865\ttotal: 11.6s\tremaining: 11.3s\n",
      "506:\tlearn: 0.1809963\ttotal: 11.6s\tremaining: 11.3s\n",
      "507:\tlearn: 0.1808930\ttotal: 11.6s\tremaining: 11.3s\n",
      "508:\tlearn: 0.1807922\ttotal: 11.6s\tremaining: 11.2s\n",
      "509:\tlearn: 0.1807256\ttotal: 11.7s\tremaining: 11.2s\n",
      "510:\tlearn: 0.1806271\ttotal: 11.7s\tremaining: 11.2s\n",
      "511:\tlearn: 0.1805370\ttotal: 11.7s\tremaining: 11.2s\n",
      "512:\tlearn: 0.1804427\ttotal: 11.7s\tremaining: 11.1s\n",
      "513:\tlearn: 0.1803533\ttotal: 11.8s\tremaining: 11.1s\n",
      "514:\tlearn: 0.1802703\ttotal: 11.8s\tremaining: 11.1s\n",
      "515:\tlearn: 0.1801771\ttotal: 11.8s\tremaining: 11.1s\n",
      "516:\tlearn: 0.1800861\ttotal: 11.8s\tremaining: 11.1s\n",
      "517:\tlearn: 0.1800067\ttotal: 11.9s\tremaining: 11s\n",
      "518:\tlearn: 0.1799106\ttotal: 11.9s\tremaining: 11s\n",
      "519:\tlearn: 0.1798283\ttotal: 11.9s\tremaining: 11s\n",
      "520:\tlearn: 0.1797432\ttotal: 11.9s\tremaining: 11s\n",
      "521:\tlearn: 0.1796549\ttotal: 11.9s\tremaining: 10.9s\n",
      "522:\tlearn: 0.1795527\ttotal: 12s\tremaining: 10.9s\n",
      "523:\tlearn: 0.1794648\ttotal: 12s\tremaining: 10.9s\n",
      "524:\tlearn: 0.1793769\ttotal: 12s\tremaining: 10.9s\n",
      "525:\tlearn: 0.1792852\ttotal: 12s\tremaining: 10.8s\n",
      "526:\tlearn: 0.1792101\ttotal: 12s\tremaining: 10.8s\n",
      "527:\tlearn: 0.1791289\ttotal: 12.1s\tremaining: 10.8s\n",
      "528:\tlearn: 0.1790426\ttotal: 12.1s\tremaining: 10.7s\n",
      "529:\tlearn: 0.1789443\ttotal: 12.1s\tremaining: 10.7s\n",
      "530:\tlearn: 0.1788627\ttotal: 12.1s\tremaining: 10.7s\n",
      "531:\tlearn: 0.1787707\ttotal: 12.1s\tremaining: 10.7s\n",
      "532:\tlearn: 0.1786869\ttotal: 12.1s\tremaining: 10.6s\n",
      "533:\tlearn: 0.1786058\ttotal: 12.2s\tremaining: 10.6s\n",
      "534:\tlearn: 0.1785320\ttotal: 12.2s\tremaining: 10.6s\n",
      "535:\tlearn: 0.1784358\ttotal: 12.2s\tremaining: 10.6s\n",
      "536:\tlearn: 0.1783306\ttotal: 12.2s\tremaining: 10.5s\n",
      "537:\tlearn: 0.1782300\ttotal: 12.3s\tremaining: 10.5s\n",
      "538:\tlearn: 0.1781391\ttotal: 12.3s\tremaining: 10.5s\n",
      "539:\tlearn: 0.1780584\ttotal: 12.3s\tremaining: 10.5s\n",
      "540:\tlearn: 0.1779718\ttotal: 12.3s\tremaining: 10.4s\n",
      "541:\tlearn: 0.1779014\ttotal: 12.3s\tremaining: 10.4s\n",
      "542:\tlearn: 0.1778128\ttotal: 12.4s\tremaining: 10.4s\n",
      "543:\tlearn: 0.1777374\ttotal: 12.4s\tremaining: 10.4s\n",
      "544:\tlearn: 0.1776586\ttotal: 12.4s\tremaining: 10.3s\n",
      "545:\tlearn: 0.1775761\ttotal: 12.4s\tremaining: 10.3s\n",
      "546:\tlearn: 0.1774860\ttotal: 12.4s\tremaining: 10.3s\n",
      "547:\tlearn: 0.1774041\ttotal: 12.4s\tremaining: 10.3s\n",
      "548:\tlearn: 0.1773190\ttotal: 12.5s\tremaining: 10.2s\n",
      "549:\tlearn: 0.1772300\ttotal: 12.5s\tremaining: 10.2s\n",
      "550:\tlearn: 0.1771443\ttotal: 12.5s\tremaining: 10.2s\n",
      "551:\tlearn: 0.1770718\ttotal: 12.5s\tremaining: 10.2s\n",
      "552:\tlearn: 0.1769944\ttotal: 12.6s\tremaining: 10.2s\n",
      "553:\tlearn: 0.1769064\ttotal: 12.6s\tremaining: 10.2s\n",
      "554:\tlearn: 0.1768146\ttotal: 12.7s\tremaining: 10.2s\n",
      "555:\tlearn: 0.1767334\ttotal: 12.7s\tremaining: 10.1s\n",
      "556:\tlearn: 0.1766344\ttotal: 12.7s\tremaining: 10.1s\n",
      "557:\tlearn: 0.1765391\ttotal: 12.7s\tremaining: 10.1s\n",
      "558:\tlearn: 0.1764454\ttotal: 12.8s\tremaining: 10.1s\n",
      "559:\tlearn: 0.1763712\ttotal: 12.8s\tremaining: 10s\n",
      "560:\tlearn: 0.1762814\ttotal: 12.8s\tremaining: 10s\n",
      "561:\tlearn: 0.1761976\ttotal: 12.8s\tremaining: 10s\n",
      "562:\tlearn: 0.1761142\ttotal: 12.9s\tremaining: 9.98s\n",
      "563:\tlearn: 0.1760316\ttotal: 12.9s\tremaining: 9.96s\n",
      "564:\tlearn: 0.1759528\ttotal: 12.9s\tremaining: 9.94s\n",
      "565:\tlearn: 0.1758628\ttotal: 13s\tremaining: 9.93s\n",
      "566:\tlearn: 0.1757848\ttotal: 13s\tremaining: 9.91s\n",
      "567:\tlearn: 0.1757060\ttotal: 13s\tremaining: 9.88s\n",
      "568:\tlearn: 0.1756277\ttotal: 13s\tremaining: 9.86s\n",
      "569:\tlearn: 0.1755335\ttotal: 13s\tremaining: 9.83s\n",
      "570:\tlearn: 0.1754547\ttotal: 13.1s\tremaining: 9.81s\n",
      "571:\tlearn: 0.1753670\ttotal: 13.1s\tremaining: 9.79s\n",
      "572:\tlearn: 0.1752783\ttotal: 13.1s\tremaining: 9.77s\n",
      "573:\tlearn: 0.1751833\ttotal: 13.1s\tremaining: 9.75s\n",
      "574:\tlearn: 0.1750957\ttotal: 13.2s\tremaining: 9.72s\n",
      "575:\tlearn: 0.1750118\ttotal: 13.2s\tremaining: 9.7s\n",
      "576:\tlearn: 0.1749367\ttotal: 13.2s\tremaining: 9.68s\n",
      "577:\tlearn: 0.1748437\ttotal: 13.2s\tremaining: 9.66s\n",
      "578:\tlearn: 0.1747594\ttotal: 13.3s\tremaining: 9.64s\n",
      "579:\tlearn: 0.1746697\ttotal: 13.3s\tremaining: 9.61s\n",
      "580:\tlearn: 0.1745837\ttotal: 13.3s\tremaining: 9.59s\n",
      "581:\tlearn: 0.1745077\ttotal: 13.3s\tremaining: 9.57s\n",
      "582:\tlearn: 0.1744320\ttotal: 13.4s\tremaining: 9.55s\n",
      "583:\tlearn: 0.1743480\ttotal: 13.4s\tremaining: 9.53s\n",
      "584:\tlearn: 0.1742645\ttotal: 13.4s\tremaining: 9.5s\n",
      "585:\tlearn: 0.1741862\ttotal: 13.4s\tremaining: 9.48s\n",
      "586:\tlearn: 0.1741089\ttotal: 13.4s\tremaining: 9.46s\n",
      "587:\tlearn: 0.1740276\ttotal: 13.5s\tremaining: 9.43s\n",
      "588:\tlearn: 0.1739646\ttotal: 13.5s\tremaining: 9.41s\n",
      "589:\tlearn: 0.1738785\ttotal: 13.5s\tremaining: 9.39s\n",
      "590:\tlearn: 0.1738007\ttotal: 13.5s\tremaining: 9.36s\n",
      "591:\tlearn: 0.1737232\ttotal: 13.6s\tremaining: 9.34s\n",
      "592:\tlearn: 0.1736346\ttotal: 13.6s\tremaining: 9.32s\n",
      "593:\tlearn: 0.1735549\ttotal: 13.6s\tremaining: 9.29s\n",
      "594:\tlearn: 0.1734699\ttotal: 13.6s\tremaining: 9.27s\n",
      "595:\tlearn: 0.1733869\ttotal: 13.6s\tremaining: 9.24s\n",
      "596:\tlearn: 0.1733058\ttotal: 13.7s\tremaining: 9.22s\n",
      "597:\tlearn: 0.1732268\ttotal: 13.7s\tremaining: 9.19s\n",
      "598:\tlearn: 0.1731503\ttotal: 13.7s\tremaining: 9.17s\n",
      "599:\tlearn: 0.1730690\ttotal: 13.7s\tremaining: 9.15s\n",
      "600:\tlearn: 0.1729895\ttotal: 13.7s\tremaining: 9.13s\n",
      "601:\tlearn: 0.1729065\ttotal: 13.8s\tremaining: 9.11s\n",
      "602:\tlearn: 0.1728319\ttotal: 13.8s\tremaining: 9.08s\n",
      "603:\tlearn: 0.1727470\ttotal: 13.8s\tremaining: 9.06s\n",
      "604:\tlearn: 0.1726805\ttotal: 13.8s\tremaining: 9.03s\n",
      "605:\tlearn: 0.1726032\ttotal: 13.9s\tremaining: 9.01s\n",
      "606:\tlearn: 0.1725301\ttotal: 13.9s\tremaining: 8.98s\n",
      "607:\tlearn: 0.1724441\ttotal: 13.9s\tremaining: 8.96s\n",
      "608:\tlearn: 0.1723619\ttotal: 13.9s\tremaining: 8.94s\n",
      "609:\tlearn: 0.1722826\ttotal: 13.9s\tremaining: 8.91s\n",
      "610:\tlearn: 0.1721996\ttotal: 14s\tremaining: 8.89s\n",
      "611:\tlearn: 0.1721249\ttotal: 14s\tremaining: 8.86s\n",
      "612:\tlearn: 0.1720559\ttotal: 14s\tremaining: 8.84s\n",
      "613:\tlearn: 0.1719689\ttotal: 14s\tremaining: 8.82s\n",
      "614:\tlearn: 0.1718966\ttotal: 14s\tremaining: 8.79s\n",
      "615:\tlearn: 0.1718034\ttotal: 14.1s\tremaining: 8.77s\n",
      "616:\tlearn: 0.1717237\ttotal: 14.1s\tremaining: 8.74s\n",
      "617:\tlearn: 0.1716526\ttotal: 14.1s\tremaining: 8.72s\n",
      "618:\tlearn: 0.1715631\ttotal: 14.1s\tremaining: 8.7s\n",
      "619:\tlearn: 0.1714901\ttotal: 14.1s\tremaining: 8.67s\n",
      "620:\tlearn: 0.1714094\ttotal: 14.2s\tremaining: 8.64s\n",
      "621:\tlearn: 0.1713213\ttotal: 14.2s\tremaining: 8.62s\n",
      "622:\tlearn: 0.1712394\ttotal: 14.2s\tremaining: 8.6s\n",
      "623:\tlearn: 0.1711610\ttotal: 14.2s\tremaining: 8.57s\n",
      "624:\tlearn: 0.1710956\ttotal: 14.2s\tremaining: 8.55s\n",
      "625:\tlearn: 0.1710032\ttotal: 14.3s\tremaining: 8.52s\n",
      "626:\tlearn: 0.1709399\ttotal: 14.3s\tremaining: 8.5s\n",
      "627:\tlearn: 0.1708721\ttotal: 14.3s\tremaining: 8.48s\n",
      "628:\tlearn: 0.1707919\ttotal: 14.3s\tremaining: 8.45s\n",
      "629:\tlearn: 0.1707113\ttotal: 14.4s\tremaining: 8.43s\n",
      "630:\tlearn: 0.1706236\ttotal: 14.4s\tremaining: 8.4s\n",
      "631:\tlearn: 0.1705472\ttotal: 14.4s\tremaining: 8.38s\n",
      "632:\tlearn: 0.1704833\ttotal: 14.4s\tremaining: 8.36s\n",
      "633:\tlearn: 0.1704057\ttotal: 14.4s\tremaining: 8.33s\n",
      "634:\tlearn: 0.1703350\ttotal: 14.4s\tremaining: 8.31s\n",
      "635:\tlearn: 0.1702465\ttotal: 14.5s\tremaining: 8.28s\n",
      "636:\tlearn: 0.1701634\ttotal: 14.5s\tremaining: 8.26s\n",
      "637:\tlearn: 0.1700794\ttotal: 14.5s\tremaining: 8.23s\n",
      "638:\tlearn: 0.1700035\ttotal: 14.5s\tremaining: 8.21s\n",
      "639:\tlearn: 0.1699265\ttotal: 14.5s\tremaining: 8.18s\n",
      "640:\tlearn: 0.1698505\ttotal: 14.6s\tremaining: 8.16s\n",
      "641:\tlearn: 0.1697796\ttotal: 14.6s\tremaining: 8.13s\n",
      "642:\tlearn: 0.1697190\ttotal: 14.6s\tremaining: 8.11s\n",
      "643:\tlearn: 0.1696431\ttotal: 14.6s\tremaining: 8.09s\n",
      "644:\tlearn: 0.1695824\ttotal: 14.6s\tremaining: 8.06s\n",
      "645:\tlearn: 0.1694987\ttotal: 14.7s\tremaining: 8.04s\n",
      "646:\tlearn: 0.1694313\ttotal: 14.7s\tremaining: 8.01s\n",
      "647:\tlearn: 0.1693527\ttotal: 14.7s\tremaining: 7.99s\n",
      "648:\tlearn: 0.1692866\ttotal: 14.7s\tremaining: 7.96s\n",
      "649:\tlearn: 0.1692154\ttotal: 14.7s\tremaining: 7.94s\n",
      "650:\tlearn: 0.1691407\ttotal: 14.8s\tremaining: 7.92s\n",
      "651:\tlearn: 0.1690560\ttotal: 14.8s\tremaining: 7.89s\n",
      "652:\tlearn: 0.1689860\ttotal: 14.8s\tremaining: 7.87s\n",
      "653:\tlearn: 0.1689216\ttotal: 14.8s\tremaining: 7.84s\n",
      "654:\tlearn: 0.1688516\ttotal: 14.8s\tremaining: 7.82s\n",
      "655:\tlearn: 0.1687678\ttotal: 14.9s\tremaining: 7.79s\n",
      "656:\tlearn: 0.1686989\ttotal: 14.9s\tremaining: 7.77s\n",
      "657:\tlearn: 0.1686151\ttotal: 14.9s\tremaining: 7.75s\n",
      "658:\tlearn: 0.1685310\ttotal: 14.9s\tremaining: 7.72s\n",
      "659:\tlearn: 0.1684591\ttotal: 14.9s\tremaining: 7.7s\n",
      "660:\tlearn: 0.1683806\ttotal: 15s\tremaining: 7.67s\n",
      "661:\tlearn: 0.1683181\ttotal: 15s\tremaining: 7.65s\n",
      "662:\tlearn: 0.1682571\ttotal: 15s\tremaining: 7.62s\n",
      "663:\tlearn: 0.1681768\ttotal: 15s\tremaining: 7.6s\n",
      "664:\tlearn: 0.1681111\ttotal: 15s\tremaining: 7.58s\n",
      "665:\tlearn: 0.1680314\ttotal: 15.1s\tremaining: 7.56s\n",
      "666:\tlearn: 0.1679586\ttotal: 15.1s\tremaining: 7.53s\n",
      "667:\tlearn: 0.1678715\ttotal: 15.1s\tremaining: 7.51s\n",
      "668:\tlearn: 0.1678010\ttotal: 15.1s\tremaining: 7.49s\n",
      "669:\tlearn: 0.1677354\ttotal: 15.2s\tremaining: 7.46s\n",
      "670:\tlearn: 0.1676543\ttotal: 15.2s\tremaining: 7.44s\n",
      "671:\tlearn: 0.1675789\ttotal: 15.2s\tremaining: 7.41s\n",
      "672:\tlearn: 0.1675015\ttotal: 15.2s\tremaining: 7.39s\n",
      "673:\tlearn: 0.1674320\ttotal: 15.2s\tremaining: 7.37s\n",
      "674:\tlearn: 0.1673598\ttotal: 15.3s\tremaining: 7.34s\n",
      "675:\tlearn: 0.1672965\ttotal: 15.3s\tremaining: 7.32s\n",
      "676:\tlearn: 0.1672193\ttotal: 15.3s\tremaining: 7.3s\n",
      "677:\tlearn: 0.1671675\ttotal: 15.3s\tremaining: 7.27s\n",
      "678:\tlearn: 0.1671017\ttotal: 15.3s\tremaining: 7.25s\n",
      "679:\tlearn: 0.1670325\ttotal: 15.4s\tremaining: 7.23s\n",
      "680:\tlearn: 0.1669622\ttotal: 15.4s\tremaining: 7.2s\n",
      "681:\tlearn: 0.1668821\ttotal: 15.4s\tremaining: 7.18s\n",
      "682:\tlearn: 0.1668016\ttotal: 15.4s\tremaining: 7.16s\n",
      "683:\tlearn: 0.1667452\ttotal: 15.4s\tremaining: 7.13s\n",
      "684:\tlearn: 0.1666617\ttotal: 15.5s\tremaining: 7.11s\n",
      "685:\tlearn: 0.1665956\ttotal: 15.5s\tremaining: 7.09s\n",
      "686:\tlearn: 0.1665161\ttotal: 15.5s\tremaining: 7.06s\n",
      "687:\tlearn: 0.1664629\ttotal: 15.5s\tremaining: 7.04s\n",
      "688:\tlearn: 0.1663752\ttotal: 15.5s\tremaining: 7.02s\n",
      "689:\tlearn: 0.1663085\ttotal: 15.6s\tremaining: 6.99s\n",
      "690:\tlearn: 0.1662283\ttotal: 15.6s\tremaining: 6.97s\n",
      "691:\tlearn: 0.1661477\ttotal: 15.6s\tremaining: 6.95s\n",
      "692:\tlearn: 0.1660805\ttotal: 15.6s\tremaining: 6.92s\n",
      "693:\tlearn: 0.1660167\ttotal: 15.6s\tremaining: 6.9s\n",
      "694:\tlearn: 0.1659557\ttotal: 15.7s\tremaining: 6.87s\n",
      "695:\tlearn: 0.1658845\ttotal: 15.7s\tremaining: 6.85s\n",
      "696:\tlearn: 0.1658280\ttotal: 15.7s\tremaining: 6.83s\n",
      "697:\tlearn: 0.1657503\ttotal: 15.7s\tremaining: 6.8s\n",
      "698:\tlearn: 0.1656991\ttotal: 15.7s\tremaining: 6.78s\n",
      "699:\tlearn: 0.1656338\ttotal: 15.8s\tremaining: 6.75s\n",
      "700:\tlearn: 0.1655710\ttotal: 15.8s\tremaining: 6.73s\n",
      "701:\tlearn: 0.1655134\ttotal: 15.8s\tremaining: 6.71s\n",
      "702:\tlearn: 0.1654459\ttotal: 15.8s\tremaining: 6.68s\n",
      "703:\tlearn: 0.1653708\ttotal: 15.8s\tremaining: 6.66s\n",
      "704:\tlearn: 0.1653072\ttotal: 15.9s\tremaining: 6.64s\n",
      "705:\tlearn: 0.1652372\ttotal: 15.9s\tremaining: 6.61s\n",
      "706:\tlearn: 0.1651503\ttotal: 15.9s\tremaining: 6.59s\n",
      "707:\tlearn: 0.1650783\ttotal: 15.9s\tremaining: 6.57s\n",
      "708:\tlearn: 0.1650069\ttotal: 16s\tremaining: 6.55s\n",
      "709:\tlearn: 0.1649432\ttotal: 16s\tremaining: 6.53s\n",
      "710:\tlearn: 0.1648703\ttotal: 16s\tremaining: 6.5s\n",
      "711:\tlearn: 0.1648061\ttotal: 16s\tremaining: 6.48s\n",
      "712:\tlearn: 0.1647371\ttotal: 16s\tremaining: 6.46s\n",
      "713:\tlearn: 0.1646618\ttotal: 16.1s\tremaining: 6.44s\n",
      "714:\tlearn: 0.1645925\ttotal: 16.1s\tremaining: 6.42s\n",
      "715:\tlearn: 0.1645195\ttotal: 16.1s\tremaining: 6.39s\n",
      "716:\tlearn: 0.1644533\ttotal: 16.1s\tremaining: 6.37s\n",
      "717:\tlearn: 0.1643567\ttotal: 16.2s\tremaining: 6.35s\n",
      "718:\tlearn: 0.1642814\ttotal: 16.2s\tremaining: 6.33s\n",
      "719:\tlearn: 0.1642126\ttotal: 16.2s\tremaining: 6.3s\n",
      "720:\tlearn: 0.1641454\ttotal: 16.2s\tremaining: 6.28s\n",
      "721:\tlearn: 0.1640674\ttotal: 16.2s\tremaining: 6.25s\n",
      "722:\tlearn: 0.1639986\ttotal: 16.3s\tremaining: 6.23s\n",
      "723:\tlearn: 0.1639326\ttotal: 16.3s\tremaining: 6.21s\n",
      "724:\tlearn: 0.1638634\ttotal: 16.3s\tremaining: 6.18s\n",
      "725:\tlearn: 0.1637881\ttotal: 16.3s\tremaining: 6.16s\n",
      "726:\tlearn: 0.1637368\ttotal: 16.3s\tremaining: 6.14s\n",
      "727:\tlearn: 0.1636706\ttotal: 16.4s\tremaining: 6.11s\n",
      "728:\tlearn: 0.1635938\ttotal: 16.4s\tremaining: 6.09s\n",
      "729:\tlearn: 0.1635283\ttotal: 16.4s\tremaining: 6.07s\n",
      "730:\tlearn: 0.1634538\ttotal: 16.4s\tremaining: 6.04s\n",
      "731:\tlearn: 0.1633903\ttotal: 16.4s\tremaining: 6.02s\n",
      "732:\tlearn: 0.1633197\ttotal: 16.5s\tremaining: 6s\n",
      "733:\tlearn: 0.1632511\ttotal: 16.5s\tremaining: 5.98s\n",
      "734:\tlearn: 0.1631871\ttotal: 16.5s\tremaining: 5.95s\n",
      "735:\tlearn: 0.1631063\ttotal: 16.5s\tremaining: 5.93s\n",
      "736:\tlearn: 0.1630513\ttotal: 16.6s\tremaining: 5.91s\n",
      "737:\tlearn: 0.1629643\ttotal: 16.6s\tremaining: 5.88s\n",
      "738:\tlearn: 0.1628954\ttotal: 16.6s\tremaining: 5.86s\n",
      "739:\tlearn: 0.1628369\ttotal: 16.6s\tremaining: 5.84s\n",
      "740:\tlearn: 0.1627627\ttotal: 16.6s\tremaining: 5.82s\n",
      "741:\tlearn: 0.1627024\ttotal: 16.7s\tremaining: 5.79s\n",
      "742:\tlearn: 0.1626280\ttotal: 16.7s\tremaining: 5.77s\n",
      "743:\tlearn: 0.1625537\ttotal: 16.7s\tremaining: 5.75s\n",
      "744:\tlearn: 0.1624936\ttotal: 16.7s\tremaining: 5.73s\n",
      "745:\tlearn: 0.1624172\ttotal: 16.8s\tremaining: 5.7s\n",
      "746:\tlearn: 0.1623598\ttotal: 16.8s\tremaining: 5.68s\n",
      "747:\tlearn: 0.1622853\ttotal: 16.8s\tremaining: 5.66s\n",
      "748:\tlearn: 0.1622259\ttotal: 16.8s\tremaining: 5.63s\n",
      "749:\tlearn: 0.1621459\ttotal: 16.8s\tremaining: 5.61s\n",
      "750:\tlearn: 0.1620873\ttotal: 16.9s\tremaining: 5.59s\n",
      "751:\tlearn: 0.1620343\ttotal: 16.9s\tremaining: 5.56s\n",
      "752:\tlearn: 0.1619574\ttotal: 16.9s\tremaining: 5.54s\n",
      "753:\tlearn: 0.1618817\ttotal: 16.9s\tremaining: 5.52s\n",
      "754:\tlearn: 0.1618079\ttotal: 16.9s\tremaining: 5.49s\n",
      "755:\tlearn: 0.1617439\ttotal: 17s\tremaining: 5.47s\n",
      "756:\tlearn: 0.1616692\ttotal: 17s\tremaining: 5.45s\n",
      "757:\tlearn: 0.1616039\ttotal: 17s\tremaining: 5.43s\n",
      "758:\tlearn: 0.1615316\ttotal: 17s\tremaining: 5.41s\n",
      "759:\tlearn: 0.1614599\ttotal: 17.1s\tremaining: 5.39s\n",
      "760:\tlearn: 0.1614080\ttotal: 17.1s\tremaining: 5.37s\n",
      "761:\tlearn: 0.1613468\ttotal: 17.1s\tremaining: 5.35s\n",
      "762:\tlearn: 0.1612797\ttotal: 17.2s\tremaining: 5.33s\n",
      "763:\tlearn: 0.1612167\ttotal: 17.2s\tremaining: 5.31s\n",
      "764:\tlearn: 0.1611617\ttotal: 17.2s\tremaining: 5.29s\n",
      "765:\tlearn: 0.1611073\ttotal: 17.2s\tremaining: 5.26s\n",
      "766:\tlearn: 0.1610465\ttotal: 17.2s\tremaining: 5.24s\n",
      "767:\tlearn: 0.1609921\ttotal: 17.3s\tremaining: 5.22s\n",
      "768:\tlearn: 0.1609314\ttotal: 17.3s\tremaining: 5.19s\n",
      "769:\tlearn: 0.1608762\ttotal: 17.3s\tremaining: 5.17s\n",
      "770:\tlearn: 0.1608250\ttotal: 17.3s\tremaining: 5.14s\n",
      "771:\tlearn: 0.1607666\ttotal: 17.3s\tremaining: 5.12s\n",
      "772:\tlearn: 0.1607071\ttotal: 17.4s\tremaining: 5.1s\n",
      "773:\tlearn: 0.1606328\ttotal: 17.4s\tremaining: 5.07s\n",
      "774:\tlearn: 0.1605426\ttotal: 17.4s\tremaining: 5.05s\n",
      "775:\tlearn: 0.1604723\ttotal: 17.4s\tremaining: 5.03s\n",
      "776:\tlearn: 0.1604023\ttotal: 17.4s\tremaining: 5s\n",
      "777:\tlearn: 0.1603419\ttotal: 17.5s\tremaining: 4.98s\n",
      "778:\tlearn: 0.1602879\ttotal: 17.5s\tremaining: 4.96s\n",
      "779:\tlearn: 0.1602223\ttotal: 17.5s\tremaining: 4.94s\n",
      "780:\tlearn: 0.1601568\ttotal: 17.5s\tremaining: 4.91s\n",
      "781:\tlearn: 0.1600863\ttotal: 17.5s\tremaining: 4.89s\n",
      "782:\tlearn: 0.1600174\ttotal: 17.6s\tremaining: 4.87s\n",
      "783:\tlearn: 0.1599437\ttotal: 17.6s\tremaining: 4.84s\n",
      "784:\tlearn: 0.1598795\ttotal: 17.6s\tremaining: 4.82s\n",
      "785:\tlearn: 0.1598019\ttotal: 17.6s\tremaining: 4.8s\n",
      "786:\tlearn: 0.1597360\ttotal: 17.6s\tremaining: 4.78s\n",
      "787:\tlearn: 0.1596640\ttotal: 17.7s\tremaining: 4.75s\n",
      "788:\tlearn: 0.1595987\ttotal: 17.7s\tremaining: 4.73s\n",
      "789:\tlearn: 0.1595286\ttotal: 17.7s\tremaining: 4.71s\n",
      "790:\tlearn: 0.1594570\ttotal: 17.7s\tremaining: 4.68s\n",
      "791:\tlearn: 0.1593947\ttotal: 17.7s\tremaining: 4.66s\n",
      "792:\tlearn: 0.1593323\ttotal: 17.8s\tremaining: 4.63s\n",
      "793:\tlearn: 0.1592670\ttotal: 17.8s\tremaining: 4.61s\n",
      "794:\tlearn: 0.1591968\ttotal: 17.8s\tremaining: 4.59s\n",
      "795:\tlearn: 0.1591374\ttotal: 17.8s\tremaining: 4.57s\n",
      "796:\tlearn: 0.1590818\ttotal: 17.8s\tremaining: 4.54s\n",
      "797:\tlearn: 0.1590162\ttotal: 17.9s\tremaining: 4.52s\n",
      "798:\tlearn: 0.1589563\ttotal: 17.9s\tremaining: 4.5s\n",
      "799:\tlearn: 0.1588776\ttotal: 17.9s\tremaining: 4.47s\n",
      "800:\tlearn: 0.1588167\ttotal: 17.9s\tremaining: 4.45s\n",
      "801:\tlearn: 0.1587637\ttotal: 17.9s\tremaining: 4.43s\n",
      "802:\tlearn: 0.1586954\ttotal: 18s\tremaining: 4.41s\n",
      "803:\tlearn: 0.1586312\ttotal: 18s\tremaining: 4.38s\n",
      "804:\tlearn: 0.1585580\ttotal: 18s\tremaining: 4.36s\n",
      "805:\tlearn: 0.1584824\ttotal: 18s\tremaining: 4.34s\n",
      "806:\tlearn: 0.1584191\ttotal: 18s\tremaining: 4.32s\n",
      "807:\tlearn: 0.1583645\ttotal: 18.1s\tremaining: 4.29s\n",
      "808:\tlearn: 0.1583116\ttotal: 18.1s\tremaining: 4.27s\n",
      "809:\tlearn: 0.1582446\ttotal: 18.1s\tremaining: 4.25s\n",
      "810:\tlearn: 0.1581777\ttotal: 18.1s\tremaining: 4.22s\n",
      "811:\tlearn: 0.1581063\ttotal: 18.1s\tremaining: 4.2s\n",
      "812:\tlearn: 0.1580390\ttotal: 18.2s\tremaining: 4.18s\n",
      "813:\tlearn: 0.1579869\ttotal: 18.2s\tremaining: 4.16s\n",
      "814:\tlearn: 0.1579278\ttotal: 18.2s\tremaining: 4.13s\n",
      "815:\tlearn: 0.1578696\ttotal: 18.2s\tremaining: 4.11s\n",
      "816:\tlearn: 0.1578080\ttotal: 18.2s\tremaining: 4.09s\n",
      "817:\tlearn: 0.1577470\ttotal: 18.3s\tremaining: 4.07s\n",
      "818:\tlearn: 0.1576992\ttotal: 18.3s\tremaining: 4.04s\n",
      "819:\tlearn: 0.1576372\ttotal: 18.3s\tremaining: 4.02s\n",
      "820:\tlearn: 0.1575724\ttotal: 18.3s\tremaining: 4s\n",
      "821:\tlearn: 0.1575188\ttotal: 18.3s\tremaining: 3.97s\n",
      "822:\tlearn: 0.1574725\ttotal: 18.4s\tremaining: 3.95s\n",
      "823:\tlearn: 0.1574019\ttotal: 18.4s\tremaining: 3.93s\n",
      "824:\tlearn: 0.1573567\ttotal: 18.4s\tremaining: 3.9s\n",
      "825:\tlearn: 0.1572846\ttotal: 18.4s\tremaining: 3.88s\n",
      "826:\tlearn: 0.1572242\ttotal: 18.4s\tremaining: 3.86s\n",
      "827:\tlearn: 0.1571619\ttotal: 18.5s\tremaining: 3.84s\n",
      "828:\tlearn: 0.1570913\ttotal: 18.5s\tremaining: 3.81s\n",
      "829:\tlearn: 0.1570227\ttotal: 18.5s\tremaining: 3.79s\n",
      "830:\tlearn: 0.1569519\ttotal: 18.5s\tremaining: 3.77s\n",
      "831:\tlearn: 0.1568974\ttotal: 18.6s\tremaining: 3.75s\n",
      "832:\tlearn: 0.1568350\ttotal: 18.6s\tremaining: 3.73s\n",
      "833:\tlearn: 0.1567702\ttotal: 18.6s\tremaining: 3.7s\n",
      "834:\tlearn: 0.1567005\ttotal: 18.6s\tremaining: 3.68s\n",
      "835:\tlearn: 0.1566320\ttotal: 18.6s\tremaining: 3.66s\n",
      "836:\tlearn: 0.1565724\ttotal: 18.7s\tremaining: 3.63s\n",
      "837:\tlearn: 0.1565058\ttotal: 18.7s\tremaining: 3.61s\n",
      "838:\tlearn: 0.1564510\ttotal: 18.7s\tremaining: 3.59s\n",
      "839:\tlearn: 0.1563971\ttotal: 18.7s\tremaining: 3.57s\n",
      "840:\tlearn: 0.1563585\ttotal: 18.8s\tremaining: 3.54s\n",
      "841:\tlearn: 0.1562900\ttotal: 18.8s\tremaining: 3.52s\n",
      "842:\tlearn: 0.1562320\ttotal: 18.8s\tremaining: 3.5s\n",
      "843:\tlearn: 0.1561848\ttotal: 18.8s\tremaining: 3.48s\n",
      "844:\tlearn: 0.1561261\ttotal: 18.8s\tremaining: 3.45s\n",
      "845:\tlearn: 0.1560649\ttotal: 18.9s\tremaining: 3.43s\n",
      "846:\tlearn: 0.1560002\ttotal: 18.9s\tremaining: 3.41s\n",
      "847:\tlearn: 0.1559325\ttotal: 18.9s\tremaining: 3.39s\n",
      "848:\tlearn: 0.1558606\ttotal: 18.9s\tremaining: 3.36s\n",
      "849:\tlearn: 0.1558117\ttotal: 18.9s\tremaining: 3.34s\n",
      "850:\tlearn: 0.1557336\ttotal: 19s\tremaining: 3.32s\n",
      "851:\tlearn: 0.1556760\ttotal: 19s\tremaining: 3.3s\n",
      "852:\tlearn: 0.1556170\ttotal: 19s\tremaining: 3.27s\n",
      "853:\tlearn: 0.1555504\ttotal: 19s\tremaining: 3.25s\n",
      "854:\tlearn: 0.1554931\ttotal: 19s\tremaining: 3.23s\n",
      "855:\tlearn: 0.1554234\ttotal: 19.1s\tremaining: 3.21s\n",
      "856:\tlearn: 0.1553634\ttotal: 19.1s\tremaining: 3.18s\n",
      "857:\tlearn: 0.1553123\ttotal: 19.1s\tremaining: 3.16s\n",
      "858:\tlearn: 0.1552584\ttotal: 19.1s\tremaining: 3.14s\n",
      "859:\tlearn: 0.1551820\ttotal: 19.1s\tremaining: 3.11s\n",
      "860:\tlearn: 0.1551481\ttotal: 19.2s\tremaining: 3.09s\n",
      "861:\tlearn: 0.1550783\ttotal: 19.2s\tremaining: 3.07s\n",
      "862:\tlearn: 0.1550255\ttotal: 19.2s\tremaining: 3.05s\n",
      "863:\tlearn: 0.1549772\ttotal: 19.2s\tremaining: 3.02s\n",
      "864:\tlearn: 0.1549122\ttotal: 19.2s\tremaining: 3s\n",
      "865:\tlearn: 0.1548491\ttotal: 19.3s\tremaining: 2.98s\n",
      "866:\tlearn: 0.1547878\ttotal: 19.3s\tremaining: 2.96s\n",
      "867:\tlearn: 0.1547312\ttotal: 19.3s\tremaining: 2.94s\n",
      "868:\tlearn: 0.1546625\ttotal: 19.3s\tremaining: 2.91s\n",
      "869:\tlearn: 0.1545999\ttotal: 19.3s\tremaining: 2.89s\n",
      "870:\tlearn: 0.1545493\ttotal: 19.4s\tremaining: 2.87s\n",
      "871:\tlearn: 0.1544921\ttotal: 19.4s\tremaining: 2.85s\n",
      "872:\tlearn: 0.1544321\ttotal: 19.4s\tremaining: 2.82s\n",
      "873:\tlearn: 0.1543671\ttotal: 19.4s\tremaining: 2.8s\n",
      "874:\tlearn: 0.1543166\ttotal: 19.4s\tremaining: 2.78s\n",
      "875:\tlearn: 0.1542505\ttotal: 19.5s\tremaining: 2.75s\n",
      "876:\tlearn: 0.1541941\ttotal: 19.5s\tremaining: 2.73s\n",
      "877:\tlearn: 0.1541328\ttotal: 19.5s\tremaining: 2.71s\n",
      "878:\tlearn: 0.1540689\ttotal: 19.5s\tremaining: 2.69s\n",
      "879:\tlearn: 0.1539999\ttotal: 19.5s\tremaining: 2.66s\n",
      "880:\tlearn: 0.1539453\ttotal: 19.6s\tremaining: 2.64s\n",
      "881:\tlearn: 0.1538930\ttotal: 19.6s\tremaining: 2.62s\n",
      "882:\tlearn: 0.1538472\ttotal: 19.6s\tremaining: 2.6s\n",
      "883:\tlearn: 0.1537830\ttotal: 19.6s\tremaining: 2.57s\n",
      "884:\tlearn: 0.1537120\ttotal: 19.6s\tremaining: 2.55s\n",
      "885:\tlearn: 0.1536442\ttotal: 19.7s\tremaining: 2.53s\n",
      "886:\tlearn: 0.1536024\ttotal: 19.7s\tremaining: 2.51s\n",
      "887:\tlearn: 0.1535342\ttotal: 19.7s\tremaining: 2.48s\n",
      "888:\tlearn: 0.1534778\ttotal: 19.7s\tremaining: 2.46s\n",
      "889:\tlearn: 0.1534149\ttotal: 19.7s\tremaining: 2.44s\n",
      "890:\tlearn: 0.1533423\ttotal: 19.7s\tremaining: 2.42s\n",
      "891:\tlearn: 0.1532772\ttotal: 19.8s\tremaining: 2.39s\n",
      "892:\tlearn: 0.1532170\ttotal: 19.8s\tremaining: 2.37s\n",
      "893:\tlearn: 0.1531564\ttotal: 19.8s\tremaining: 2.35s\n",
      "894:\tlearn: 0.1530998\ttotal: 19.8s\tremaining: 2.33s\n",
      "895:\tlearn: 0.1530473\ttotal: 19.8s\tremaining: 2.3s\n",
      "896:\tlearn: 0.1529966\ttotal: 19.9s\tremaining: 2.28s\n",
      "897:\tlearn: 0.1529388\ttotal: 19.9s\tremaining: 2.26s\n",
      "898:\tlearn: 0.1528783\ttotal: 19.9s\tremaining: 2.23s\n",
      "899:\tlearn: 0.1528172\ttotal: 19.9s\tremaining: 2.21s\n",
      "900:\tlearn: 0.1527535\ttotal: 19.9s\tremaining: 2.19s\n",
      "901:\tlearn: 0.1527028\ttotal: 20s\tremaining: 2.17s\n",
      "902:\tlearn: 0.1526529\ttotal: 20s\tremaining: 2.15s\n",
      "903:\tlearn: 0.1525891\ttotal: 20s\tremaining: 2.12s\n",
      "904:\tlearn: 0.1525370\ttotal: 20s\tremaining: 2.1s\n",
      "905:\tlearn: 0.1524827\ttotal: 20s\tremaining: 2.08s\n",
      "906:\tlearn: 0.1524133\ttotal: 20.1s\tremaining: 2.06s\n",
      "907:\tlearn: 0.1523435\ttotal: 20.1s\tremaining: 2.03s\n",
      "908:\tlearn: 0.1522830\ttotal: 20.1s\tremaining: 2.01s\n",
      "909:\tlearn: 0.1522316\ttotal: 20.1s\tremaining: 1.99s\n",
      "910:\tlearn: 0.1521644\ttotal: 20.1s\tremaining: 1.97s\n",
      "911:\tlearn: 0.1521034\ttotal: 20.1s\tremaining: 1.94s\n",
      "912:\tlearn: 0.1520412\ttotal: 20.2s\tremaining: 1.92s\n",
      "913:\tlearn: 0.1519772\ttotal: 20.2s\tremaining: 1.9s\n",
      "914:\tlearn: 0.1519274\ttotal: 20.2s\tremaining: 1.88s\n",
      "915:\tlearn: 0.1518584\ttotal: 20.2s\tremaining: 1.85s\n",
      "916:\tlearn: 0.1518172\ttotal: 20.2s\tremaining: 1.83s\n",
      "917:\tlearn: 0.1517460\ttotal: 20.3s\tremaining: 1.81s\n",
      "918:\tlearn: 0.1517022\ttotal: 20.3s\tremaining: 1.79s\n",
      "919:\tlearn: 0.1516471\ttotal: 20.3s\tremaining: 1.76s\n",
      "920:\tlearn: 0.1515928\ttotal: 20.3s\tremaining: 1.74s\n",
      "921:\tlearn: 0.1515421\ttotal: 20.3s\tremaining: 1.72s\n",
      "922:\tlearn: 0.1514895\ttotal: 20.4s\tremaining: 1.7s\n",
      "923:\tlearn: 0.1514336\ttotal: 20.4s\tremaining: 1.68s\n",
      "924:\tlearn: 0.1513750\ttotal: 20.4s\tremaining: 1.65s\n",
      "925:\tlearn: 0.1513130\ttotal: 20.4s\tremaining: 1.63s\n",
      "926:\tlearn: 0.1512670\ttotal: 20.4s\tremaining: 1.61s\n",
      "927:\tlearn: 0.1512088\ttotal: 20.5s\tremaining: 1.59s\n",
      "928:\tlearn: 0.1511631\ttotal: 20.5s\tremaining: 1.56s\n",
      "929:\tlearn: 0.1511032\ttotal: 20.5s\tremaining: 1.54s\n",
      "930:\tlearn: 0.1510442\ttotal: 20.5s\tremaining: 1.52s\n",
      "931:\tlearn: 0.1509809\ttotal: 20.5s\tremaining: 1.5s\n",
      "932:\tlearn: 0.1509120\ttotal: 20.6s\tremaining: 1.48s\n",
      "933:\tlearn: 0.1508593\ttotal: 20.6s\tremaining: 1.45s\n",
      "934:\tlearn: 0.1507992\ttotal: 20.6s\tremaining: 1.43s\n",
      "935:\tlearn: 0.1507401\ttotal: 20.6s\tremaining: 1.41s\n",
      "936:\tlearn: 0.1506756\ttotal: 20.6s\tremaining: 1.39s\n",
      "937:\tlearn: 0.1506059\ttotal: 20.6s\tremaining: 1.36s\n",
      "938:\tlearn: 0.1505678\ttotal: 20.7s\tremaining: 1.34s\n",
      "939:\tlearn: 0.1505079\ttotal: 20.7s\tremaining: 1.32s\n",
      "940:\tlearn: 0.1504548\ttotal: 20.7s\tremaining: 1.3s\n",
      "941:\tlearn: 0.1504012\ttotal: 20.7s\tremaining: 1.27s\n",
      "942:\tlearn: 0.1503352\ttotal: 20.7s\tremaining: 1.25s\n",
      "943:\tlearn: 0.1502990\ttotal: 20.8s\tremaining: 1.23s\n",
      "944:\tlearn: 0.1502450\ttotal: 20.8s\tremaining: 1.21s\n",
      "945:\tlearn: 0.1501895\ttotal: 20.8s\tremaining: 1.19s\n",
      "946:\tlearn: 0.1501427\ttotal: 20.8s\tremaining: 1.16s\n",
      "947:\tlearn: 0.1500781\ttotal: 20.8s\tremaining: 1.14s\n",
      "948:\tlearn: 0.1500168\ttotal: 20.8s\tremaining: 1.12s\n",
      "949:\tlearn: 0.1499636\ttotal: 20.9s\tremaining: 1.1s\n",
      "950:\tlearn: 0.1499006\ttotal: 20.9s\tremaining: 1.08s\n",
      "951:\tlearn: 0.1498376\ttotal: 20.9s\tremaining: 1.05s\n",
      "952:\tlearn: 0.1497868\ttotal: 20.9s\tremaining: 1.03s\n",
      "953:\tlearn: 0.1497212\ttotal: 20.9s\tremaining: 1.01s\n",
      "954:\tlearn: 0.1496683\ttotal: 21s\tremaining: 988ms\n",
      "955:\tlearn: 0.1495923\ttotal: 21s\tremaining: 966ms\n",
      "956:\tlearn: 0.1495375\ttotal: 21s\tremaining: 944ms\n",
      "957:\tlearn: 0.1494855\ttotal: 21s\tremaining: 922ms\n",
      "958:\tlearn: 0.1494272\ttotal: 21s\tremaining: 900ms\n",
      "959:\tlearn: 0.1493727\ttotal: 21.1s\tremaining: 877ms\n",
      "960:\tlearn: 0.1493381\ttotal: 21.1s\tremaining: 855ms\n",
      "961:\tlearn: 0.1492601\ttotal: 21.1s\tremaining: 833ms\n",
      "962:\tlearn: 0.1491905\ttotal: 21.1s\tremaining: 811ms\n",
      "963:\tlearn: 0.1491428\ttotal: 21.1s\tremaining: 789ms\n",
      "964:\tlearn: 0.1490939\ttotal: 21.2s\tremaining: 767ms\n",
      "965:\tlearn: 0.1490325\ttotal: 21.2s\tremaining: 745ms\n",
      "966:\tlearn: 0.1489755\ttotal: 21.2s\tremaining: 723ms\n",
      "967:\tlearn: 0.1489256\ttotal: 21.2s\tremaining: 701ms\n",
      "968:\tlearn: 0.1488709\ttotal: 21.2s\tremaining: 679ms\n",
      "969:\tlearn: 0.1488169\ttotal: 21.3s\tremaining: 657ms\n",
      "970:\tlearn: 0.1487621\ttotal: 21.3s\tremaining: 635ms\n",
      "971:\tlearn: 0.1487096\ttotal: 21.3s\tremaining: 613ms\n",
      "972:\tlearn: 0.1486516\ttotal: 21.3s\tremaining: 591ms\n",
      "973:\tlearn: 0.1485970\ttotal: 21.3s\tremaining: 569ms\n",
      "974:\tlearn: 0.1485388\ttotal: 21.3s\tremaining: 547ms\n",
      "975:\tlearn: 0.1484836\ttotal: 21.4s\tremaining: 525ms\n",
      "976:\tlearn: 0.1484291\ttotal: 21.4s\tremaining: 504ms\n",
      "977:\tlearn: 0.1483867\ttotal: 21.4s\tremaining: 482ms\n",
      "978:\tlearn: 0.1483397\ttotal: 21.4s\tremaining: 460ms\n",
      "979:\tlearn: 0.1482718\ttotal: 21.4s\tremaining: 438ms\n",
      "980:\tlearn: 0.1482162\ttotal: 21.5s\tremaining: 416ms\n",
      "981:\tlearn: 0.1481613\ttotal: 21.5s\tremaining: 394ms\n",
      "982:\tlearn: 0.1481063\ttotal: 21.5s\tremaining: 372ms\n",
      "983:\tlearn: 0.1480523\ttotal: 21.5s\tremaining: 350ms\n",
      "984:\tlearn: 0.1479847\ttotal: 21.6s\tremaining: 328ms\n",
      "985:\tlearn: 0.1479395\ttotal: 21.6s\tremaining: 306ms\n",
      "986:\tlearn: 0.1478809\ttotal: 21.6s\tremaining: 284ms\n",
      "987:\tlearn: 0.1478351\ttotal: 21.6s\tremaining: 263ms\n",
      "988:\tlearn: 0.1477977\ttotal: 21.6s\tremaining: 241ms\n",
      "989:\tlearn: 0.1477322\ttotal: 21.7s\tremaining: 219ms\n",
      "990:\tlearn: 0.1476914\ttotal: 21.7s\tremaining: 197ms\n",
      "991:\tlearn: 0.1476452\ttotal: 21.7s\tremaining: 175ms\n",
      "992:\tlearn: 0.1476039\ttotal: 21.7s\tremaining: 153ms\n",
      "993:\tlearn: 0.1475541\ttotal: 21.7s\tremaining: 131ms\n",
      "994:\tlearn: 0.1475104\ttotal: 21.8s\tremaining: 109ms\n",
      "995:\tlearn: 0.1474647\ttotal: 21.8s\tremaining: 87.4ms\n",
      "996:\tlearn: 0.1474075\ttotal: 21.8s\tremaining: 65.6ms\n",
      "997:\tlearn: 0.1473553\ttotal: 21.8s\tremaining: 43.7ms\n",
      "998:\tlearn: 0.1473011\ttotal: 21.8s\tremaining: 21.9ms\n",
      "999:\tlearn: 0.1472388\ttotal: 21.9s\tremaining: 0us\n",
      "Model saved to: results/cat_classifier.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5a798_row0_col0, #T_5a798_row0_col1, #T_5a798_row0_col2, #T_5a798_row2_col2, #T_5a798_row3_col0, #T_5a798_row4_col0, #T_5a798_row4_col1, #T_5a798_row4_col2 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_5a798_row1_col0, #T_5a798_row3_col1, #T_5a798_row3_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_5a798_row1_col1, #T_5a798_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_5a798_row2_col0, #T_5a798_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5a798\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5a798_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_5a798_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_5a798_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_5a798_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5a798_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5a798_row0_col0\" class=\"data row0 col0\" >0.928300</td>\n",
       "      <td id=\"T_5a798_row0_col1\" class=\"data row0 col1\" >0.990300</td>\n",
       "      <td id=\"T_5a798_row0_col2\" class=\"data row0 col2\" >0.958300</td>\n",
       "      <td id=\"T_5a798_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a798_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5a798_row1_col0\" class=\"data row1 col0\" >0.766800</td>\n",
       "      <td id=\"T_5a798_row1_col1\" class=\"data row1 col1\" >0.293200</td>\n",
       "      <td id=\"T_5a798_row1_col2\" class=\"data row1 col2\" >0.424200</td>\n",
       "      <td id=\"T_5a798_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a798_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_5a798_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_5a798_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_5a798_row2_col2\" class=\"data row2 col2\" >0.922247</td>\n",
       "      <td id=\"T_5a798_row2_col3\" class=\"data row2 col3\" >0.922200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a798_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_5a798_row3_col0\" class=\"data row3 col0\" >0.847500</td>\n",
       "      <td id=\"T_5a798_row3_col1\" class=\"data row3 col1\" >0.641800</td>\n",
       "      <td id=\"T_5a798_row3_col2\" class=\"data row3 col2\" >0.691200</td>\n",
       "      <td id=\"T_5a798_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a798_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_5a798_row4_col0\" class=\"data row4 col0\" >0.912500</td>\n",
       "      <td id=\"T_5a798_row4_col1\" class=\"data row4 col1\" >0.922200</td>\n",
       "      <td id=\"T_5a798_row4_col2\" class=\"data row4 col2\" >0.906100</td>\n",
       "      <td id=\"T_5a798_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x124680190>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=CatBoostClassifier(),\n",
    "    model_name=\"cat_classifier\",\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=False\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7931c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13684, number of negative: 126399\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51000\n",
      "[LightGBM] [Info] Number of data points in the train set: 140083, number of used features: 200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.097685 -> initscore=-2.223216\n",
      "[LightGBM] [Info] Start training from score -2.223216\n",
      "Model saved to: results/lgbm_classifier.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olutolaoloruntobipaul/Desktop/Projects/Hands-on-ML/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fda03_row0_col0, #T_fda03_row0_col1, #T_fda03_row0_col2, #T_fda03_row1_col0, #T_fda03_row2_col2, #T_fda03_row3_col0, #T_fda03_row4_col0, #T_fda03_row4_col1, #T_fda03_row4_col2 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_fda03_row1_col1, #T_fda03_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_fda03_row2_col0, #T_fda03_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_fda03_row3_col1, #T_fda03_row3_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fda03\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fda03_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_fda03_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_fda03_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_fda03_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fda03_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fda03_row0_col0\" class=\"data row0 col0\" >0.910400</td>\n",
       "      <td id=\"T_fda03_row0_col1\" class=\"data row0 col1\" >0.998400</td>\n",
       "      <td id=\"T_fda03_row0_col2\" class=\"data row0 col2\" >0.952400</td>\n",
       "      <td id=\"T_fda03_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fda03_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fda03_row1_col0\" class=\"data row1 col0\" >0.862600</td>\n",
       "      <td id=\"T_fda03_row1_col1\" class=\"data row1 col1\" >0.091800</td>\n",
       "      <td id=\"T_fda03_row1_col2\" class=\"data row1 col2\" >0.165900</td>\n",
       "      <td id=\"T_fda03_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fda03_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_fda03_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_fda03_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_fda03_row2_col2\" class=\"data row2 col2\" >0.909854</td>\n",
       "      <td id=\"T_fda03_row2_col3\" class=\"data row2 col3\" >0.909900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fda03_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_fda03_row3_col0\" class=\"data row3 col0\" >0.886500</td>\n",
       "      <td id=\"T_fda03_row3_col1\" class=\"data row3 col1\" >0.545100</td>\n",
       "      <td id=\"T_fda03_row3_col2\" class=\"data row3 col2\" >0.559100</td>\n",
       "      <td id=\"T_fda03_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fda03_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_fda03_row4_col0\" class=\"data row4 col0\" >0.905700</td>\n",
       "      <td id=\"T_fda03_row4_col1\" class=\"data row4 col1\" >0.909900</td>\n",
       "      <td id=\"T_fda03_row4_col2\" class=\"data row4 col2\" >0.875500</td>\n",
       "      <td id=\"T_fda03_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x124680550>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=LGBMClassifier(),\n",
    "    model_name=\"lgbm_classifier\",\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=False\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c46f53f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/linear_svc_classifier.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ccdb9_row0_col0, #T_ccdb9_row0_col1, #T_ccdb9_row0_col2, #T_ccdb9_row2_col2, #T_ccdb9_row3_col0, #T_ccdb9_row4_col0, #T_ccdb9_row4_col1, #T_ccdb9_row4_col2 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_ccdb9_row1_col0, #T_ccdb9_row3_col1, #T_ccdb9_row3_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_ccdb9_row1_col1, #T_ccdb9_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_ccdb9_row2_col0, #T_ccdb9_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ccdb9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ccdb9_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_ccdb9_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_ccdb9_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_ccdb9_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ccdb9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ccdb9_row0_col0\" class=\"data row0 col0\" >0.915500</td>\n",
       "      <td id=\"T_ccdb9_row0_col1\" class=\"data row0 col1\" >0.994800</td>\n",
       "      <td id=\"T_ccdb9_row0_col2\" class=\"data row0 col2\" >0.953500</td>\n",
       "      <td id=\"T_ccdb9_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccdb9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ccdb9_row1_col0\" class=\"data row1 col0\" >0.759500</td>\n",
       "      <td id=\"T_ccdb9_row1_col1\" class=\"data row1 col1\" >0.152300</td>\n",
       "      <td id=\"T_ccdb9_row1_col2\" class=\"data row1 col2\" >0.253700</td>\n",
       "      <td id=\"T_ccdb9_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccdb9_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_ccdb9_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_ccdb9_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_ccdb9_row2_col2\" class=\"data row2 col2\" >0.912481</td>\n",
       "      <td id=\"T_ccdb9_row2_col3\" class=\"data row2 col3\" >0.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccdb9_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_ccdb9_row3_col0\" class=\"data row3 col0\" >0.837500</td>\n",
       "      <td id=\"T_ccdb9_row3_col1\" class=\"data row3 col1\" >0.573500</td>\n",
       "      <td id=\"T_ccdb9_row3_col2\" class=\"data row3 col2\" >0.603600</td>\n",
       "      <td id=\"T_ccdb9_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccdb9_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_ccdb9_row4_col0\" class=\"data row4 col0\" >0.900300</td>\n",
       "      <td id=\"T_ccdb9_row4_col1\" class=\"data row4 col1\" >0.912500</td>\n",
       "      <td id=\"T_ccdb9_row4_col2\" class=\"data row4 col2\" >0.885200</td>\n",
       "      <td id=\"T_ccdb9_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x124680410>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=LinearSVC(),\n",
    "    model_name=\"linear_svc_classifier\",\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=False\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "519fdba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/rf_classifier.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aa625_row0_col0, #T_aa625_row0_col1, #T_aa625_row0_col2, #T_aa625_row1_col0, #T_aa625_row2_col2, #T_aa625_row3_col0, #T_aa625_row4_col0, #T_aa625_row4_col1, #T_aa625_row4_col2 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_aa625_row1_col1, #T_aa625_row1_col2, #T_aa625_row3_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_aa625_row2_col0, #T_aa625_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_aa625_row3_col1 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aa625\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aa625_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_aa625_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_aa625_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_aa625_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aa625_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aa625_row0_col0\" class=\"data row0 col0\" >0.902300</td>\n",
       "      <td id=\"T_aa625_row0_col1\" class=\"data row0 col1\" >1.000000</td>\n",
       "      <td id=\"T_aa625_row0_col2\" class=\"data row0 col2\" >0.948700</td>\n",
       "      <td id=\"T_aa625_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa625_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_aa625_row1_col0\" class=\"data row1 col0\" >1.000000</td>\n",
       "      <td id=\"T_aa625_row1_col1\" class=\"data row1 col1\" >0.000300</td>\n",
       "      <td id=\"T_aa625_row1_col2\" class=\"data row1 col2\" >0.000600</td>\n",
       "      <td id=\"T_aa625_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa625_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_aa625_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_aa625_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_aa625_row2_col2\" class=\"data row2 col2\" >0.902344</td>\n",
       "      <td id=\"T_aa625_row2_col3\" class=\"data row2 col3\" >0.902300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa625_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_aa625_row3_col0\" class=\"data row3 col0\" >0.951200</td>\n",
       "      <td id=\"T_aa625_row3_col1\" class=\"data row3 col1\" >0.500100</td>\n",
       "      <td id=\"T_aa625_row3_col2\" class=\"data row3 col2\" >0.474600</td>\n",
       "      <td id=\"T_aa625_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa625_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_aa625_row4_col0\" class=\"data row4 col0\" >0.911900</td>\n",
       "      <td id=\"T_aa625_row4_col1\" class=\"data row4 col1\" >0.902300</td>\n",
       "      <td id=\"T_aa625_row4_col2\" class=\"data row4 col2\" >0.856100</td>\n",
       "      <td id=\"T_aa625_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x124680b90>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=RandomForestClassifier(),\n",
    "    model_name=\"rf_classifier\",\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=False\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9a50004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: results/nb_classifier.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_37cf2_row0_col0, #T_37cf2_row0_col1, #T_37cf2_row0_col2, #T_37cf2_row2_col2, #T_37cf2_row3_col0, #T_37cf2_row4_col0, #T_37cf2_row4_col1, #T_37cf2_row4_col2 {\n",
       "  background-color: rgba(0, 200, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_37cf2_row1_col0, #T_37cf2_row3_col1, #T_37cf2_row3_col2 {\n",
       "  background-color: rgba(255, 165, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_37cf2_row1_col1, #T_37cf2_row1_col2 {\n",
       "  background-color: rgba(255, 0, 0, 0.35);\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_37cf2_row2_col0, #T_37cf2_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_37cf2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_37cf2_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_37cf2_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_37cf2_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_37cf2_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_37cf2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_37cf2_row0_col0\" class=\"data row0 col0\" >0.931700</td>\n",
       "      <td id=\"T_37cf2_row0_col1\" class=\"data row0 col1\" >0.984600</td>\n",
       "      <td id=\"T_37cf2_row0_col2\" class=\"data row0 col2\" >0.957400</td>\n",
       "      <td id=\"T_37cf2_row0_col3\" class=\"data row0 col3\" >31600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37cf2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_37cf2_row1_col0\" class=\"data row1 col0\" >0.701300</td>\n",
       "      <td id=\"T_37cf2_row1_col1\" class=\"data row1 col1\" >0.333500</td>\n",
       "      <td id=\"T_37cf2_row1_col2\" class=\"data row1 col2\" >0.452100</td>\n",
       "      <td id=\"T_37cf2_row1_col3\" class=\"data row1 col3\" >3421.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37cf2_level0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "      <td id=\"T_37cf2_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_37cf2_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_37cf2_row2_col2\" class=\"data row2 col2\" >0.921019</td>\n",
       "      <td id=\"T_37cf2_row2_col3\" class=\"data row2 col3\" >0.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37cf2_level0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "      <td id=\"T_37cf2_row3_col0\" class=\"data row3 col0\" >0.816500</td>\n",
       "      <td id=\"T_37cf2_row3_col1\" class=\"data row3 col1\" >0.659100</td>\n",
       "      <td id=\"T_37cf2_row3_col2\" class=\"data row3 col2\" >0.704800</td>\n",
       "      <td id=\"T_37cf2_row3_col3\" class=\"data row3 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37cf2_level0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "      <td id=\"T_37cf2_row4_col0\" class=\"data row4 col0\" >0.909200</td>\n",
       "      <td id=\"T_37cf2_row4_col1\" class=\"data row4 col1\" >0.921000</td>\n",
       "      <td id=\"T_37cf2_row4_col2\" class=\"data row4 col2\" >0.908100</td>\n",
       "      <td id=\"T_37cf2_row4_col3\" class=\"data row4 col3\" >35021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x124680e10>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=GaussianNB(),\n",
    "    model_name=\"nb_classifier\",\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=False\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef6a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=GradientBoostingClassifier(),\n",
    "    model_name=\"gb_classifier\",\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=False\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb12e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=SVC(),\n",
    "    model_name=\"sv_classifier\",\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=False\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8cf209",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=KNeighborsClassifier(),\n",
    "    model_name=\"knn_classifier\",\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=False\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02657c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=MLPClassifier(),\n",
    "    model_name=\"nn_classifier\",\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=False\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred, report  = train_and_save_model(\n",
    "    model=XGBClassifier(),\n",
    "    model_name=\"xgb_classifier\",\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    sampled=False\n",
    ")\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
